{"sentences": ["See <https://builds.apache.org/job/provisionr-master/96/", "see < https : / / builds . apache . org / job / provisionr - master / 96 /"], "labels": [0, 0], "abstract_id": 0}
{"sentences": ["I was wondering how to modify window options like resizable,scrollbars,.. I use the dialog framework to open a popup.", "The popup seems to use a frameset.", "Can i disable this behaviour?", "Is a non modal Dialog available?"], "labels": [0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["Maybe worth to think about moving parts of the kalumet code into plugins for devops tools like chef or puppets...", "________________________________ Von: Andreas Pieber <anpieber@gmail.com Gesendet: Mittwoch, 2. September 2015 15:00 An: kalumet-user@incubator.apache.org Cc: kalumet-dev@incubator.apache.org Betreff: Re: [VOTE] Retire Kalumet from the incubator +1 Same problem here.", "Simply not enough free timeslots as I had hoped for :-(", "Kind regards, Andreas On Wed, Sep 2, 2015 at 2:11 PM"], "labels": [0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["________________________________ Von: Andreas Pieber <anpieber@gmail.com Gesendet: Mittwoch, 2. September 2015 15:00 An: kalumet-user@incubator.apache.org Cc: kalumet-dev@incubator.apache.org Betreff: Re: [VOTE] Retire Kalumet from the incubator +1 Same problem here.", "Simply not enough free timeslots as I had hoped for :-(", "Kind regards, Andreas On Wed, Sep 2, 2015 at 2:11 PM", "Jamie G. <jamie.goodyear@gmail.com<mailto:jamie.goodyear@gmail.com wrote: +1 Same feelings as Achim here, just not enough time to devote to this project :( On Wed, Sep 2, 2015 at 9:07 AM, Achim Nierbeck <bcanhome@googlemail.com<mailto:bcanhome@googlemail.com wrote: +1 ... I'm very sorry but I couldn't spent as much time on this project then what I wished for."], "labels": [0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["Simply not enough free timeslots as I had hoped for :-(", "Kind regards, Andreas On Wed, Sep 2, 2015 at 2:11 PM", "Jamie G. <jamie.goodyear@gmail.com<mailto:jamie.goodyear@gmail.com wrote: +1 Same feelings as Achim here, just not enough time to devote to this project :( On Wed, Sep 2, 2015 at 9:07 AM, Achim Nierbeck <bcanhome@googlemail.com<mailto:bcanhome@googlemail.com wrote: +1 ... I'm very sorry but I couldn't spent as much time on this project then what I wished for.", "regards, Achim 2015-09-02 13:35 GMT+02:00 Jean-Baptiste Onofré <jb@nanthrax.net<mailto:jb@nanthrax.net:", "Hi all, Regarding the Kalumet community activity, I think it's a fair question: do we want to continue the incubation process ?"], "labels": [0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["regards, Achim 2015-09-02 13:35 GMT+02:00 Jean-Baptiste Onofré <jb@nanthrax.net<mailto:jb@nanthrax.net:", "Hi all, Regarding the Kalumet community activity, I think it's a fair question: do we want to continue the incubation process ?", "Even if I'm still thinking that Kalumet has lot of values, I propose to retire Kalumet from the incubator: [ ] +1 to retire Kalumet from the incubator [ ] -1 to keep Kalumet in the incubator", "The vote is open for 48 hours.", "Thanks, Regards JB -- Jean-Baptiste Onofré jbonofre@apache.org<mailto:jbonofre@apache.org"], "labels": [0, 0, 1, 1, 0], "abstract_id": 0}
{"sentences": ["Hi all, Regarding the Kalumet community activity, I think it's a fair question: do we want to continue the incubation process ?", "Even if I'm still thinking that Kalumet has lot of values, I propose to retire Kalumet from the incubator: [ ] +1 to retire Kalumet from the incubator [ ] -1 to keep Kalumet in the incubator", "The vote is open for 48 hours.", "Thanks, Regards JB -- Jean-Baptiste Onofré jbonofre@apache.org<mailto:jbonofre@apache.org", "http://blog.nanthrax.net Talend - http://www.talend.com -- Apache Member Apache Karaf <http://karaf.apache.org/ Committer & PMC OPS4J Pax Web <http://wiki.ops4j.org/display/paxweb/Pax+Web/ Committer & Project Lead blog <http://notizblog.nierbeck.de/ Co-Author of Apache Karaf Cookbook <http://bit.ly/1ps9rkS"], "labels": [0, 1, 1, 0, 0], "abstract_id": 0}
{"sentences": ["Even if I'm still thinking that Kalumet has lot of values, I propose to retire Kalumet from the incubator: [ ] +1 to retire Kalumet from the incubator [ ] -1 to keep Kalumet in the incubator", "The vote is open for 48 hours.", "Thanks, Regards JB -- Jean-Baptiste Onofré jbonofre@apache.org<mailto:jbonofre@apache.org", "http://blog.nanthrax.net Talend - http://www.talend.com -- Apache Member Apache Karaf <http://karaf.apache.org/ Committer & PMC OPS4J Pax Web <http://wiki.ops4j.org/display/paxweb/Pax+Web/ Committer & Project Lead blog <http://notizblog.nierbeck.de/ Co-Author of Apache Karaf Cookbook <http://bit.ly/1ps9rkS", "Software Architect / Project Manager / Scrum Master -- --"], "labels": [1, 1, 0, 0, 0], "abstract_id": 0}
{"sentences": ["The vote is open for 48 hours.", "Thanks, Regards JB -- Jean-Baptiste Onofré jbonofre@apache.org<mailto:jbonofre@apache.org", "http://blog.nanthrax.net Talend - http://www.talend.com -- Apache Member Apache Karaf <http://karaf.apache.org/ Committer & PMC OPS4J Pax Web <http://wiki.ops4j.org/display/paxweb/Pax+Web/ Committer & Project Lead blog <http://notizblog.nierbeck.de/ Co-Author of Apache Karaf Cookbook <http://bit.ly/1ps9rkS", "Software Architect / Project Manager / Scrum Master -- --", "Sent from my mobile."], "labels": [1, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["http://blog.nanthrax.net Talend - http://www.talend.com -- Apache Member Apache Karaf <http://karaf.apache.org/ Committer & PMC OPS4J Pax Web <http://wiki.ops4j.org/display/paxweb/Pax+Web/ Committer & Project Lead blog <http://notizblog.nierbeck.de/ Co-Author of Apache Karaf Cookbook <http://bit.ly/1ps9rkS", "Software Architect / Project Manager / Scrum Master -- --", "Sent from my mobile.", "Forgive the brevity, the typos and the lack of nuance."], "labels": [0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["I've recently upgraded to 1.8.0 and immediately encountered the hanging SubDag issue that's been mentioned.", "I'm not sure the rollback from rc5 to rc4 fixed the issue.", "For now I've removed all SubDags and put their task_instances in the main DAG.", "Assuming this issue gets fixed, how is one supposed to recover from failures within SubDags after the # of retries have maxed?", "Previously, I would clear the state of the offending tasks and run a backfill job.", "Backfill jobs in 1.7.1 would skip successful task_instances and only run the task_instances with cleared states."], "labels": [0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["I'm not sure the rollback from rc5 to rc4 fixed the issue.", "For now I've removed all SubDags and put their task_instances in the main DAG.", "Assuming this issue gets fixed, how is one supposed to recover from failures within SubDags after the # of retries have maxed?", "Previously, I would clear the state of the offending tasks and run a backfill job.", "Backfill jobs in 1.7.1 would skip successful task_instances and only run the task_instances with cleared states.", "Now, backfills and SubDagOperators clear the state of successful tasks."], "labels": [0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["For now I've removed all SubDags and put their task_instances in the main DAG.", "Assuming this issue gets fixed, how is one supposed to recover from failures within SubDags after the # of retries have maxed?", "Previously, I would clear the state of the offending tasks and run a backfill job.", "Backfill jobs in 1.7.1 would skip successful task_instances and only run the task_instances with cleared states.", "Now, backfills and SubDagOperators clear the state of successful tasks.", "I'd rather not re-run a task that already succeeded."], "labels": [0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["Assuming this issue gets fixed, how is one supposed to recover from failures within SubDags after the # of retries have maxed?", "Previously, I would clear the state of the offending tasks and run a backfill job.", "Backfill jobs in 1.7.1 would skip successful task_instances and only run the task_instances with cleared states.", "Now, backfills and SubDagOperators clear the state of successful tasks.", "I'd rather not re-run a task that already succeeded.", "I tried running backfills with --task_regex and --ignore_dependencies, but that doesn't quite work either."], "labels": [0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["Previously, I would clear the state of the offending tasks and run a backfill job.", "Backfill jobs in 1.7.1 would skip successful task_instances and only run the task_instances with cleared states.", "Now, backfills and SubDagOperators clear the state of successful tasks.", "I'd rather not re-run a task that already succeeded.", "I tried running backfills with --task_regex and --ignore_dependencies, but that doesn't quite work either.", "If I have t1(success) - t2(clear) - t3(clear) and I set --task_regex so that it excludes t1, then t2 will run, but t3 will never run because it doesn't wait for t2 to finish."], "labels": [0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["Backfill jobs in 1.7.1 would skip successful task_instances and only run the task_instances with cleared states.", "Now, backfills and SubDagOperators clear the state of successful tasks.", "I'd rather not re-run a task that already succeeded.", "I tried running backfills with --task_regex and --ignore_dependencies, but that doesn't quite work either.", "If I have t1(success) - t2(clear) - t3(clear) and I set --task_regex so that it excludes t1, then t2 will run, but t3 will never run because it doesn't wait for t2 to finish.", "It fails because its upstream dependency condition is not met."], "labels": [0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["Now, backfills and SubDagOperators clear the state of successful tasks.", "I'd rather not re-run a task that already succeeded.", "I tried running backfills with --task_regex and --ignore_dependencies, but that doesn't quite work either.", "If I have t1(success) - t2(clear) - t3(clear) and I set --task_regex so that it excludes t1, then t2 will run, but t3 will never run because it doesn't wait for t2 to finish.", "It fails because its upstream dependency condition is not met.", "I like the logical grouping that SubDags provide, but I don't want all retry all tasks even if they're successful."], "labels": [0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["I'd rather not re-run a task that already succeeded.", "I tried running backfills with --task_regex and --ignore_dependencies, but that doesn't quite work either.", "If I have t1(success) - t2(clear) - t3(clear) and I set --task_regex so that it excludes t1, then t2 will run, but t3 will never run because it doesn't wait for t2 to finish.", "It fails because its upstream dependency condition is not met.", "I like the logical grouping that SubDags provide, but I don't want all retry all tasks even if they're successful.", "I can see why one would want that behavior in some cases, but it's certainly not useful in all."], "labels": [0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["I am a Blur newbie and just heard about it and the recent 0.2 release from the latest Hadoop Weekly email.", "I checked out the site and there is a great documentation for getting started, but didn't mention a couple questions I have.", "We are running our Hadoop clusters as a mix of persistent and transient EMR clusters in Amazon.", "It is running Hadoop 1.0.3.", "We are also using S3 instead of HDFS to store our data.", "So does anyone have experience running Blur in an Amazon environment?", "Does S3 vs HDFS present any problems to the Blur architecture?"], "labels": [0, 0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["I checked out the site and there is a great documentation for getting started, but didn't mention a couple questions I have.", "We are running our Hadoop clusters as a mix of persistent and transient EMR clusters in Amazon.", "It is running Hadoop 1.0.3.", "We are also using S3 instead of HDFS to store our data.", "So does anyone have experience running Blur in an Amazon environment?", "Does S3 vs HDFS present any problems to the Blur architecture?", "Thanks in advance!"], "labels": [0, 0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["We are running our Hadoop clusters as a mix of persistent and transient EMR clusters in Amazon.", "It is running Hadoop 1.0.3.", "We are also using S3 instead of HDFS to store our data.", "So does anyone have experience running Blur in an Amazon environment?", "Does S3 vs HDFS present any problems to the Blur architecture?", "Thanks in advance!", "-Jonathan"], "labels": [0, 0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["[ https://issues.apache.org/jira/browse/JOHNZON-46?page=com.atlassian.jira.plugin.system.issuetabpanels:all-tabpanel ] Romain Manni-Bucau resolved JOHNZON-46.", "---------------------------------------", "Resolution: Fixed warning using builder + size config", "----------------------------------- Key: JOHNZON-46 URL: https://issues.apache.org/jira/browse/JOHNZON-46"], "labels": [0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["---------------------------------------", "Resolution: Fixed warning using builder + size config", "----------------------------------- Key: JOHNZON-46 URL: https://issues.apache.org/jira/browse/JOHNZON-46", "Project: Johnzon Issue Type: Bug Reporter: Romain Manni-Bucau Fix For: 0.8-incubating {code} AVERTISSEMENT - org.apache.johnzon.default-char-buffer is not supported by org.apache.johnzon.core.JsonGeneratorFactoryImpl AVERTISSEMENT - org.apache.johnzon.max-string-length is not supported by org.apache.johnzon.core.JsonGeneratorFactoryImpl {code} --", "This message was sent by Atlassian JIRA (v6.3.4#6332)"], "labels": [0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["That is probably because Livy supports Spark 1.6 and \"SparkSession\" does not exist in that version, so the code wouldn't compile otherwise.", "If you try to cast it to some other type, though, you'll get an exception at run time.", "On Sat, Dec 2, 2017 at 10:11 AM, kant kodali <kanth909@gmail.com wrote: Hi All, Why does jobContext.sparkSession() doesn't return a SparkSession Object instead it returns a parametrized type?", "jobContext.sc(); //returns JavaSparkContext so this is good jobContext.sqlContext();// returns SqlContext so this is good jobContext.steamingContext(); // returns StreamingContext so this is good jobContext.sparkSession(); // returns any parameterized type. why?", "since it returns a parametrized type I can assign it to anything I like that wouldn't make any sense."], "labels": [0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["On Sat, Dec 2, 2017 at 10:11 AM, kant kodali <kanth909@gmail.com wrote: Hi All, Why does jobContext.sparkSession() doesn't return a SparkSession Object instead it returns a parametrized type?", "jobContext.sc(); //returns JavaSparkContext so this is good jobContext.sqlContext();// returns SqlContext so this is good jobContext.steamingContext(); // returns StreamingContext so this is good jobContext.sparkSession(); // returns any parameterized type. why?", "since it returns a parametrized type I can assign it to anything I like that wouldn't make any sense.", "Integer k = jobContext.sparkSession() or Long l = jobContext.sparkSession()"], "labels": [0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["jobContext.sc(); //returns JavaSparkContext so this is good jobContext.sqlContext();// returns SqlContext so this is good jobContext.steamingContext(); // returns StreamingContext so this is good jobContext.sparkSession(); // returns any parameterized type. why?", "since it returns a parametrized type I can assign it to anything I like that wouldn't make any sense.", "Integer k = jobContext.sparkSession() or Long l = jobContext.sparkSession()", "Below is the livy interface package org.apache.livy; import java.io."], "labels": [0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["since it returns a parametrized type I can assign it to anything I like that wouldn't make any sense.", "Integer k = jobContext.sparkSession() or Long l = jobContext.sparkSession()", "Below is the livy interface package org.apache.livy; import java.io.", "File; import org.apache.spark.api.java.JavaSparkContext; import org.apache.spark.sql.SQLContext; import org.apache.spark.sql.hive.HiveContext; import org.apache.spark.streaming.api.java.JavaStreamingContext; public interface JobContext { JavaSparkContext sc(); SQLContext sqlctx(); HiveContext hivectx(); JavaStreamingContext streamingctx(); void createStreamingContext(long var1); void stopStreamingCtx(); File getLocalTmpDir(); <E E sparkSession() throws Exception; } -- Marcelo"], "labels": [0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["Interesting question.", "So if you have legacy/pre-existing data formats, then the use case for DFDL is clear.", "So I think of your question as this really:", "What are use cases for DFDL for \"new\" applications?", "I think new applications that are inventing file formats may end up using DFDL if the application authors are too lazy to use say, XML as the file format.", "If they just do whatever is easiest to write-out from their favorite programming language, then they're going to get an ad-hoc file format, and in the future if some *other* software wants to read that file, then DFDL is a tool of choice.", "But it is preferable if new applications that invent file formats do so purposefully and use a standard text-oriented representation like XML."], "labels": [0, 0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["So I think of your question as this really:", "What are use cases for DFDL for \"new\" applications?", "I think new applications that are inventing file formats may end up using DFDL if the application authors are too lazy to use say, XML as the file format.", "If they just do whatever is easiest to write-out from their favorite programming language, then they're going to get an ad-hoc file format, and in the future if some *other* software wants to read that file, then DFDL is a tool of choice.", "But it is preferable if new applications that invent file formats do so purposefully and use a standard text-oriented representation like XML.", "(Could be JSON too, but lack of a schema language for JSON makes it far less desirable IMHO.)"], "labels": [0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["I think new applications that are inventing file formats may end up using DFDL if the application authors are too lazy to use say, XML as the file format.", "If they just do whatever is easiest to write-out from their favorite programming language, then they're going to get an ad-hoc file format, and in the future if some *other* software wants to read that file, then DFDL is a tool of choice.", "But it is preferable if new applications that invent file formats do so purposefully and use a standard text-oriented representation like XML.", "(Could be JSON too, but lack of a schema language for JSON makes it far less desirable IMHO.)", "The exceptions here are if speed/space concerns make the overhead of XML too high."], "labels": [0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["If they just do whatever is easiest to write-out from their favorite programming language, then they're going to get an ad-hoc file format, and in the future if some *other* software wants to read that file, then DFDL is a tool of choice.", "But it is preferable if new applications that invent file formats do so purposefully and use a standard text-oriented representation like XML.", "(Could be JSON too, but lack of a schema language for JSON makes it far less desirable IMHO.)", "The exceptions here are if speed/space concerns make the overhead of XML too high.", "There is an environmental argument against using XML."], "labels": [0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["But it is preferable if new applications that invent file formats do so purposefully and use a standard text-oriented representation like XML.", "(Could be JSON too, but lack of a schema language for JSON makes it far less desirable IMHO.)", "The exceptions here are if speed/space concerns make the overhead of XML too high.", "There is an environmental argument against using XML.", "Consider all the wasted CPU cycles in the world dealing with XML's verbose and redundant structure.", "Given that computers use lots of energy, the \"Carbon Footprint\" of XML on global scale is something to think about."], "labels": [0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["(Could be JSON too, but lack of a schema language for JSON makes it far less desirable IMHO.)", "The exceptions here are if speed/space concerns make the overhead of XML too high.", "There is an environmental argument against using XML.", "Consider all the wasted CPU cycles in the world dealing with XML's verbose and redundant structure.", "Given that computers use lots of energy, the \"Carbon Footprint\" of XML on global scale is something to think about.", "Makes me wish EXI would catch on more.", "I also wish XML would just allow a non-verbose close tag like <foovalue</ where the end tag doesn't have to repeat the open tag."], "labels": [0, 0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["The exceptions here are if speed/space concerns make the overhead of XML too high.", "There is an environmental argument against using XML.", "Consider all the wasted CPU cycles in the world dealing with XML's verbose and redundant structure.", "Given that computers use lots of energy, the \"Carbon Footprint\" of XML on global scale is something to think about.", "Makes me wish EXI would catch on more.", "I also wish XML would just allow a non-verbose close tag like <foovalue</ where the end tag doesn't have to repeat the open tag.", "This would reduce XML's overhead to much closer to JSON or Lisp S-expressions again."], "labels": [0, 0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["There is an environmental argument against using XML.", "Consider all the wasted CPU cycles in the world dealing with XML's verbose and redundant structure.", "Given that computers use lots of energy, the \"Carbon Footprint\" of XML on global scale is something to think about.", "Makes me wish EXI would catch on more.", "I also wish XML would just allow a non-verbose close tag like <foovalue</ where the end tag doesn't have to repeat the open tag.", "This would reduce XML's overhead to much closer to JSON or Lisp S-expressions again.", "But I digress."], "labels": [0, 0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["Consider all the wasted CPU cycles in the world dealing with XML's verbose and redundant structure.", "Given that computers use lots of energy, the \"Carbon Footprint\" of XML on global scale is something to think about.", "Makes me wish EXI would catch on more.", "I also wish XML would just allow a non-verbose close tag like <foovalue</ where the end tag doesn't have to repeat the open tag.", "This would reduce XML's overhead to much closer to JSON or Lisp S-expressions again.", "But I digress.", "But ignoring all that, there are cases where use of an expensive data format like XML just won't allow you to achieve the goal of your software."], "labels": [0, 0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["Given that computers use lots of energy, the \"Carbon Footprint\" of XML on global scale is something to think about.", "Makes me wish EXI would catch on more.", "I also wish XML would just allow a non-verbose close tag like <foovalue</ where the end tag doesn't have to repeat the open tag.", "This would reduce XML's overhead to much closer to JSON or Lisp S-expressions again.", "But I digress.", "But ignoring all that, there are cases where use of an expensive data format like XML just won't allow you to achieve the goal of your software.", "The two cases I know of where something like XML is unacceptable and one might prefer a dense binary data format are cutting-edge supercomputing applications - where every bit counts in space/speed if the application is going to work at all, and also ultra-low-power computing, where every bit counts, because the cost of just data compress/decompress consumes too much battery power."], "labels": [0, 0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["I also wish XML would just allow a non-verbose close tag like <foovalue</ where the end tag doesn't have to repeat the open tag.", "This would reduce XML's overhead to much closer to JSON or Lisp S-expressions again.", "But I digress.", "But ignoring all that, there are cases where use of an expensive data format like XML just won't allow you to achieve the goal of your software.", "The two cases I know of where something like XML is unacceptable and one might prefer a dense binary data format are cutting-edge supercomputing applications - where every bit counts in space/speed if the application is going to work at all, and also ultra-low-power computing, where every bit counts, because the cost of just data compress/decompress consumes too much battery power.", "But even then, a standard binary format like EXI (binary XML - same infoset as XML, just denser binary representation) may be preferable to an ad-hoc file format with DFDL schema."], "labels": [0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["This would reduce XML's overhead to much closer to JSON or Lisp S-expressions again.", "But I digress.", "But ignoring all that, there are cases where use of an expensive data format like XML just won't allow you to achieve the goal of your software.", "The two cases I know of where something like XML is unacceptable and one might prefer a dense binary data format are cutting-edge supercomputing applications - where every bit counts in space/speed if the application is going to work at all, and also ultra-low-power computing, where every bit counts, because the cost of just data compress/decompress consumes too much battery power.", "But even then, a standard binary format like EXI (binary XML - same infoset as XML, just denser binary representation) may be preferable to an ad-hoc file format with DFDL schema.", "Lastly another use case I've found for DFDL is what I call \"CSV-like\" data files."], "labels": [0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["The two cases I know of where something like XML is unacceptable and one might prefer a dense binary data format are cutting-edge supercomputing applications - where every bit counts in space/speed if the application is going to work at all, and also ultra-low-power computing, where every bit counts, because the cost of just data compress/decompress consumes too much battery power.", "But even then, a standard binary format like EXI (binary XML - same infoset as XML, just denser binary representation) may be preferable to an ad-hoc file format with DFDL schema.", "Lastly another use case I've found for DFDL is what I call \"CSV-like\" data files.", "These arise when human beings will be editing data files by hand."], "labels": [0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["But even then, a standard binary format like EXI (binary XML - same infoset as XML, just denser binary representation) may be preferable to an ad-hoc file format with DFDL schema.", "Lastly another use case I've found for DFDL is what I call \"CSV-like\" data files.", "These arise when human beings will be editing data files by hand.", "I have a lot of experience of \"CSV\" data files that aren't at all well behaved as true CSV data files are supposed to be.", "Given a spreadsheet program like MS-Excel, people will create a spreadsheet document with all sorts of headers and sections on a sheet."], "labels": [0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["Lastly another use case I've found for DFDL is what I call \"CSV-like\" data files.", "These arise when human beings will be editing data files by hand.", "I have a lot of experience of \"CSV\" data files that aren't at all well behaved as true CSV data files are supposed to be.", "Given a spreadsheet program like MS-Excel, people will create a spreadsheet document with all sorts of headers and sections on a sheet.", "Then they'll export that sheet as \"CSV\" and claim the file is CSV data.", "These sorts of \"CSV-like\" files are often full of inconsistencies."], "labels": [0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["These arise when human beings will be editing data files by hand.", "I have a lot of experience of \"CSV\" data files that aren't at all well behaved as true CSV data files are supposed to be.", "Given a spreadsheet program like MS-Excel, people will create a spreadsheet document with all sorts of headers and sections on a sheet.", "Then they'll export that sheet as \"CSV\" and claim the file is CSV data.", "These sorts of \"CSV-like\" files are often full of inconsistencies.", "Empty cells are sometimes empty string, sometimes all-whitespace strings, sometimes various markers like \"--\" or \"N/A\" or \"none\""], "labels": [0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["I have a lot of experience of \"CSV\" data files that aren't at all well behaved as true CSV data files are supposed to be.", "Given a spreadsheet program like MS-Excel, people will create a spreadsheet document with all sorts of headers and sections on a sheet.", "Then they'll export that sheet as \"CSV\" and claim the file is CSV data.", "These sorts of \"CSV-like\" files are often full of inconsistencies.", "Empty cells are sometimes empty string, sometimes all-whitespace strings, sometimes various markers like \"--\" or \"N/A\" or \"none\"", "A DFDL schema can be written which handles all these human inconsistency factors, skipping section headers, standardizing \"--\", \"N/A\", etc."], "labels": [0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["Given a spreadsheet program like MS-Excel, people will create a spreadsheet document with all sorts of headers and sections on a sheet.", "Then they'll export that sheet as \"CSV\" and claim the file is CSV data.", "These sorts of \"CSV-like\" files are often full of inconsistencies.", "Empty cells are sometimes empty string, sometimes all-whitespace strings, sometimes various markers like \"--\" or \"N/A\" or \"none\"", "A DFDL schema can be written which handles all these human inconsistency factors, skipping section headers, standardizing \"--\", \"N/A\", etc.", "The result is well-behaved XML data set from an inconsistent human-edited CSV-like data file."], "labels": [0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["Then they'll export that sheet as \"CSV\" and claim the file is CSV data.", "These sorts of \"CSV-like\" files are often full of inconsistencies.", "Empty cells are sometimes empty string, sometimes all-whitespace strings, sometimes various markers like \"--\" or \"N/A\" or \"none\"", "A DFDL schema can be written which handles all these human inconsistency factors, skipping section headers, standardizing \"--\", \"N/A\", etc.", "The result is well-behaved XML data set from an inconsistent human-edited CSV-like data file.", "-mike beckerle Tresys Technology ________________________________"], "labels": [0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["These sorts of \"CSV-like\" files are often full of inconsistencies.", "Empty cells are sometimes empty string, sometimes all-whitespace strings, sometimes various markers like \"--\" or \"N/A\" or \"none\"", "A DFDL schema can be written which handles all these human inconsistency factors, skipping section headers, standardizing \"--\", \"N/A\", etc.", "The result is well-behaved XML data set from an inconsistent human-edited CSV-like data file.", "-mike beckerle Tresys Technology ________________________________", "From: Costello, Roger L. <costello@mitre.org Sent: Tuesday, February 19, 2019 12:16:09 PM"], "labels": [0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["A DFDL schema can be written which handles all these human inconsistency factors, skipping section headers, standardizing \"--\", \"N/A\", etc.", "The result is well-behaved XML data set from an inconsistent human-edited CSV-like data file.", "-mike beckerle Tresys Technology ________________________________", "From: Costello, Roger L. <costello@mitre.org Sent: Tuesday, February 19, 2019 12:16:09 PM", "To: users@daffodil.apache.org"], "labels": [0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["The result is well-behaved XML data set from an inconsistent human-edited CSV-like data file.", "-mike beckerle Tresys Technology ________________________________", "From: Costello, Roger L. <costello@mitre.org Sent: Tuesday, February 19, 2019 12:16:09 PM", "To: users@daffodil.apache.org", "Subject:", "With the tremendous agility that DFDL provides, what is the role of XML?"], "labels": [0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["-mike beckerle Tresys Technology ________________________________", "From: Costello, Roger L. <costello@mitre.org Sent: Tuesday, February 19, 2019 12:16:09 PM", "To: users@daffodil.apache.org", "Subject:", "With the tremendous agility that DFDL provides, what is the role of XML?", "What is the role of binary?"], "labels": [0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["From: Costello, Roger L. <costello@mitre.org Sent: Tuesday, February 19, 2019 12:16:09 PM", "To: users@daffodil.apache.org", "Subject:", "With the tremendous agility that DFDL provides, what is the role of XML?", "What is the role of binary?", "Hello DFDL community, DFDL gives us tremendous agility - we can quickly and easily transform binary to XML and XML to binary.", "Binary, with its conciseness, is beautiful for moving data.", "XML, with its vast tool suite, is beautiful for processing data."], "labels": [0, 0, 0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["To: users@daffodil.apache.org", "Subject:", "With the tremendous agility that DFDL provides, what is the role of XML?", "What is the role of binary?", "Hello DFDL community, DFDL gives us tremendous agility - we can quickly and easily transform binary to XML and XML to binary.", "Binary, with its conciseness, is beautiful for moving data.", "XML, with its vast tool suite, is beautiful for processing data.", "What do you see as the role of XML?"], "labels": [0, 0, 0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["Subject:", "With the tremendous agility that DFDL provides, what is the role of XML?", "What is the role of binary?", "Hello DFDL community, DFDL gives us tremendous agility - we can quickly and easily transform binary to XML and XML to binary.", "Binary, with its conciseness, is beautiful for moving data.", "XML, with its vast tool suite, is beautiful for processing data.", "What do you see as the role of XML?", "The role of binary?"], "labels": [0, 0, 0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["With the tremendous agility that DFDL provides, what is the role of XML?", "What is the role of binary?", "Hello DFDL community, DFDL gives us tremendous agility - we can quickly and easily transform binary to XML and XML to binary.", "Binary, with its conciseness, is beautiful for moving data.", "XML, with its vast tool suite, is beautiful for processing data.", "What do you see as the role of XML?", "The role of binary?", "Use binary when moving data, use XML when processing data?"], "labels": [0, 0, 0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["What is the role of binary?", "Hello DFDL community, DFDL gives us tremendous agility - we can quickly and easily transform binary to XML and XML to binary.", "Binary, with its conciseness, is beautiful for moving data.", "XML, with its vast tool suite, is beautiful for processing data.", "What do you see as the role of XML?", "The role of binary?", "Use binary when moving data, use XML when processing data?", "Most images (JPEG, GIF, PNG, etc.) are binary and are processed in their binary form."], "labels": [0, 0, 0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["Binary, with its conciseness, is beautiful for moving data.", "XML, with its vast tool suite, is beautiful for processing data.", "What do you see as the role of XML?", "The role of binary?", "Use binary when moving data, use XML when processing data?", "Most images (JPEG, GIF, PNG, etc.) are binary and are processed in their binary form.", "So XML isn't necessarily the ideal form for processing data.", "I am eager to hear your thoughts/opinions/comments on this subject."], "labels": [0, 0, 0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["XML, with its vast tool suite, is beautiful for processing data.", "What do you see as the role of XML?", "The role of binary?", "Use binary when moving data, use XML when processing data?", "Most images (JPEG, GIF, PNG, etc.) are binary and are processed in their binary form.", "So XML isn't necessarily the ideal form for processing data.", "I am eager to hear your thoughts/opinions/comments on this subject.", "/Roger"], "labels": [0, 0, 0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["The IndexOutOf problem is more related to the first than it seems.", "Check if you have any whitespace after the closing tag of components nested in your <af:table (columns, commandLinks, rowLayouts, etc).", "The exception is thrown because it seems that the <af:table does some work to save and restore a \"state\" for each of its child components, and the extra spaces confuse this logic (like trying to restore the state a component that doesn't exists in the page).", "There must be some problem in parsing of facelets pages.", "Cosma 2006/6/1, Cosma Colanicchia <cosmacol@gmail.com: OC4J has by default the Oracle XDK's XML parser (xmlparserv2.jar)."], "labels": [0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["Check if you have any whitespace after the closing tag of components nested in your <af:table (columns, commandLinks, rowLayouts, etc).", "The exception is thrown because it seems that the <af:table does some work to save and restore a \"state\" for each of its child components, and the extra spaces confuse this logic (like trying to restore the state a component that doesn't exists in the page).", "There must be some problem in parsing of facelets pages.", "Cosma 2006/6/1, Cosma Colanicchia <cosmacol@gmail.com: OC4J has by default the Oracle XDK's XML parser (xmlparserv2.jar).", "If it is a parser related issue, isn't it strange that two different parser implementations produce the same error?"], "labels": [0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["The exception is thrown because it seems that the <af:table does some work to save and restore a \"state\" for each of its child components, and the extra spaces confuse this logic (like trying to restore the state a component that doesn't exists in the page).", "There must be some problem in parsing of facelets pages.", "Cosma 2006/6/1, Cosma Colanicchia <cosmacol@gmail.com: OC4J has by default the Oracle XDK's XML parser (xmlparserv2.jar).", "If it is a parser related issue, isn't it strange that two different parser implementations produce the same error?", "2006/6/1, Frank Felix Debatin <ffd@gmx.net: Pretty ugly, isn't it?"], "labels": [0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["There must be some problem in parsing of facelets pages.", "Cosma 2006/6/1, Cosma Colanicchia <cosmacol@gmail.com: OC4J has by default the Oracle XDK's XML parser (xmlparserv2.jar).", "If it is a parser related issue, isn't it strange that two different parser implementations produce the same error?", "2006/6/1, Frank Felix Debatin <ffd@gmx.net: Pretty ugly, isn't it?", "Adam asked in one of his posts for the XML parser used because that might be the cause of the problem.", "In my JBoss environment it's Xerces."], "labels": [0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["If it is a parser related issue, isn't it strange that two different parser implementations produce the same error?", "2006/6/1, Frank Felix Debatin <ffd@gmx.net: Pretty ugly, isn't it?", "Adam asked in one of his posts for the XML parser used because that might be the cause of the problem.", "In my JBoss environment it's Xerces.", "What alternatives are there?", "Frank Felix -----Original Message----- From: Cosma Colanicchia [mailto:cosmacol@gmail.com]"], "labels": [0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["2006/6/1, Frank Felix Debatin <ffd@gmx.net: Pretty ugly, isn't it?", "Adam asked in one of his posts for the XML parser used because that might be the cause of the problem.", "In my JBoss environment it's Xerces.", "What alternatives are there?", "Frank Felix -----Original Message----- From: Cosma Colanicchia [mailto:cosmacol@gmail.com]", "Sent: Thursday, June 01, 2006 11:25 AM", "To: adffaces-user@incubator.apache.org Subject: Re: ADF"], "labels": [0, 0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["Adam asked in one of his posts for the XML parser used because that might be the cause of the problem.", "In my JBoss environment it's Xerces.", "What alternatives are there?", "Frank Felix -----Original Message----- From: Cosma Colanicchia [mailto:cosmacol@gmail.com]", "Sent: Thursday, June 01, 2006 11:25 AM", "To: adffaces-user@incubator.apache.org Subject: Re: ADF", "Faces component with facelets Frank, as I replied in another your post, I'm having the very same problems using Facelets 1.1.7, latest ADF Faces and MyFaces from SVN, and OC4J as app server."], "labels": [0, 0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["In my JBoss environment it's Xerces.", "What alternatives are there?", "Frank Felix -----Original Message----- From: Cosma Colanicchia [mailto:cosmacol@gmail.com]", "Sent: Thursday, June 01, 2006 11:25 AM", "To: adffaces-user@incubator.apache.org Subject: Re: ADF", "Faces component with facelets Frank, as I replied in another your post, I'm having the very same problems using Facelets 1.1.7, latest ADF Faces and MyFaces from SVN, and OC4J as app server.", "Cosma 2006/5/31, Cosma Colanicchia <cosmacol@gmail.com:"], "labels": [0, 0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["What alternatives are there?", "Frank Felix -----Original Message----- From: Cosma Colanicchia [mailto:cosmacol@gmail.com]", "Sent: Thursday, June 01, 2006 11:25 AM", "To: adffaces-user@incubator.apache.org Subject: Re: ADF", "Faces component with facelets Frank, as I replied in another your post, I'm having the very same problems using Facelets 1.1.7, latest ADF Faces and MyFaces from SVN, and OC4J as app server.", "Cosma 2006/5/31, Cosma Colanicchia <cosmacol@gmail.com:", "Ops, it was a typo :-) yes, I mean <f:facet."], "labels": [0, 0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["Sent: Thursday, June 01, 2006 11:25 AM", "To: adffaces-user@incubator.apache.org Subject: Re: ADF", "Faces component with facelets Frank, as I replied in another your post, I'm having the very same problems using Facelets 1.1.7, latest ADF Faces and MyFaces from SVN, and OC4J as app server.", "Cosma 2006/5/31, Cosma Colanicchia <cosmacol@gmail.com:", "Ops, it was a typo :-) yes, I mean <f:facet.", "You're right, I changed the namespace and now it works, thank you very much Noah."], "labels": [0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["To: adffaces-user@incubator.apache.org Subject: Re: ADF", "Faces component with facelets Frank, as I replied in another your post, I'm having the very same problems using Facelets 1.1.7, latest ADF Faces and MyFaces from SVN, and OC4J as app server.", "Cosma 2006/5/31, Cosma Colanicchia <cosmacol@gmail.com:", "Ops, it was a typo :-) yes, I mean <f:facet.", "You're right, I changed the namespace and now it works, thank you very much Noah.", "Cosma 2006/5/31, Sloan, Noah M <Noah_Sloan@baylor.edu:"], "labels": [0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["Cosma 2006/5/31, Cosma Colanicchia <cosmacol@gmail.com:", "Ops, it was a typo :-) yes, I mean <f:facet.", "You're right, I changed the namespace and now it works, thank you very much Noah.", "Cosma 2006/5/31, Sloan, Noah M <Noah_Sloan@baylor.edu:", "Just checking, but you mean 'f:facet' and not 'facelet' right?", "I think the namespace is supposed to be xmlns:", "f=http://java.sun.com/jsf/core"], "labels": [0, 0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["Ops, it was a typo :-) yes, I mean <f:facet.", "You're right, I changed the namespace and now it works, thank you very much Noah.", "Cosma 2006/5/31, Sloan, Noah M <Noah_Sloan@baylor.edu:", "Just checking, but you mean 'f:facet' and not 'facelet' right?", "I think the namespace is supposed to be xmlns:", "f=http://java.sun.com/jsf/core", "________________________________"], "labels": [0, 0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["You're right, I changed the namespace and now it works, thank you very much Noah.", "Cosma 2006/5/31, Sloan, Noah M <Noah_Sloan@baylor.edu:", "Just checking, but you mean 'f:facet' and not 'facelet' right?", "I think the namespace is supposed to be xmlns:", "f=http://java.sun.com/jsf/core", "________________________________", "From: Cosma Colanicchia [mailto:cosmacol@gmail.com]"], "labels": [0, 0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["Cosma 2006/5/31, Sloan, Noah M <Noah_Sloan@baylor.edu:", "Just checking, but you mean 'f:facet' and not 'facelet' right?", "I think the namespace is supposed to be xmlns:", "f=http://java.sun.com/jsf/core", "________________________________", "From: Cosma Colanicchia [mailto:cosmacol@gmail.com]", "Sent: Wed 31-May-06 6:09 AM"], "labels": [0, 0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["Just checking, but you mean 'f:facet' and not 'facelet' right?", "I think the namespace is supposed to be xmlns:", "f=http://java.sun.com/jsf/core", "________________________________", "From: Cosma Colanicchia [mailto:cosmacol@gmail.com]", "Sent: Wed 31-May-06 6:09 AM", "To: adffaces-user@incubator.apache.org Subject: Re: ADF"], "labels": [0, 0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["I think the namespace is supposed to be xmlns:", "f=http://java.sun.com/jsf/core", "________________________________", "From: Cosma Colanicchia [mailto:cosmacol@gmail.com]", "Sent: Wed 31-May-06 6:09 AM", "To: adffaces-user@incubator.apache.org Subject: Re: ADF", "Faces component with facelets I have a problem either with 1.1.7 and 1.0.14."], "labels": [0, 0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["f=http://java.sun.com/jsf/core", "________________________________", "From: Cosma Colanicchia [mailto:cosmacol@gmail.com]", "Sent: Wed 31-May-06 6:09 AM", "To: adffaces-user@incubator.apache.org Subject: Re: ADF", "Faces component with facelets I have a problem either with 1.1.7 and 1.0.14.", "First, I had to manually add to the adf-faces jar the af.taglib."], "labels": [0, 0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["From: Cosma Colanicchia [mailto:cosmacol@gmail.com]", "Sent: Wed 31-May-06 6:09 AM", "To: adffaces-user@incubator.apache.org Subject: Re: ADF", "Faces component with facelets I have a problem either with 1.1.7 and 1.0.14.", "First, I had to manually add to the adf-faces jar the af.taglib.", "xml file from the sources, because there was only yhe afh.taglib.xml one... strange thing.", "Anyway I use the latest sources from apache to build the adf-faces jars."], "labels": [0, 0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["Sent: Wed 31-May-06 6:09 AM", "To: adffaces-user@incubator.apache.org Subject: Re: ADF", "Faces component with facelets I have a problem either with 1.1.7 and 1.0.14.", "First, I had to manually add to the adf-faces jar the af.taglib.", "xml file from the sources, because there was only yhe afh.taglib.xml one... strange thing.", "Anyway I use the latest sources from apache to build the adf-faces jars.", "Now, I have a test page that seems to work, <h:* <af:* <afh:* and <t:* tags get replaced in my output by the generated HTML, but my <f:* ones does not."], "labels": [0, 0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["Faces component with facelets I have a problem either with 1.1.7 and 1.0.14.", "First, I had to manually add to the adf-faces jar the af.taglib.", "xml file from the sources, because there was only yhe afh.taglib.xml one... strange thing.", "Anyway I use the latest sources from apache to build the adf-faces jars.", "Now, I have a test page that seems to work, <h:* <af:* <afh:* and <t:* tags get replaced in my output by the generated HTML, but my <f:* ones does not.", "I have <f:facelets in my output page."], "labels": [0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["First, I had to manually add to the adf-faces jar the af.taglib.", "xml file from the sources, because there was only yhe afh.taglib.xml one... strange thing.", "Anyway I use the latest sources from apache to build the adf-faces jars.", "Now, I have a test page that seems to work, <h:* <af:* <afh:* and <t:* tags get replaced in my output by the generated HTML, but my <f:* ones does not.", "I have <f:facelets in my output page.", "What's wrong?"], "labels": [0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["xml file from the sources, because there was only yhe afh.taglib.xml one... strange thing.", "Anyway I use the latest sources from apache to build the adf-faces jars.", "Now, I have a test page that seems to work, <h:* <af:* <afh:* and <t:* tags get replaced in my output by the generated HTML, but my <f:* ones does not.", "I have <f:facelets in my output page.", "What's wrong?", "This is the libraries I set for my project: adf-faces-api-11-m7-SNAPSHOT.jar adf-faces-impl-11-m7-SNAPSHOT.jar myfaces-api-1.1.4-SNAPSHOT.jar myfaces-impl-1.1.4-SNAPSHOT.jar tomahawk-1.1.4-SNAPSHOT.jar jsf-facelets-1.1.7.jar el-api.jar el-ri.jar commons-beanutils-1.7.0.jar commons-codec-1.3.jar commons-collections-3.1.jar commons-digester-1.6.jar commons-el-1.0.jar commons-fileupload-1.0.jar commons-lang-2.1.jar commons-logging-1.0.4.jar commons-validator-1.1.4.jar jakarta-oro-2.0.7.jar jstl-1.1.0.jar"], "labels": [0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["I have <f:facelets in my output page.", "What's wrong?", "This is the libraries I set for my project: adf-faces-api-11-m7-SNAPSHOT.jar adf-faces-impl-11-m7-SNAPSHOT.jar myfaces-api-1.1.4-SNAPSHOT.jar myfaces-impl-1.1.4-SNAPSHOT.jar tomahawk-1.1.4-SNAPSHOT.jar jsf-facelets-1.1.7.jar el-api.jar el-ri.jar commons-beanutils-1.7.0.jar commons-codec-1.3.jar commons-collections-3.1.jar commons-digester-1.6.jar commons-el-1.0.jar commons-fileupload-1.0.jar commons-lang-2.1.jar commons-logging-1.0.4.jar commons-validator-1.1.4.jar jakarta-oro-2.0.7.jar jstl-1.1.0.jar", "In my facelets page, I declared the namespaces this way: <html xmlns=\"http://www.w3.org/1999/xhtml\" xmlns:ui=\"http://java.sun.com/jsf/facelets\" xmlns:f=\"http://java.sun.com/jsf\" xmlns:h=\"http://java.sun.com/jsf/html\" xmlns:t=\"http://myfaces.apache.org/tomahawk\" xmlns:af=\"http://myfaces.apache.org/adf/faces\" xmlns:afh=\"http://myfaces.apache.org/adf/faces/html\""], "labels": [0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["In my facelets page, I declared the namespaces this way: <html xmlns=\"http://www.w3.org/1999/xhtml\" xmlns:ui=\"http://java.sun.com/jsf/facelets\" xmlns:f=\"http://java.sun.com/jsf\" xmlns:h=\"http://java.sun.com/jsf/html\" xmlns:t=\"http://myfaces.apache.org/tomahawk\" xmlns:af=\"http://myfaces.apache.org/adf/faces\" xmlns:afh=\"http://myfaces.apache.org/adf/faces/html\"", "What's wrong?", "2006/5/31, Cosma Colanicchia <cosmacol@gmail.com: 2006/5/31, Frank Felix Debatin <ffd@gmx.net: I'm was starting with the latest release, 1.1.7, but I'll follow your hint and try 1.0.14 first."], "labels": [0, 0, 0], "abstract_id": 0}
{"sentences": ["What's wrong?", "2006/5/31, Cosma Colanicchia <cosmacol@gmail.com: 2006/5/31, Frank Felix Debatin <ffd@gmx.net: I'm was starting with the latest release, 1.1.7, but I'll follow your hint and try 1.0.14 first.", "I was actually hoping you start with 1.1.x to see if you find the same problems ;-)", "Ok, I promise that, if I can work out without problems 1.0.14, I'll try switch to 1.1.7 :-)", "So, the only required libraries are those for tomahawk and for the sandbox, right?"], "labels": [0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["2006/5/31, Cosma Colanicchia <cosmacol@gmail.com: 2006/5/31, Frank Felix Debatin <ffd@gmx.net: I'm was starting with the latest release, 1.1.7, but I'll follow your hint and try 1.0.14 first.", "I was actually hoping you start with 1.1.x to see if you find the same problems ;-)", "Ok, I promise that, if I can work out without problems 1.0.14, I'll try switch to 1.1.7 :-)", "So, the only required libraries are those for tomahawk and for the sandbox, right?", "The facelets page mentions a tomahawk taglib contribution."], "labels": [0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["I was actually hoping you start with 1.1.x to see if you find the same problems ;-)", "Ok, I promise that, if I can work out without problems 1.0.14, I'll try switch to 1.1.7 :-)", "So, the only required libraries are those for tomahawk and for the sandbox, right?", "The facelets page mentions a tomahawk taglib contribution.", "I'm just using the ADF component, so I can't tell.", "I'll probably leave the tomahawk and sandbox in the future, it seems that ADF Faces has a rather complete feature set.."], "labels": [0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["Ok, I promise that, if I can work out without problems 1.0.14, I'll try switch to 1.1.7 :-)", "So, the only required libraries are those for tomahawk and for the sandbox, right?", "The facelets page mentions a tomahawk taglib contribution.", "I'm just using the ADF component, so I can't tell.", "I'll probably leave the tomahawk and sandbox in the future, it seems that ADF Faces has a rather complete feature set..", "Frank Felix"], "labels": [0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["An OTN there are some articles and documentation about ADF Faces, hasn't Oracle donated them along with the sources?", "2006/6/13, Matthias Wessendorf <matzew@apache.org:", "Hey- there is some *temporary* documentation available ([1]).", "This is basicly the result from a \"mvn site\" call.", "This includes JavaDoc ([2]) and describtion of taglib ([3]).", "There is also a compiled api-jar and a compiled impl-jar online ([4]).", "Temporary means, we are working on continuum based nightly build."], "labels": [0, 0, 1, 0, 1, 1, 0], "abstract_id": 0}
{"sentences": ["2006/6/13, Matthias Wessendorf <matzew@apache.org:", "Hey- there is some *temporary* documentation available ([1]).", "This is basicly the result from a \"mvn site\" call.", "This includes JavaDoc ([2]) and describtion of taglib ([3]).", "There is also a compiled api-jar and a compiled impl-jar online ([4]).", "Temporary means, we are working on continuum based nightly build.", "Stay tuned!"], "labels": [0, 1, 0, 1, 1, 0, 0], "abstract_id": 0}
{"sentences": ["Hey- there is some *temporary* documentation available ([1]).", "This is basicly the result from a \"mvn site\" call.", "This includes JavaDoc ([2]) and describtion of taglib ([3]).", "There is also a compiled api-jar and a compiled impl-jar online ([4]).", "Temporary means, we are working on continuum based nightly build.", "Stay tuned!", "Please note; that the name \"ADF Faces\" will be removed asap!"], "labels": [1, 0, 1, 1, 0, 0, 1], "abstract_id": 0}
{"sentences": ["This is basicly the result from a \"mvn site\" call.", "This includes JavaDoc ([2]) and describtion of taglib ([3]).", "There is also a compiled api-jar and a compiled impl-jar online ([4]).", "Temporary means, we are working on continuum based nightly build.", "Stay tuned!", "Please note; that the name \"ADF Faces\" will be removed asap!", "-Matthias [1]"], "labels": [0, 1, 1, 0, 0, 1, 0], "abstract_id": 0}
{"sentences": ["This includes JavaDoc ([2]) and describtion of taglib ([3]).", "There is also a compiled api-jar and a compiled impl-jar online ([4]).", "Temporary means, we are working on continuum based nightly build.", "Stay tuned!", "Please note; that the name \"ADF Faces\" will be removed asap!", "-Matthias [1]", "http://people.apache.org/~matzew/trinidad_doc/ [2]"], "labels": [1, 1, 0, 0, 1, 0, 0], "abstract_id": 0}
{"sentences": ["There is also a compiled api-jar and a compiled impl-jar online ([4]).", "Temporary means, we are working on continuum based nightly build.", "Stay tuned!", "Please note; that the name \"ADF Faces\" will be removed asap!", "-Matthias [1]", "http://people.apache.org/~matzew/trinidad_doc/ [2]", "http://people.apache.org/~matzew/trinidad_doc/apidocs/index.html [3]", "http://people.apache.org/~matzew/trinidad_doc/tagdoc.html [4]"], "labels": [1, 0, 0, 1, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["Temporary means, we are working on continuum based nightly build.", "Stay tuned!", "Please note; that the name \"ADF Faces\" will be removed asap!", "-Matthias [1]", "http://people.apache.org/~matzew/trinidad_doc/ [2]", "http://people.apache.org/~matzew/trinidad_doc/apidocs/index.html [3]", "http://people.apache.org/~matzew/trinidad_doc/tagdoc.html [4]", "http://people.apache.org/~matzew/trinidad/ -- Matthias Wessendorf Aechterhoek 18 48282 Emsdetten blog: http://jroller.com/page/mwessendorf mail: mwessendorf-at-gmail-dot-com"], "labels": [0, 0, 1, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["Hi, I had a look and indeed could reproduce that issue.", "In order to customize the log config, we need to include an arbitrary directory in the classpath of s4 nodes, so we can place logback.", "xml there.", "The classpath for s4 nodes is given by a generated script (check s4 file and linked s4-tools file), and apparently (maybe due to some gradle update) the generated classpath does not include the lib directory anymore, only the jars it contains.", "So that's a bug.", "Workaround would be to manually modify the s4-tools script and include an arbitrary directory in the CLASSPATH variable."], "labels": [0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["In order to customize the log config, we need to include an arbitrary directory in the classpath of s4 nodes, so we can place logback.", "xml there.", "The classpath for s4 nodes is given by a generated script (check s4 file and linked s4-tools file), and apparently (maybe due to some gradle update) the generated classpath does not include the lib directory anymore, only the jars it contains.", "So that's a bug.", "Workaround would be to manually modify the s4-tools script and include an arbitrary directory in the CLASSPATH variable.", "You could do that from a generated binary distribution so you don't have to worry about getting the s4-tools file rewritten."], "labels": [0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["xml there.", "The classpath for s4 nodes is given by a generated script (check s4 file and linked s4-tools file), and apparently (maybe due to some gradle update) the generated classpath does not include the lib directory anymore, only the jars it contains.", "So that's a bug.", "Workaround would be to manually modify the s4-tools script and include an arbitrary directory in the CLASSPATH variable.", "You could do that from a generated binary distribution so you don't have to worry about getting the s4-tools file rewritten.", "Hope this helps, Matthieu On Aug 30, 2013, at 17:19 , Yago <iamxami@gmail.com wrote: Hello all I'm having problems with log configuration in my s4 apps."], "labels": [0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["So that's a bug.", "Workaround would be to manually modify the s4-tools script and include an arbitrary directory in the CLASSPATH variable.", "You could do that from a generated binary distribution so you don't have to worry about getting the s4-tools file rewritten.", "Hope this helps, Matthieu On Aug 30, 2013, at 17:19 , Yago <iamxami@gmail.com wrote: Hello all I'm having problems with log configuration in my s4 apps.", "Have tried a lot of things in order to change the default behaviour of logback, but none of them worked.", "These were my attempts (some of them might look a bit strange or desperate): - Put logback.xml in subprojects/s4-tools/build/install/s4-tools/lib/ directory as suggested in doc, and even in lib/ directory."], "labels": [0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["You could do that from a generated binary distribution so you don't have to worry about getting the s4-tools file rewritten.", "Hope this helps, Matthieu On Aug 30, 2013, at 17:19 , Yago <iamxami@gmail.com wrote: Hello all I'm having problems with log configuration in my s4 apps.", "Have tried a lot of things in order to change the default behaviour of logback, but none of them worked.", "These were my attempts (some of them might look a bit strange or desperate): - Put logback.xml in subprojects/s4-tools/build/install/s4-tools/lib/ directory as suggested in doc, and even in lib/ directory.", "- Edited all the logback."], "labels": [0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["Hope this helps, Matthieu On Aug 30, 2013, at 17:19 , Yago <iamxami@gmail.com wrote: Hello all I'm having problems with log configuration in my s4 apps.", "Have tried a lot of things in order to change the default behaviour of logback, but none of them worked.", "These were my attempts (some of them might look a bit strange or desperate): - Put logback.xml in subprojects/s4-tools/build/install/s4-tools/lib/ directory as suggested in doc, and even in lib/ directory.", "- Edited all the logback.", "xml files in my s4 directory, changing level and/or pattern - Edited all the default.s4.core."], "labels": [0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["Have tried a lot of things in order to change the default behaviour of logback, but none of them worked.", "These were my attempts (some of them might look a bit strange or desperate): - Put logback.xml in subprojects/s4-tools/build/install/s4-tools/lib/ directory as suggested in doc, and even in lib/ directory.", "- Edited all the logback.", "xml files in my s4 directory, changing level and/or pattern - Edited all the default.s4.core.", "properties files, changing level - Added both files to my application in /src/main/resources/ directory, so they are included in the built jar (checked)."], "labels": [0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["These were my attempts (some of them might look a bit strange or desperate): - Put logback.xml in subprojects/s4-tools/build/install/s4-tools/lib/ directory as suggested in doc, and even in lib/ directory.", "- Edited all the logback.", "xml files in my s4 directory, changing level and/or pattern - Edited all the default.s4.core.", "properties files, changing level - Added both files to my application in /src/main/resources/ directory, so they are included in the built jar (checked).", "No result."], "labels": [0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["- Edited all the logback.", "xml files in my s4 directory, changing level and/or pattern - Edited all the default.s4.core.", "properties files, changing level - Added both files to my application in /src/main/resources/ directory, so they are included in the built jar (checked).", "No result.", "- Tried to pass s4.logger_level=info as a parameter in node start.", "A received an exception from ParametersInjectionModule: property already configured.", "- Tried to pass that parameter in s4r deploy."], "labels": [0, 0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["xml files in my s4 directory, changing level and/or pattern - Edited all the default.s4.core.", "properties files, changing level - Added both files to my application in /src/main/resources/ directory, so they are included in the built jar (checked).", "No result.", "- Tried to pass s4.logger_level=info as a parameter in node start.", "A received an exception from ParametersInjectionModule: property already configured.", "- Tried to pass that parameter in s4r deploy.", "Nothing changed."], "labels": [0, 0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["properties files, changing level - Added both files to my application in /src/main/resources/ directory, so they are included in the built jar (checked).", "No result.", "- Tried to pass s4.logger_level=info as a parameter in node start.", "A received an exception from ParametersInjectionModule: property already configured.", "- Tried to pass that parameter in s4r deploy.", "Nothing changed.", "My actual s4 version is 0.6.0 final, built from src (was 0.5.0 but updated myself because of this!)"], "labels": [0, 0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["No result.", "- Tried to pass s4.logger_level=info as a parameter in node start.", "A received an exception from ParametersInjectionModule: property already configured.", "- Tried to pass that parameter in s4r deploy.", "Nothing changed.", "My actual s4 version is 0.6.0 final, built from src (was 0.5.0 but updated myself because of this!)", "Any ideas?", "maybe I'm going with log4j..."], "labels": [0, 0, 0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["- Tried to pass s4.logger_level=info as a parameter in node start.", "A received an exception from ParametersInjectionModule: property already configured.", "- Tried to pass that parameter in s4r deploy.", "Nothing changed.", "My actual s4 version is 0.6.0 final, built from src (was 0.5.0 but updated myself because of this!)", "Any ideas?", "maybe I'm going with log4j...", "Thanks + Regards"], "labels": [0, 0, 0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["The announce@myfaces.apache.org link shows no posts since 2014.", "https://lists.apache.org/list.html?announce@myfaces.apache.org:2016-09", "Compare with http://mail-archives.apache.org/mod_mbox/myfaces-announce/201609.mbox/browser", "Should I open a bug report or is this some kind of \"user error\" issue that I'm experiencing?", "Note that I'm not subscribed to users@ponymail, so please cc mkienenb@gmail.com or mkienenb@apache.org on any responses.", "Thanks, Mike"], "labels": [0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["* I hope this will be of interest to people using Taverna in the drug discovery arena.", "You may be interested to hear that we are organising a session on workflow tools in the Division of Chemical Information (CINF) at the American Chemical Society Fall 2015 National Meeting in Boston, Massachusetts.", "The title of the symposium is “Workflow Tools & Data Pipelining in Drug Discovery” and will comprise a series oral presentations.", "The meeting takes place on August 16-20.", "Full details of the program can be found here: http://www.acs.org/content/acs/en/meetings/abstract-submissions/acsnm250/division-of-chemical-information.html", "We would are keen to have an exciting set of talks for this session, and hope you might be interested in participating."], "labels": [0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["The title of the symposium is “Workflow Tools & Data Pipelining in Drug Discovery” and will comprise a series oral presentations.", "The meeting takes place on August 16-20.", "Full details of the program can be found here: http://www.acs.org/content/acs/en/meetings/abstract-submissions/acsnm250/division-of-chemical-information.html", "We would are keen to have an exciting set of talks for this session, and hope you might be interested in participating.", "To do so we ask you need to submit an abstract by March 12.", "We are expecting the session to cover a number of aspects of workflow tools, such as * the types of problem being solved * the approaches used * the technical solution chosen * the hurdles that had to be overcome * scalability and performance aspects * issues with deploying the solution to others * the balance between manual and automated approaches Please also note that there is a separate lightning session that will allow products and solutions in this area to be presented."], "labels": [0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["The meeting takes place on August 16-20.", "Full details of the program can be found here: http://www.acs.org/content/acs/en/meetings/abstract-submissions/acsnm250/division-of-chemical-information.html", "We would are keen to have an exciting set of talks for this session, and hope you might be interested in participating.", "To do so we ask you need to submit an abstract by March 12.", "We are expecting the session to cover a number of aspects of workflow tools, such as * the types of problem being solved * the approaches used * the technical solution chosen * the hurdles that had to be overcome * scalability and performance aspects * issues with deploying the solution to others * the balance between manual and automated approaches Please also note that there is a separate lightning session that will allow products and solutions in this area to be presented.", "You might well want to participate in both sessions."], "labels": [0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["We would are keen to have an exciting set of talks for this session, and hope you might be interested in participating.", "To do so we ask you need to submit an abstract by March 12.", "We are expecting the session to cover a number of aspects of workflow tools, such as * the types of problem being solved * the approaches used * the technical solution chosen * the hurdles that had to be overcome * scalability and performance aspects * issues with deploying the solution to others * the balance between manual and automated approaches Please also note that there is a separate lightning session that will allow products and solutions in this area to be presented.", "You might well want to participate in both sessions.", "Finally, if you think this might be of interest to others, then please pass the message on."], "labels": [0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["To do so we ask you need to submit an abstract by March 12.", "We are expecting the session to cover a number of aspects of workflow tools, such as * the types of problem being solved * the approaches used * the technical solution chosen * the hurdles that had to be overcome * scalability and performance aspects * issues with deploying the solution to others * the balance between manual and automated approaches Please also note that there is a separate lightning session that will allow products and solutions in this area to be presented.", "You might well want to participate in both sessions.", "Finally, if you think this might be of interest to others, then please pass the message on.", "Hoping we might see you in Boston in August."], "labels": [0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["We are expecting the session to cover a number of aspects of workflow tools, such as * the types of problem being solved * the approaches used * the technical solution chosen * the hurdles that had to be overcome * scalability and performance aspects * issues with deploying the solution to others * the balance between manual and automated approaches Please also note that there is a separate lightning session that will allow products and solutions in this area to be presented.", "You might well want to participate in both sessions.", "Finally, if you think this might be of interest to others, then please pass the message on.", "Hoping we might see you in Boston in August.", "Tim Dudgeon *"], "labels": [0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["Hi, Newbie question...", "I have my own file format.", "The files are saved on HDFS.", "I would like HCatalog to facilitate to read those files by Hive.", "Something like: Hive | HCatalog | MyFiles", "Where should I start with?", "Is there any sample integration of other File formats which I can use a reference?", "-- Cheers, *Subroto Sanyal*"], "labels": [0, 0, 0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["Dear podling,", "This email was sent by an automated system on behalf of the Apache Incubator PMC.", "It is an initial reminder to give you plenty of time to prepare your quarterly board report.", "The board meeting is scheduled for Wed, 18 January 2017, 10:30 am PDT.", "The report for your podling will form a part of the Incubator PMC report.", "The Incubator PMC requires your report to be submitted 2 weeks before the board meeting, to allow sufficient time for review and submission (Wed, January 04).", "Please submit your report with sufficient time to allow the Incubator PMC, and subsequently board members to review and digest."], "labels": [0, 1, 1, 0, 1, 1, 1], "abstract_id": 0}
{"sentences": ["This email was sent by an automated system on behalf of the Apache Incubator PMC.", "It is an initial reminder to give you plenty of time to prepare your quarterly board report.", "The board meeting is scheduled for Wed, 18 January 2017, 10:30 am PDT.", "The report for your podling will form a part of the Incubator PMC report.", "The Incubator PMC requires your report to be submitted 2 weeks before the board meeting, to allow sufficient time for review and submission (Wed, January 04).", "Please submit your report with sufficient time to allow the Incubator PMC, and subsequently board members to review and digest.", "Again, the very latest you should submit your report is 2 weeks prior to the board meeting."], "labels": [1, 1, 0, 1, 1, 1, 1], "abstract_id": 0}
{"sentences": ["The board meeting is scheduled for Wed, 18 January 2017, 10:30 am PDT.", "The report for your podling will form a part of the Incubator PMC report.", "The Incubator PMC requires your report to be submitted 2 weeks before the board meeting, to allow sufficient time for review and submission (Wed, January 04).", "Please submit your report with sufficient time to allow the Incubator PMC, and subsequently board members to review and digest.", "Again, the very latest you should submit your report is 2 weeks prior to the board meeting.", "Thanks,"], "labels": [0, 1, 1, 1, 1, 0], "abstract_id": 0}
{"sentences": ["The report for your podling will form a part of the Incubator PMC report.", "The Incubator PMC requires your report to be submitted 2 weeks before the board meeting, to allow sufficient time for review and submission (Wed, January 04).", "Please submit your report with sufficient time to allow the Incubator PMC, and subsequently board members to review and digest.", "Again, the very latest you should submit your report is 2 weeks prior to the board meeting.", "Thanks,", "The Apache Incubator PMC Submitting your Report ----------------------"], "labels": [1, 1, 1, 1, 0, 0], "abstract_id": 0}
{"sentences": ["The Incubator PMC requires your report to be submitted 2 weeks before the board meeting, to allow sufficient time for review and submission (Wed, January 04).", "Please submit your report with sufficient time to allow the Incubator PMC, and subsequently board members to review and digest.", "Again, the very latest you should submit your report is 2 weeks prior to the board meeting.", "Thanks,", "The Apache Incubator PMC Submitting your Report ----------------------", "Your report should contain the following: *"], "labels": [1, 1, 1, 0, 0, 1], "abstract_id": 0}
{"sentences": ["Please submit your report with sufficient time to allow the Incubator PMC, and subsequently board members to review and digest.", "Again, the very latest you should submit your report is 2 weeks prior to the board meeting.", "Thanks,", "The Apache Incubator PMC Submitting your Report ----------------------", "Your report should contain the following: *", "Your project name *", "A brief description of your project, which assumes no knowledge of the project or necessarily of its field *"], "labels": [1, 1, 0, 0, 1, 1, 1], "abstract_id": 0}
{"sentences": ["Again, the very latest you should submit your report is 2 weeks prior to the board meeting.", "Thanks,", "The Apache Incubator PMC Submitting your Report ----------------------", "Your report should contain the following: *", "Your project name *", "A brief description of your project, which assumes no knowledge of the project or necessarily of its field *", "A list of the three most important issues to address in the move towards graduation.", "*"], "labels": [1, 0, 0, 1, 1, 1, 1, 1], "abstract_id": 0}
{"sentences": ["Thanks,", "The Apache Incubator PMC Submitting your Report ----------------------", "Your report should contain the following: *", "Your project name *", "A brief description of your project, which assumes no knowledge of the project or necessarily of its field *", "A list of the three most important issues to address in the move towards graduation.", "*", "Any issues that the Incubator PMC or ASF Board might wish/need to be aware of *"], "labels": [0, 0, 1, 1, 1, 1, 1, 1], "abstract_id": 0}
{"sentences": ["Your report should contain the following: *", "Your project name *", "A brief description of your project, which assumes no knowledge of the project or necessarily of its field *", "A list of the three most important issues to address in the move towards graduation.", "*", "Any issues that the Incubator PMC or ASF Board might wish/need to be aware of *", "How has the community developed since the last report *", "How has the project developed since the last report.", "This should be appended to the Incubator Wiki page at: https://wiki.apache.org/incubator/January2017"], "labels": [1, 1, 1, 1, 1, 1, 1, 1, 1], "abstract_id": 0}
{"sentences": ["A brief description of your project, which assumes no knowledge of the project or necessarily of its field *", "A list of the three most important issues to address in the move towards graduation.", "*", "Any issues that the Incubator PMC or ASF Board might wish/need to be aware of *", "How has the community developed since the last report *", "How has the project developed since the last report.", "This should be appended to the Incubator Wiki page at: https://wiki.apache.org/incubator/January2017", "Note: This is manually populated."], "labels": [1, 1, 1, 1, 1, 1, 1, 0], "abstract_id": 0}
{"sentences": ["A list of the three most important issues to address in the move towards graduation.", "*", "Any issues that the Incubator PMC or ASF Board might wish/need to be aware of *", "How has the community developed since the last report *", "How has the project developed since the last report.", "This should be appended to the Incubator Wiki page at: https://wiki.apache.org/incubator/January2017", "Note: This is manually populated.", "You may need to wait a little before this page is created from a template."], "labels": [1, 1, 1, 1, 1, 1, 0, 1], "abstract_id": 0}
{"sentences": ["*", "Any issues that the Incubator PMC or ASF Board might wish/need to be aware of *", "How has the community developed since the last report *", "How has the project developed since the last report.", "This should be appended to the Incubator Wiki page at: https://wiki.apache.org/incubator/January2017", "Note: This is manually populated.", "You may need to wait a little before this page is created from a template.", "Mentors ------- Mentors should review reports for their project(s) and sign them off on the Incubator wiki page."], "labels": [1, 1, 1, 1, 1, 0, 1, 0], "abstract_id": 0}
{"sentences": ["How has the community developed since the last report *", "How has the project developed since the last report.", "This should be appended to the Incubator Wiki page at: https://wiki.apache.org/incubator/January2017", "Note: This is manually populated.", "You may need to wait a little before this page is created from a template.", "Mentors ------- Mentors should review reports for their project(s) and sign them off on the Incubator wiki page.", "Signing off reports shows that you are following the project - projects that are not signed may raise alarms for the Incubator PMC."], "labels": [1, 1, 1, 0, 1, 0, 1], "abstract_id": 0}
{"sentences": ["How has the project developed since the last report.", "This should be appended to the Incubator Wiki page at: https://wiki.apache.org/incubator/January2017", "Note: This is manually populated.", "You may need to wait a little before this page is created from a template.", "Mentors ------- Mentors should review reports for their project(s) and sign them off on the Incubator wiki page.", "Signing off reports shows that you are following the project - projects that are not signed may raise alarms for the Incubator PMC.", "Incubator PMC"], "labels": [1, 1, 0, 1, 0, 1, 1], "abstract_id": 0}
{"sentences": ["Should clarify this occurs when a dagrun does not have a start date, not a dag (which makes it even less likely to happen).", "I don't think this is a blocker for releasing.", "On Wed, Feb 22, 2017 at 1:15 PM, Dan Davydov <dan.davydov@airbnb.com wrote: I rolled this out in our prod and the webservers failed to load due to this commit: [AIRFLOW-510]", "Filter Paused Dags, show Last Run & Trigger Dag 7c94d81c390881643f94d5e3d7d6fb351a445b72", "This fixed it: - </a <span id=\"statuses_info\" class=\"glyphicon glyphicon-info-sign\" aria-hidden=\"true\" title=\"Start Date: {{last_run.start_date.strftime('%Y-%m-%d %H:%M')}}\"</span + </a <span id=\"statuses_info\" class=\"glyphicon glyphicon-info-sign\" aria-hidden=\"true\"</span"], "labels": [0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["I don't think this is a blocker for releasing.", "On Wed, Feb 22, 2017 at 1:15 PM, Dan Davydov <dan.davydov@airbnb.com wrote: I rolled this out in our prod and the webservers failed to load due to this commit: [AIRFLOW-510]", "Filter Paused Dags, show Last Run & Trigger Dag 7c94d81c390881643f94d5e3d7d6fb351a445b72", "This fixed it: - </a <span id=\"statuses_info\" class=\"glyphicon glyphicon-info-sign\" aria-hidden=\"true\" title=\"Start Date: {{last_run.start_date.strftime('%Y-%m-%d %H:%M')}}\"</span + </a <span id=\"statuses_info\" class=\"glyphicon glyphicon-info-sign\" aria-hidden=\"true\"</span", "This is caused by assuming that all DAGs have start dates set, so a broken DAG will take down the whole UI."], "labels": [0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["Filter Paused Dags, show Last Run & Trigger Dag 7c94d81c390881643f94d5e3d7d6fb351a445b72", "This fixed it: - </a <span id=\"statuses_info\" class=\"glyphicon glyphicon-info-sign\" aria-hidden=\"true\" title=\"Start Date: {{last_run.start_date.strftime('%Y-%m-%d %H:%M')}}\"</span + </a <span id=\"statuses_info\" class=\"glyphicon glyphicon-info-sign\" aria-hidden=\"true\"</span", "This is caused by assuming that all DAGs have start dates set, so a broken DAG will take down the whole UI.", "Not sure if we want to make this a blocker for the release or not, I'm guessing for most deployments this would occur pretty rarely."], "labels": [0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["This fixed it: - </a <span id=\"statuses_info\" class=\"glyphicon glyphicon-info-sign\" aria-hidden=\"true\" title=\"Start Date: {{last_run.start_date.strftime('%Y-%m-%d %H:%M')}}\"</span + </a <span id=\"statuses_info\" class=\"glyphicon glyphicon-info-sign\" aria-hidden=\"true\"</span", "This is caused by assuming that all DAGs have start dates set, so a broken DAG will take down the whole UI.", "Not sure if we want to make this a blocker for the release or not, I'm guessing for most deployments this would occur pretty rarely.", "I'll submit a PR to fix it soon."], "labels": [0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["This is caused by assuming that all DAGs have start dates set, so a broken DAG will take down the whole UI.", "Not sure if we want to make this a blocker for the release or not, I'm guessing for most deployments this would occur pretty rarely.", "I'll submit a PR to fix it soon.", "On Tue, Feb 21, 2017 at 9:49 AM, Chris Riccomini <criccomini@apache.org wrote: Ack that the vote has already passed, but belated +1 (binding) On Tue, Feb 21, 2017 at 7:42 AM, Bolke de Bruin <bdbruin@gmail.com wrote: IPMC Voting can be found here: http://mail-archives.apache.org/mod_mbox/incubator-general/ 201702.mbox/% 3c676BDC9F-1B55-4469-92A7-9FF309AD0EC8@gmail.com%3e < http://mail-archives.apache.org/mod_mbox/incubator-general/ 201702.mbox/% 3C676BDC9F-1B55-4469-92A7-9FF309AD0EC8@gmail.com%3E", "Kind regards, Bolke On 21 Feb 2017, at 08:20, Bolke de Bruin <bdbruin@gmail.com wrote: Hello, Apache Airflow (incubating) 1.8.0 (based on RC4) has been accepted."], "labels": [0, 0, 0, 1, 0], "abstract_id": 0}
{"sentences": ["Kind regards, Bolke On 21 Feb 2017, at 08:20, Bolke de Bruin <bdbruin@gmail.com wrote: Hello, Apache Airflow (incubating) 1.8.0 (based on RC4) has been accepted.", "9 “+1” votes received: - Maxime Beauchemin (binding) - Arthur Wiedmer (binding) - Dan Davydov (binding) - Jeremiah Lowin (binding) - Siddharth Anand (binding) - Alex van Boxel (binding) - Bolke de Bruin (binding) - Jayesh Senjaliya (non-binding) - Yi (non-binding) Vote thread (start): http://mail-archives.apache.org/mod_mbox/incubator- airflow-dev/201702.mbox/%3cD360D9BE-C358-42A1-9188- 6C92C31A2F8B@gmail.com%3e <http://mail-archives.apache.", "org/mod_mbox/incubator-airflow-dev/201702.mbox/%3C7EB7B6D6- 092E-48D2-AA0F- 15F44376A8FF@gmail.com%3E"], "labels": [0, 0, 0], "abstract_id": 0}
{"sentences": ["9 “+1” votes received: - Maxime Beauchemin (binding) - Arthur Wiedmer (binding) - Dan Davydov (binding) - Jeremiah Lowin (binding) - Siddharth Anand (binding) - Alex van Boxel (binding) - Bolke de Bruin (binding) - Jayesh Senjaliya (non-binding) - Yi (non-binding) Vote thread (start): http://mail-archives.apache.org/mod_mbox/incubator- airflow-dev/201702.mbox/%3cD360D9BE-C358-42A1-9188- 6C92C31A2F8B@gmail.com%3e <http://mail-archives.apache.", "org/mod_mbox/incubator-airflow-dev/201702.mbox/%3C7EB7B6D6- 092E-48D2-AA0F- 15F44376A8FF@gmail.com%3E", "Next steps: 1) will start the voting process at the IPMC mailinglist."], "labels": [0, 0, 1], "abstract_id": 0}
{"sentences": ["org/mod_mbox/incubator-airflow-dev/201702.mbox/%3C7EB7B6D6- 092E-48D2-AA0F- 15F44376A8FF@gmail.com%3E", "Next steps: 1) will start the voting process at the IPMC mailinglist.", "I do expect some changes to be required mostly in documentation maybe a license here and there.", "So, we might end up with changes to stable.", "As long as these are not (significant) code changes I will not re-raise the vote."], "labels": [0, 1, 0, 1, 0], "abstract_id": 0}
{"sentences": ["Next steps: 1) will start the voting process at the IPMC mailinglist.", "I do expect some changes to be required mostly in documentation maybe a license here and there.", "So, we might end up with changes to stable.", "As long as these are not (significant) code changes I will not re-raise the vote.", "2) Only after the positive voting on the IPMC and finalisation I will rebrand the RC to Release.", "3) I will upload it to the incubator release page, then the tar ball needs to propagate to the mirrors.", "4) Update the website (can someone volunteer please?)"], "labels": [1, 0, 1, 0, 1, 0, 1], "abstract_id": 0}
{"sentences": ["I do expect some changes to be required mostly in documentation maybe a license here and there.", "So, we might end up with changes to stable.", "As long as these are not (significant) code changes I will not re-raise the vote.", "2) Only after the positive voting on the IPMC and finalisation I will rebrand the RC to Release.", "3) I will upload it to the incubator release page, then the tar ball needs to propagate to the mirrors.", "4) Update the website (can someone volunteer please?)", "5) Finally, I will ask Maxime to upload it to pypi."], "labels": [0, 1, 0, 1, 0, 1, 0], "abstract_id": 0}
{"sentences": ["So, we might end up with changes to stable.", "As long as these are not (significant) code changes I will not re-raise the vote.", "2) Only after the positive voting on the IPMC and finalisation I will rebrand the RC to Release.", "3) I will upload it to the incubator release page, then the tar ball needs to propagate to the mirrors.", "4) Update the website (can someone volunteer please?)", "5) Finally, I will ask Maxime to upload it to pypi.", "It seems we can keep the apache branding as lib cloud is doing this as well ( https://libcloud.apache.org/downloads.html#pypi-package < https://libcloud.apache.org/downloads.html#pypi-package)."], "labels": [1, 0, 1, 0, 1, 0, 1], "abstract_id": 0}
{"sentences": ["2) Only after the positive voting on the IPMC and finalisation I will rebrand the RC to Release.", "3) I will upload it to the incubator release page, then the tar ball needs to propagate to the mirrors.", "4) Update the website (can someone volunteer please?)", "5) Finally, I will ask Maxime to upload it to pypi.", "It seems we can keep the apache branding as lib cloud is doing this as well ( https://libcloud.apache.org/downloads.html#pypi-package < https://libcloud.apache.org/downloads.html#pypi-package).", "Jippie!"], "labels": [1, 0, 1, 0, 1, 0], "abstract_id": 0}
{"sentences": ["3) I will upload it to the incubator release page, then the tar ball needs to propagate to the mirrors.", "4) Update the website (can someone volunteer please?)", "5) Finally, I will ask Maxime to upload it to pypi.", "It seems we can keep the apache branding as lib cloud is doing this as well ( https://libcloud.apache.org/downloads.html#pypi-package < https://libcloud.apache.org/downloads.html#pypi-package).", "Jippie!", "Bolke"], "labels": [0, 1, 0, 1, 0, 0], "abstract_id": 0}
{"sentences": ["Thanks Aaron, for the clarification Detecting row hotspots and isolating them to private shards is a pretty useful feature in production.", "-- Ravi On Fri, Sep 27, 2013 at 5:08 PM, Aaron McCurry <amccurry@gmail.com wrote: Ravi,", "You can definitely walk through the row ids in blur and detect how many records are within the given row.", "But there is no built-in way to detect the size of a given row including the size of a record without fetching the row for inspection.", "This sounds like it could be a useful feature to detect row hotspots in the shards.", "The current scheme for distributing data is through the BlurPartitioner and it is a basic hash of the rowid."], "labels": [0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["-- Ravi On Fri, Sep 27, 2013 at 5:08 PM, Aaron McCurry <amccurry@gmail.com wrote: Ravi,", "You can definitely walk through the row ids in blur and detect how many records are within the given row.", "But there is no built-in way to detect the size of a given row including the size of a record without fetching the row for inspection.", "This sounds like it could be a useful feature to detect row hotspots in the shards.", "The current scheme for distributing data is through the BlurPartitioner and it is a basic hash of the rowid.", "So that should provide a fairly even distribution of rows but with no regard to the row's size or the size of the shard."], "labels": [0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["You can definitely walk through the row ids in blur and detect how many records are within the given row.", "But there is no built-in way to detect the size of a given row including the size of a record without fetching the row for inspection.", "This sounds like it could be a useful feature to detect row hotspots in the shards.", "The current scheme for distributing data is through the BlurPartitioner and it is a basic hash of the rowid.", "So that should provide a fairly even distribution of rows but with no regard to the row's size or the size of the shard.", "In 0.3.0 we will be beginning to expose internal APIs that should allow for more control of the shard layout in the cluster (meaning what machine it is beginning served from)."], "labels": [0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["But there is no built-in way to detect the size of a given row including the size of a record without fetching the row for inspection.", "This sounds like it could be a useful feature to detect row hotspots in the shards.", "The current scheme for distributing data is through the BlurPartitioner and it is a basic hash of the rowid.", "So that should provide a fairly even distribution of rows but with no regard to the row's size or the size of the shard.", "In 0.3.0 we will be beginning to expose internal APIs that should allow for more control of the shard layout in the cluster (meaning what machine it is beginning served from).", "We also have a task to deal with large rows in a better way."], "labels": [0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["This sounds like it could be a useful feature to detect row hotspots in the shards.", "The current scheme for distributing data is through the BlurPartitioner and it is a basic hash of the rowid.", "So that should provide a fairly even distribution of rows but with no regard to the row's size or the size of the shard.", "In 0.3.0 we will be beginning to expose internal APIs that should allow for more control of the shard layout in the cluster (meaning what machine it is beginning served from).", "We also have a task to deal with large rows in a better way.", "https://issues.apache.org/jira/browse/BLUR-220 Aaron On Thu, Sep 26, 2013 at 9:30 PM, Ravikumar Govindarajan < ravikumar.govindarajan@gmail.com wrote: Hi,"], "labels": [0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["The current scheme for distributing data is through the BlurPartitioner and it is a basic hash of the rowid.", "So that should provide a fairly even distribution of rows but with no regard to the row's size or the size of the shard.", "In 0.3.0 we will be beginning to expose internal APIs that should allow for more control of the shard layout in the cluster (meaning what machine it is beginning served from).", "We also have a task to deal with large rows in a better way.", "https://issues.apache.org/jira/browse/BLUR-220 Aaron On Thu, Sep 26, 2013 at 9:30 PM, Ravikumar Govindarajan < ravikumar.govindarajan@gmail.com wrote: Hi,", "The statistics are as follows 1. Few hundreds of users - 1-10 GB of indexes 2."], "labels": [0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["In 0.3.0 we will be beginning to expose internal APIs that should allow for more control of the shard layout in the cluster (meaning what machine it is beginning served from).", "We also have a task to deal with large rows in a better way.", "https://issues.apache.org/jira/browse/BLUR-220 Aaron On Thu, Sep 26, 2013 at 9:30 PM, Ravikumar Govindarajan < ravikumar.govindarajan@gmail.com wrote: Hi,", "The statistics are as follows 1. Few hundreds of users - 1-10 GB of indexes 2.", "Few thousands of users - 100 MB - 1 GB of indexes 3. All others - < 100 MB of indexes"], "labels": [0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["We also have a task to deal with large rows in a better way.", "https://issues.apache.org/jira/browse/BLUR-220 Aaron On Thu, Sep 26, 2013 at 9:30 PM, Ravikumar Govindarajan < ravikumar.govindarajan@gmail.com wrote: Hi,", "The statistics are as follows 1. Few hundreds of users - 1-10 GB of indexes 2.", "Few thousands of users - 100 MB - 1 GB of indexes 3. All others - < 100 MB of indexes", "The system has very few heavy-weight users, a little more middle-weight and then lots of light-weight users.", "Yes, like you had said I might need to split my row-keys internally for handling large data per-user."], "labels": [0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["The statistics are as follows 1. Few hundreds of users - 1-10 GB of indexes 2.", "Few thousands of users - 100 MB - 1 GB of indexes 3. All others - < 100 MB of indexes", "The system has very few heavy-weight users, a little more middle-weight and then lots of light-weight users.", "Yes, like you had said I might need to split my row-keys internally for handling large data per-user.", "The problem with such an approach is that IDF will get distributed for a rowId, impacting either scores or response times.", "Alternatively, I was looking at periodically running schedules to detect the size of a row for a given user and then isolate the heavy-weights to a separate shard."], "labels": [0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["Few thousands of users - 100 MB - 1 GB of indexes 3. All others - < 100 MB of indexes", "The system has very few heavy-weight users, a little more middle-weight and then lots of light-weight users.", "Yes, like you had said I might need to split my row-keys internally for handling large data per-user.", "The problem with such an approach is that IDF will get distributed for a rowId, impacting either scores or response times.", "Alternatively, I was looking at periodically running schedules to detect the size of a row for a given user and then isolate the heavy-weights to a separate shard.", "Is such an operation supported in Blur? -- Ravi On Thu, Sep 26, 2013 at 5:56 PM, Garrett Barton < garrett.barton@gmail.com wrote: First thing I can think of is to not use your userid key directly for the rowid."], "labels": [0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["The system has very few heavy-weight users, a little more middle-weight and then lots of light-weight users.", "Yes, like you had said I might need to split my row-keys internally for handling large data per-user.", "The problem with such an approach is that IDF will get distributed for a rowId, impacting either scores or response times.", "Alternatively, I was looking at periodically running schedules to detect the size of a row for a given user and then isolate the heavy-weights to a separate shard.", "Is such an operation supported in Blur? -- Ravi On Thu, Sep 26, 2013 at 5:56 PM, Garrett Barton < garrett.barton@gmail.com wrote: First thing I can think of is to not use your userid key directly for the rowid.", "Instead hash/encrypt or a combination of the two to guarantee more evenly partitioned keys thus making the shards more even."], "labels": [0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["The problem with such an approach is that IDF will get distributed for a rowId, impacting either scores or response times.", "Alternatively, I was looking at periodically running schedules to detect the size of a row for a given user and then isolate the heavy-weights to a separate shard.", "Is such an operation supported in Blur? -- Ravi On Thu, Sep 26, 2013 at 5:56 PM, Garrett Barton < garrett.barton@gmail.com wrote: First thing I can think of is to not use your userid key directly for the rowid.", "Instead hash/encrypt or a combination of the two to guarantee more evenly partitioned keys thus making the shards more even.", "Second thing that comes to mind is to periodically rebuild the index from scratch and up the number of shards."], "labels": [0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["Alternatively, I was looking at periodically running schedules to detect the size of a row for a given user and then isolate the heavy-weights to a separate shard.", "Is such an operation supported in Blur? -- Ravi On Thu, Sep 26, 2013 at 5:56 PM, Garrett Barton < garrett.barton@gmail.com wrote: First thing I can think of is to not use your userid key directly for the rowid.", "Instead hash/encrypt or a combination of the two to guarantee more evenly partitioned keys thus making the shards more even.", "Second thing that comes to mind is to periodically rebuild the index from scratch and up the number of shards.", "How many rows are you expecting per user?"], "labels": [0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["Is such an operation supported in Blur? -- Ravi On Thu, Sep 26, 2013 at 5:56 PM, Garrett Barton < garrett.barton@gmail.com wrote: First thing I can think of is to not use your userid key directly for the rowid.", "Instead hash/encrypt or a combination of the two to guarantee more evenly partitioned keys thus making the shards more even.", "Second thing that comes to mind is to periodically rebuild the index from scratch and up the number of shards.", "How many rows are you expecting per user?", "Avg row width?"], "labels": [0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["Instead hash/encrypt or a combination of the two to guarantee more evenly partitioned keys thus making the shards more even.", "Second thing that comes to mind is to periodically rebuild the index from scratch and up the number of shards.", "How many rows are you expecting per user?", "Avg row width?", "~Garrett On Thu, Sep 26, 2013 at 5:25 AM, Ravikumar Govindarajan < ravikumar.govindarajan@gmail.com wrote: Rahul & Aaron, I will take a look at the alternate approach of having different clusters.", "Sounds like a very promising method.", "I have another question related to BlurPartitioner."], "labels": [0, 0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["Second thing that comes to mind is to periodically rebuild the index from scratch and up the number of shards.", "How many rows are you expecting per user?", "Avg row width?", "~Garrett On Thu, Sep 26, 2013 at 5:25 AM, Ravikumar Govindarajan < ravikumar.govindarajan@gmail.com wrote: Rahul & Aaron, I will take a look at the alternate approach of having different clusters.", "Sounds like a very promising method.", "I have another question related to BlurPartitioner.", "I assume that rowId and it's data resides in only one shard."], "labels": [0, 0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["How many rows are you expecting per user?", "Avg row width?", "~Garrett On Thu, Sep 26, 2013 at 5:25 AM, Ravikumar Govindarajan < ravikumar.govindarajan@gmail.com wrote: Rahul & Aaron, I will take a look at the alternate approach of having different clusters.", "Sounds like a very promising method.", "I have another question related to BlurPartitioner.", "I assume that rowId and it's data resides in only one shard.", "Is this correct?"], "labels": [0, 0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["Avg row width?", "~Garrett On Thu, Sep 26, 2013 at 5:25 AM, Ravikumar Govindarajan < ravikumar.govindarajan@gmail.com wrote: Rahul & Aaron, I will take a look at the alternate approach of having different clusters.", "Sounds like a very promising method.", "I have another question related to BlurPartitioner.", "I assume that rowId and it's data resides in only one shard.", "Is this correct?", "In that case, how to handle a single-shard that become too unwieldy over a period of time?"], "labels": [0, 0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["Sounds like a very promising method.", "I have another question related to BlurPartitioner.", "I assume that rowId and it's data resides in only one shard.", "Is this correct?", "In that case, how to handle a single-shard that become too unwieldy over a period of time?", "[serving too much data and/or too many rowIds].", "What are your suggestions.", "-- Ravi On Tue, Sep 24, 2013 at 6:36 AM, Aaron McCurry <amccurry@gmail.com wrote: Ravi, See my comments below."], "labels": [0, 0, 0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["I have another question related to BlurPartitioner.", "I assume that rowId and it's data resides in only one shard.", "Is this correct?", "In that case, how to handle a single-shard that become too unwieldy over a period of time?", "[serving too much data and/or too many rowIds].", "What are your suggestions.", "-- Ravi On Tue, Sep 24, 2013 at 6:36 AM, Aaron McCurry <amccurry@gmail.com wrote: Ravi, See my comments below.", "On Mon, Sep 23, 2013 at 8:48 AM, Ravikumar Govindarajan < ravikumar.govindarajan@gmail.com wrote: Rahul, \"When a search request is issued to the Blur Controller it searches though all the shard servers in parallel and each shard server searches through all of its shards."], "labels": [0, 0, 0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["Is this correct?", "In that case, how to handle a single-shard that become too unwieldy over a period of time?", "[serving too much data and/or too many rowIds].", "What are your suggestions.", "-- Ravi On Tue, Sep 24, 2013 at 6:36 AM, Aaron McCurry <amccurry@gmail.com wrote: Ravi, See my comments below.", "On Mon, Sep 23, 2013 at 8:48 AM, Ravikumar Govindarajan < ravikumar.govindarajan@gmail.com wrote: Rahul, \"When a search request is issued to the Blur Controller it searches though all the shard servers in parallel and each shard server searches through all of its shards.", "Unlike database partitioning, I believe we cannot direct a search to a particular shard."], "labels": [0, 0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["[serving too much data and/or too many rowIds].", "What are your suggestions.", "-- Ravi On Tue, Sep 24, 2013 at 6:36 AM, Aaron McCurry <amccurry@gmail.com wrote: Ravi, See my comments below.", "On Mon, Sep 23, 2013 at 8:48 AM, Ravikumar Govindarajan < ravikumar.govindarajan@gmail.com wrote: Rahul, \"When a search request is issued to the Blur Controller it searches though all the shard servers in parallel and each shard server searches through all of its shards.", "Unlike database partitioning, I believe we cannot direct a search to a particular shard.", "However 1. Upon shard server start, all the shards are warmed up ie Index Reader's for each shard is loaded into memory 2."], "labels": [0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["-- Ravi On Tue, Sep 24, 2013 at 6:36 AM, Aaron McCurry <amccurry@gmail.com wrote: Ravi, See my comments below.", "On Mon, Sep 23, 2013 at 8:48 AM, Ravikumar Govindarajan < ravikumar.govindarajan@gmail.com wrote: Rahul, \"When a search request is issued to the Blur Controller it searches though all the shard servers in parallel and each shard server searches through all of its shards.", "Unlike database partitioning, I believe we cannot direct a search to a particular shard.", "However 1. Upon shard server start, all the shards are warmed up ie Index Reader's for each shard is loaded into memory 2.", "Blur uses a block level cache."], "labels": [0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["On Mon, Sep 23, 2013 at 8:48 AM, Ravikumar Govindarajan < ravikumar.govindarajan@gmail.com wrote: Rahul, \"When a search request is issued to the Blur Controller it searches though all the shard servers in parallel and each shard server searches through all of its shards.", "Unlike database partitioning, I believe we cannot direct a search to a particular shard.", "However 1. Upon shard server start, all the shards are warmed up ie Index Reader's for each shard is loaded into memory 2.", "Blur uses a block level cache.", "With sufficient memory allocated to the cache, performance will be greatly enhanced\""], "labels": [0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["Unlike database partitioning, I believe we cannot direct a search to a particular shard.", "However 1. Upon shard server start, all the shards are warmed up ie Index Reader's for each shard is loaded into memory 2.", "Blur uses a block level cache.", "With sufficient memory allocated to the cache, performance will be greatly enhanced\"", "You are spot-on that what I was referring was a DB-Sharding like technique and it definitely has some advantages, at least in our set-up.", "I think, what it translates in Blur, is to create N identical tables and maintain user-wise mappings in our app.", "I mean lets say I create a table for every 10k users."], "labels": [0, 0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["However 1. Upon shard server start, all the shards are warmed up ie Index Reader's for each shard is loaded into memory 2.", "Blur uses a block level cache.", "With sufficient memory allocated to the cache, performance will be greatly enhanced\"", "You are spot-on that what I was referring was a DB-Sharding like technique and it definitely has some advantages, at least in our set-up.", "I think, what it translates in Blur, is to create N identical tables and maintain user-wise mappings in our app.", "I mean lets say I create a table for every 10k users.", "I will end up with 300 tables for 3 million users."], "labels": [0, 0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["Blur uses a block level cache.", "With sufficient memory allocated to the cache, performance will be greatly enhanced\"", "You are spot-on that what I was referring was a DB-Sharding like technique and it definitely has some advantages, at least in our set-up.", "I think, what it translates in Blur, is to create N identical tables and maintain user-wise mappings in our app.", "I mean lets say I create a table for every 10k users.", "I will end up with 300 tables for 3 million users.", "What are the problems you foresee with that large number of tables?"], "labels": [0, 0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["With sufficient memory allocated to the cache, performance will be greatly enhanced\"", "You are spot-on that what I was referring was a DB-Sharding like technique and it definitely has some advantages, at least in our set-up.", "I think, what it translates in Blur, is to create N identical tables and maintain user-wise mappings in our app.", "I mean lets say I create a table for every 10k users.", "I will end up with 300 tables for 3 million users.", "What are the problems you foresee with that large number of tables?", "I know for sure some K-V stores prohibit such an approach."], "labels": [0, 0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["I think, what it translates in Blur, is to create N identical tables and maintain user-wise mappings in our app.", "I mean lets say I create a table for every 10k users.", "I will end up with 300 tables for 3 million users.", "What are the problems you foresee with that large number of tables?", "I know for sure some K-V stores prohibit such an approach.", "I think that this is valid approach, however I wouldn't optimize too soon.", "I think the performance will likely be better with one larger table (or at least fewer) than hundreds of smaller tables."], "labels": [0, 0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["I mean lets say I create a table for every 10k users.", "I will end up with 300 tables for 3 million users.", "What are the problems you foresee with that large number of tables?", "I know for sure some K-V stores prohibit such an approach.", "I think that this is valid approach, however I wouldn't optimize too soon.", "I think the performance will likely be better with one larger table (or at least fewer) than hundreds of smaller tables.", "However if you need to split into separate tables there is a feature in Blur that you will likely be interested in using.", "In Blur the controllers act as a gateway/router for the shard cluster."], "labels": [0, 0, 0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["What are the problems you foresee with that large number of tables?", "I know for sure some K-V stores prohibit such an approach.", "I think that this is valid approach, however I wouldn't optimize too soon.", "I think the performance will likely be better with one larger table (or at least fewer) than hundreds of smaller tables.", "However if you need to split into separate tables there is a feature in Blur that you will likely be interested in using.", "In Blur the controllers act as a gateway/router for the shard cluster.", "However they can access more than just a single shard cluster."], "labels": [0, 0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["I know for sure some K-V stores prohibit such an approach.", "I think that this is valid approach, however I wouldn't optimize too soon.", "I think the performance will likely be better with one larger table (or at least fewer) than hundreds of smaller tables.", "However if you need to split into separate tables there is a feature in Blur that you will likely be interested in using.", "In Blur the controllers act as a gateway/router for the shard cluster.", "However they can access more than just a single shard cluster.", "If you name each shard cluster a different name (blur-site."], "labels": [0, 0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["I think that this is valid approach, however I wouldn't optimize too soon.", "I think the performance will likely be better with one larger table (or at least fewer) than hundreds of smaller tables.", "However if you need to split into separate tables there is a feature in Blur that you will likely be interested in using.", "In Blur the controllers act as a gateway/router for the shard cluster.", "However they can access more than just a single shard cluster.", "If you name each shard cluster a different name (blur-site.", "properties file) the controllers see all of them and make all the tables accessible through the controller cluster."], "labels": [0, 0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["I think the performance will likely be better with one larger table (or at least fewer) than hundreds of smaller tables.", "However if you need to split into separate tables there is a feature in Blur that you will likely be interested in using.", "In Blur the controllers act as a gateway/router for the shard cluster.", "However they can access more than just a single shard cluster.", "If you name each shard cluster a different name (blur-site.", "properties file) the controllers see all of them and make all the tables accessible through the controller cluster.", "For example: Given: Shard Cluster A (100 servers) 10 tables Shard Cluster B (100 servers) 10 tables Shard Cluster C (100 servers) 10 tables Shard Cluster D (100 servers) 10 tables"], "labels": [0, 0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["However if you need to split into separate tables there is a feature in Blur that you will likely be interested in using.", "In Blur the controllers act as a gateway/router for the shard cluster.", "However they can access more than just a single shard cluster.", "If you name each shard cluster a different name (blur-site.", "properties file) the controllers see all of them and make all the tables accessible through the controller cluster.", "For example: Given: Shard Cluster A (100 servers) 10 tables Shard Cluster B (100 servers) 10 tables Shard Cluster C (100 servers) 10 tables Shard Cluster D (100 servers) 10 tables", "The controllers would present all 40 tables to the clients."], "labels": [0, 0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["In Blur the controllers act as a gateway/router for the shard cluster.", "However they can access more than just a single shard cluster.", "If you name each shard cluster a different name (blur-site.", "properties file) the controllers see all of them and make all the tables accessible through the controller cluster.", "For example: Given: Shard Cluster A (100 servers) 10 tables Shard Cluster B (100 servers) 10 tables Shard Cluster C (100 servers) 10 tables Shard Cluster D (100 servers) 10 tables", "The controllers would present all 40 tables to the clients.", "I have normally used this feature to do full replacements of MapReduced indexes onto a off cluster while another was presenting the data users were accessing."], "labels": [0, 0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["However they can access more than just a single shard cluster.", "If you name each shard cluster a different name (blur-site.", "properties file) the controllers see all of them and make all the tables accessible through the controller cluster.", "For example: Given: Shard Cluster A (100 servers) 10 tables Shard Cluster B (100 servers) 10 tables Shard Cluster C (100 servers) 10 tables Shard Cluster D (100 servers) 10 tables", "The controllers would present all 40 tables to the clients.", "I have normally used this feature to do full replacements of MapReduced indexes onto a off cluster while another was presenting the data users were accessing.", "Once the indexing was complete the application was soft switched to use the new table."], "labels": [0, 0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["properties file) the controllers see all of them and make all the tables accessible through the controller cluster.", "For example: Given: Shard Cluster A (100 servers) 10 tables Shard Cluster B (100 servers) 10 tables Shard Cluster C (100 servers) 10 tables Shard Cluster D (100 servers) 10 tables", "The controllers would present all 40 tables to the clients.", "I have normally used this feature to do full replacements of MapReduced indexes onto a off cluster while another was presenting the data users were accessing.", "Once the indexing was complete the application was soft switched to use the new table.", "Just some more ideas to think about."], "labels": [0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["For example: Given: Shard Cluster A (100 servers) 10 tables Shard Cluster B (100 servers) 10 tables Shard Cluster C (100 servers) 10 tables Shard Cluster D (100 servers) 10 tables", "The controllers would present all 40 tables to the clients.", "I have normally used this feature to do full replacements of MapReduced indexes onto a off cluster while another was presenting the data users were accessing.", "Once the indexing was complete the application was soft switched to use the new table.", "Just some more ideas to think about.", "Aaron -- Ravi On Thu, Sep 19, 2013 at 11:16 PM, rahul challapalli < challapallirahul@gmail.com wrote: I will attempt to answer some of your questions below."], "labels": [0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["The controllers would present all 40 tables to the clients.", "I have normally used this feature to do full replacements of MapReduced indexes onto a off cluster while another was presenting the data users were accessing.", "Once the indexing was complete the application was soft switched to use the new table.", "Just some more ideas to think about.", "Aaron -- Ravi On Thu, Sep 19, 2013 at 11:16 PM, rahul challapalli < challapallirahul@gmail.com wrote: I will attempt to answer some of your questions below.", "Aaron or someone else can correct me if I am wrong On Thu, Sep 19, 2013 at 6:15 AM, Ravikumar Govindarajan < ravikumar.govindarajan@gmail.com wrote: Thanks Aaron."], "labels": [0, 0, 0, 0, 0, 1], "abstract_id": 0}
{"sentences": ["I have normally used this feature to do full replacements of MapReduced indexes onto a off cluster while another was presenting the data users were accessing.", "Once the indexing was complete the application was soft switched to use the new table.", "Just some more ideas to think about.", "Aaron -- Ravi On Thu, Sep 19, 2013 at 11:16 PM, rahul challapalli < challapallirahul@gmail.com wrote: I will attempt to answer some of your questions below.", "Aaron or someone else can correct me if I am wrong On Thu, Sep 19, 2013 at 6:15 AM, Ravikumar Govindarajan < ravikumar.govindarajan@gmail.com wrote: Thanks Aaron.", "I think, it has answered my question."], "labels": [0, 0, 0, 0, 1, 0], "abstract_id": 0}
{"sentences": ["Once the indexing was complete the application was soft switched to use the new table.", "Just some more ideas to think about.", "Aaron -- Ravi On Thu, Sep 19, 2013 at 11:16 PM, rahul challapalli < challapallirahul@gmail.com wrote: I will attempt to answer some of your questions below.", "Aaron or someone else can correct me if I am wrong On Thu, Sep 19, 2013 at 6:15 AM, Ravikumar Govindarajan < ravikumar.govindarajan@gmail.com wrote: Thanks Aaron.", "I think, it has answered my question.", "I have a few more and would be great if you can clarify them 1."], "labels": [0, 0, 0, 1, 0, 0], "abstract_id": 0}
{"sentences": ["Just some more ideas to think about.", "Aaron -- Ravi On Thu, Sep 19, 2013 at 11:16 PM, rahul challapalli < challapallirahul@gmail.com wrote: I will attempt to answer some of your questions below.", "Aaron or someone else can correct me if I am wrong On Thu, Sep 19, 2013 at 6:15 AM, Ravikumar Govindarajan < ravikumar.govindarajan@gmail.com wrote: Thanks Aaron.", "I think, it has answered my question.", "I have a few more and would be great if you can clarify them 1.", "Is the number of shards per-table fixed during table-creation or we can dynamically allocate shards?"], "labels": [0, 0, 1, 0, 0, 0], "abstract_id": 0}
{"sentences": ["Aaron or someone else can correct me if I am wrong On Thu, Sep 19, 2013 at 6:15 AM, Ravikumar Govindarajan < ravikumar.govindarajan@gmail.com wrote: Thanks Aaron.", "I think, it has answered my question.", "I have a few more and would be great if you can clarify them 1.", "Is the number of shards per-table fixed during table-creation or we can dynamically allocate shards?", "I believe we cannot dynamically allocate shards.", "The only thing we can dynamically add to an existing table is new columns 2."], "labels": [1, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["I think, it has answered my question.", "I have a few more and would be great if you can clarify them 1.", "Is the number of shards per-table fixed during table-creation or we can dynamically allocate shards?", "I believe we cannot dynamically allocate shards.", "The only thing we can dynamically add to an existing table is new columns 2.", "Assuming I have 10k shards with each shard-size=2GB, for a total of 20 TB table size.", "I typically use RowId = UserId and there are approx 3 million users, in our system", "How do I ensure that when a user issues a query, I should not end-up searching all these 10k shards, but rather search only a very small set of shards?"], "labels": [0, 0, 0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["Is the number of shards per-table fixed during table-creation or we can dynamically allocate shards?", "I believe we cannot dynamically allocate shards.", "The only thing we can dynamically add to an existing table is new columns 2.", "Assuming I have 10k shards with each shard-size=2GB, for a total of 20 TB table size.", "I typically use RowId = UserId and there are approx 3 million users, in our system", "How do I ensure that when a user issues a query, I should not end-up searching all these 10k shards, but rather search only a very small set of shards?", "When a search request is issued to the Blur Controller it searches though all the shard servers in parallel and each shard server searches through all of its shards."], "labels": [0, 0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["I believe we cannot dynamically allocate shards.", "The only thing we can dynamically add to an existing table is new columns 2.", "Assuming I have 10k shards with each shard-size=2GB, for a total of 20 TB table size.", "I typically use RowId = UserId and there are approx 3 million users, in our system", "How do I ensure that when a user issues a query, I should not end-up searching all these 10k shards, but rather search only a very small set of shards?", "When a search request is issued to the Blur Controller it searches though all the shard servers in parallel and each shard server searches through all of its shards.", "Unlike database partitioning, I believe we cannot direct a search to a particular shard."], "labels": [0, 0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["Assuming I have 10k shards with each shard-size=2GB, for a total of 20 TB table size.", "I typically use RowId = UserId and there are approx 3 million users, in our system", "How do I ensure that when a user issues a query, I should not end-up searching all these 10k shards, but rather search only a very small set of shards?", "When a search request is issued to the Blur Controller it searches though all the shard servers in parallel and each shard server searches through all of its shards.", "Unlike database partitioning, I believe we cannot direct a search to a particular shard.", "However 1. Upon shard server start, all the shards are warmed up ie Index Reader's for each shard is loaded into memory 2."], "labels": [0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["I typically use RowId = UserId and there are approx 3 million users, in our system", "How do I ensure that when a user issues a query, I should not end-up searching all these 10k shards, but rather search only a very small set of shards?", "When a search request is issued to the Blur Controller it searches though all the shard servers in parallel and each shard server searches through all of its shards.", "Unlike database partitioning, I believe we cannot direct a search to a particular shard.", "However 1. Upon shard server start, all the shards are warmed up ie Index Reader's for each shard is loaded into memory 2.", "Blur uses a block level cache."], "labels": [0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["How do I ensure that when a user issues a query, I should not end-up searching all these 10k shards, but rather search only a very small set of shards?", "When a search request is issued to the Blur Controller it searches though all the shard servers in parallel and each shard server searches through all of its shards.", "Unlike database partitioning, I believe we cannot direct a search to a particular shard.", "However 1. Upon shard server start, all the shards are warmed up ie Index Reader's for each shard is loaded into memory 2.", "Blur uses a block level cache.", "With sufficient memory allocated to the cache, performance will be greatly enhanced 3. Are there any advantages of running shard-server and data-nodes {HDFS} in the same machine?"], "labels": [0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["When a search request is issued to the Blur Controller it searches though all the shard servers in parallel and each shard server searches through all of its shards.", "Unlike database partitioning, I believe we cannot direct a search to a particular shard.", "However 1. Upon shard server start, all the shards are warmed up ie Index Reader's for each shard is loaded into memory 2.", "Blur uses a block level cache.", "With sufficient memory allocated to the cache, performance will be greatly enhanced 3. Are there any advantages of running shard-server and data-nodes {HDFS} in the same machine?", "Someone else can provide a better answer here."], "labels": [0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["Unlike database partitioning, I believe we cannot direct a search to a particular shard.", "However 1. Upon shard server start, all the shards are warmed up ie Index Reader's for each shard is loaded into memory 2.", "Blur uses a block level cache.", "With sufficient memory allocated to the cache, performance will be greatly enhanced 3. Are there any advantages of running shard-server and data-nodes {HDFS} in the same machine?", "Someone else can provide a better answer here.", "In a typical Hadoop installation Task Trackers and Data Nodes run alongside each other on the same machine.", "Since data nodes store the first block replica on the same machine, shard servers might see an advantage in terms of network latency."], "labels": [0, 0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["Blur uses a block level cache.", "With sufficient memory allocated to the cache, performance will be greatly enhanced 3. Are there any advantages of running shard-server and data-nodes {HDFS} in the same machine?", "Someone else can provide a better answer here.", "In a typical Hadoop installation Task Trackers and Data Nodes run alongside each other on the same machine.", "Since data nodes store the first block replica on the same machine, shard servers might see an advantage in terms of network latency.", "However I think it is not a good idea to run Blur alongside Task Trackers for performance reasons -- Ravi On Thu, Sep 19, 2013 at 2:36 AM, Aaron McCurry < amccurry@gmail.com wrote: I will attempt to answer below: On Wed, Sep 18, 2013 at 1:54 AM, Ravikumar Govindarajan < ravikumar.govindarajan@gmail.com wrote:"], "labels": [0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["With sufficient memory allocated to the cache, performance will be greatly enhanced 3. Are there any advantages of running shard-server and data-nodes {HDFS} in the same machine?", "Someone else can provide a better answer here.", "In a typical Hadoop installation Task Trackers and Data Nodes run alongside each other on the same machine.", "Since data nodes store the first block replica on the same machine, shard servers might see an advantage in terms of network latency.", "However I think it is not a good idea to run Blur alongside Task Trackers for performance reasons -- Ravi On Thu, Sep 19, 2013 at 2:36 AM, Aaron McCurry < amccurry@gmail.com wrote: I will attempt to answer below: On Wed, Sep 18, 2013 at 1:54 AM, Ravikumar Govindarajan < ravikumar.govindarajan@gmail.com wrote:", "Thanks a bunch for a concise and quick reply."], "labels": [0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["Someone else can provide a better answer here.", "In a typical Hadoop installation Task Trackers and Data Nodes run alongside each other on the same machine.", "Since data nodes store the first block replica on the same machine, shard servers might see an advantage in terms of network latency.", "However I think it is not a good idea to run Blur alongside Task Trackers for performance reasons -- Ravi On Thu, Sep 19, 2013 at 2:36 AM, Aaron McCurry < amccurry@gmail.com wrote: I will attempt to answer below: On Wed, Sep 18, 2013 at 1:54 AM, Ravikumar Govindarajan < ravikumar.govindarajan@gmail.com wrote:", "Thanks a bunch for a concise and quick reply.", "Few more questions 1. Any pointers/links on how you plan to tackle the availability problem?"], "labels": [0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["Since data nodes store the first block replica on the same machine, shard servers might see an advantage in terms of network latency.", "However I think it is not a good idea to run Blur alongside Task Trackers for performance reasons -- Ravi On Thu, Sep 19, 2013 at 2:36 AM, Aaron McCurry < amccurry@gmail.com wrote: I will attempt to answer below: On Wed, Sep 18, 2013 at 1:54 AM, Ravikumar Govindarajan < ravikumar.govindarajan@gmail.com wrote:", "Thanks a bunch for a concise and quick reply.", "Few more questions 1. Any pointers/links on how you plan to tackle the availability problem?", "Lets say we store-forward hints to the failed shard-server."], "labels": [0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["Thanks a bunch for a concise and quick reply.", "Few more questions 1. Any pointers/links on how you plan to tackle the availability problem?", "Lets say we store-forward hints to the failed shard-server.", "Won't the HDFS index-files differ in shard replicas?", "I am in the process of documenting the strategy and will be adding it to JIRA soon.", "The way I am planning on solving this problem doesn't involve storing the indexes in more than once in HDFS (which of course is replicated).", "2. I did not phrase my question on cross-join correctly."], "labels": [0, 0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["Few more questions 1. Any pointers/links on how you plan to tackle the availability problem?", "Lets say we store-forward hints to the failed shard-server.", "Won't the HDFS index-files differ in shard replicas?", "I am in the process of documenting the strategy and will be adding it to JIRA soon.", "The way I am planning on solving this problem doesn't involve storing the indexes in more than once in HDFS (which of course is replicated).", "2. I did not phrase my question on cross-join correctly.", "Let me clarify RowKey = 123 RecId = 1000 Family = \"ACCOUNTS\" Col-Name = \"NAME\" Col-Value = \"ABC\" ...... RecId = 1001 Family = \"CONTACTS\" Col-Name = \"NAME\" Col-Value = \"XYZ\" Col-Name = \"ACCOUNTS-NAME\" [FK to RecId=1000] Col-Value = \"1000\" ......."], "labels": [0, 0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["Won't the HDFS index-files differ in shard replicas?", "I am in the process of documenting the strategy and will be adding it to JIRA soon.", "The way I am planning on solving this problem doesn't involve storing the indexes in more than once in HDFS (which of course is replicated).", "2. I did not phrase my question on cross-join correctly.", "Let me clarify RowKey = 123 RecId = 1000 Family = \"ACCOUNTS\" Col-Name = \"NAME\" Col-Value = \"ABC\" ...... RecId = 1001 Family = \"CONTACTS\" Col-Name = \"NAME\" Col-Value = \"XYZ\" Col-Name = \"ACCOUNTS-NAME\" [FK to RecId=1000] Col-Value = \"1000\" .......", "Lets say the user specifies the search query as key=123 AND name:(ABC OR XYZ) Initially I will apply this query to each of the Family types, namely \"ACCOUNTS\", \"CONTACTS\" etc.... and get their RecIds.."], "labels": [0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["The way I am planning on solving this problem doesn't involve storing the indexes in more than once in HDFS (which of course is replicated).", "2. I did not phrase my question on cross-join correctly.", "Let me clarify RowKey = 123 RecId = 1000 Family = \"ACCOUNTS\" Col-Name = \"NAME\" Col-Value = \"ABC\" ...... RecId = 1001 Family = \"CONTACTS\" Col-Name = \"NAME\" Col-Value = \"XYZ\" Col-Name = \"ACCOUNTS-NAME\" [FK to RecId=1000] Col-Value = \"1000\" .......", "Lets say the user specifies the search query as key=123 AND name:(ABC OR XYZ) Initially I will apply this query to each of the Family types, namely \"ACCOUNTS\", \"CONTACTS\" etc.... and get their RecIds..", "After this, I will have to filter \"CONTACTS\" family results, based on RecIds received from \"ACCOUNTS\" [Join within records of different family, based on FK]"], "labels": [0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["Let me clarify RowKey = 123 RecId = 1000 Family = \"ACCOUNTS\" Col-Name = \"NAME\" Col-Value = \"ABC\" ...... RecId = 1001 Family = \"CONTACTS\" Col-Name = \"NAME\" Col-Value = \"XYZ\" Col-Name = \"ACCOUNTS-NAME\" [FK to RecId=1000] Col-Value = \"1000\" .......", "Lets say the user specifies the search query as key=123 AND name:(ABC OR XYZ) Initially I will apply this query to each of the Family types, namely \"ACCOUNTS\", \"CONTACTS\" etc.... and get their RecIds..", "After this, I will have to filter \"CONTACTS\" family results, based on RecIds received from \"ACCOUNTS\" [Join within records of different family, based on FK]", "Is something like this achievable?"], "labels": [0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["Lets say the user specifies the search query as key=123 AND name:(ABC OR XYZ) Initially I will apply this query to each of the Family types, namely \"ACCOUNTS\", \"CONTACTS\" etc.... and get their RecIds..", "After this, I will have to filter \"CONTACTS\" family results, based on RecIds received from \"ACCOUNTS\" [Join within records of different family, based on FK]", "Is something like this achievable?", "Can I design it differently to satisfy my requirements?", "I may not fully understand your scenario."], "labels": [0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["After this, I will have to filter \"CONTACTS\" family results, based on RecIds received from \"ACCOUNTS\" [Join within records of different family, based on FK]", "Is something like this achievable?", "Can I design it differently to satisfy my requirements?", "I may not fully understand your scenario.", "As I understand your example above: Row { \"id\" = \"123\", \"records\" = [ Record { \"recordId\" = \"1000\", \"family\" = \"accounts\", \"columns\" = [Column {\"name\" = \"abc\"}] }, Record { \"recordId\" = \"1001\", \"family\" = \"contacts\", \"columns\" = [Column {\"name\" = \"abc\"}] } ] }", "Let me go through some example queries that we support: +<accounts.name:abc +<contacts.name:abc"], "labels": [0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["Is something like this achievable?", "Can I design it differently to satisfy my requirements?", "I may not fully understand your scenario.", "As I understand your example above: Row { \"id\" = \"123\", \"records\" = [ Record { \"recordId\" = \"1000\", \"family\" = \"accounts\", \"columns\" = [Column {\"name\" = \"abc\"}] }, Record { \"recordId\" = \"1001\", \"family\" = \"contacts\", \"columns\" = [Column {\"name\" = \"abc\"}] } ] }", "Let me go through some example queries that we support: +<accounts.name:abc +<contacts.name:abc", "Another way of writing it would be: <accounts.name:abc AND <contacts.name:abc"], "labels": [0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["I may not fully understand your scenario.", "As I understand your example above: Row { \"id\" = \"123\", \"records\" = [ Record { \"recordId\" = \"1000\", \"family\" = \"accounts\", \"columns\" = [Column {\"name\" = \"abc\"}] }, Record { \"recordId\" = \"1001\", \"family\" = \"contacts\", \"columns\" = [Column {\"name\" = \"abc\"}] } ] }", "Let me go through some example queries that we support: +<accounts.name:abc +<contacts.name:abc", "Another way of writing it would be: <accounts.name:abc AND <contacts.name:abc", "Would yield a hit on the Row, there aren't any FKs in Blur."], "labels": [0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["Let me go through some example queries that we support: +<accounts.name:abc +<contacts.name:abc", "Another way of writing it would be: <accounts.name:abc AND <contacts.name:abc", "Would yield a hit on the Row, there aren't any FKs in Blur.", "However if there are some interesting queries that be done with more examples: Row { \"id\" = \"123\", \"records\" = [ Record { \"recordId\" = \"1000\", \"family\" = \"accounts\", \"columns\" = [Column {\"name\" = \"abc\"}] }, Record { \"recordId\" = \"1001\", \"family\" = \"contacts\", \"columns\" = [Column {\"name\" = \"abc\"}] } ] } Row { \"id\" = \"456\", \"records\" = [ Record { \"recordId\" = \"1000\", \"family\" = \"accounts\", \"columns\" = [Column {\"name\" = \"abc\"}] }, Record { \"recordId\" = \"1001\", \"family\" = \"contacts\", \"columns\" = [Column {\"name\" = \"abc\"}] }, Record { \"recordId\" = \"1002\", \"family\" = \"contacts\", \"columns\" = [Column {\"name\" = \"def\"}] } ] } Row { \"id\" = \"789\", \"records\" = [ Record { \"recordId\" = \"1000\", \"family\" = \"accounts\", \"columns\" = [Column {\"name\" = \"abc\"}] }, Record { \"recordId\" = \"1002\", \"family\" = \"contacts\", \"columns\" = [Column {\"name\" = \"def\"}] } ] }"], "labels": [0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["Another way of writing it would be: <accounts.name:abc AND <contacts.name:abc", "Would yield a hit on the Row, there aren't any FKs in Blur.", "However if there are some interesting queries that be done with more examples: Row { \"id\" = \"123\", \"records\" = [ Record { \"recordId\" = \"1000\", \"family\" = \"accounts\", \"columns\" = [Column {\"name\" = \"abc\"}] }, Record { \"recordId\" = \"1001\", \"family\" = \"contacts\", \"columns\" = [Column {\"name\" = \"abc\"}] } ] } Row { \"id\" = \"456\", \"records\" = [ Record { \"recordId\" = \"1000\", \"family\" = \"accounts\", \"columns\" = [Column {\"name\" = \"abc\"}] }, Record { \"recordId\" = \"1001\", \"family\" = \"contacts\", \"columns\" = [Column {\"name\" = \"abc\"}] }, Record { \"recordId\" = \"1002\", \"family\" = \"contacts\", \"columns\" = [Column {\"name\" = \"def\"}] } ] } Row { \"id\" = \"789\", \"records\" = [ Record { \"recordId\" = \"1000\", \"family\" = \"accounts\", \"columns\" = [Column {\"name\" = \"abc\"}] }, Record { \"recordId\" = \"1002\", \"family\" = \"contacts\", \"columns\" = [Column {\"name\" = \"def\"}] } ] }", "For the given query: \"<accounts.name:abc AND < contacts.name : abc\" would yield 2 Row hits."], "labels": [0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["For the given query: \"<accounts.name:abc AND < contacts.name : abc\" would yield 2 Row hits.", "123 and 456", "For the given query: \"<accounts.name:abc AND < contacts.name : def\" would yield 2 Row hits.", "456 and 789", "For the given query: \"<contacts.name:abc AND < contacts.name : def\" would yield 1 Row hit of 456.", "NOTICE that the family is the same here \"contacts\".", "Also in Blur you can turn off the Row query and just query the records."], "labels": [0, 0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["123 and 456", "For the given query: \"<accounts.name:abc AND < contacts.name : def\" would yield 2 Row hits.", "456 and 789", "For the given query: \"<contacts.name:abc AND < contacts.name : def\" would yield 1 Row hit of 456.", "NOTICE that the family is the same here \"contacts\".", "Also in Blur you can turn off the Row query and just query the records.", "This would be your typical Document like access.", "I fear that this has not answered your question, so if it hasn't please let me know."], "labels": [0, 0, 0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["456 and 789", "For the given query: \"<contacts.name:abc AND < contacts.name : def\" would yield 1 Row hit of 456.", "NOTICE that the family is the same here \"contacts\".", "Also in Blur you can turn off the Row query and just query the records.", "This would be your typical Document like access.", "I fear that this has not answered your question, so if it hasn't please let me know.", "Thanks!", "Aaron -- Ravi On Tue, Sep 17, 2013 at 7:01 PM, Aaron McCurry < amccurry@gmail.com wrote: First off let me say welcome!"], "labels": [0, 0, 0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["NOTICE that the family is the same here \"contacts\".", "Also in Blur you can turn off the Row query and just query the records.", "This would be your typical Document like access.", "I fear that this has not answered your question, so if it hasn't please let me know.", "Thanks!", "Aaron -- Ravi On Tue, Sep 17, 2013 at 7:01 PM, Aaron McCurry < amccurry@gmail.com wrote: First off let me say welcome!", "Hopefully I can answer your questions inline below.", "On Tue, Sep 17, 2013 at 6:52 AM, Ravikumar Govindarajan < ravikumar.govindarajan@gmail.com wrote: I am quite new to Blur and need some help with the following questions 1. Lets say I have a replication_factor=3 for all HDFS indexes."], "labels": [0, 0, 0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["This would be your typical Document like access.", "I fear that this has not answered your question, so if it hasn't please let me know.", "Thanks!", "Aaron -- Ravi On Tue, Sep 17, 2013 at 7:01 PM, Aaron McCurry < amccurry@gmail.com wrote: First off let me say welcome!", "Hopefully I can answer your questions inline below.", "On Tue, Sep 17, 2013 at 6:52 AM, Ravikumar Govindarajan < ravikumar.govindarajan@gmail.com wrote: I am quite new to Blur and need some help with the following questions 1. Lets say I have a replication_factor=3 for all HDFS indexes.", "In case one of the server hosting HDFS indexes goes down [temporary or take-down], what will happen to writes?"], "labels": [0, 0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["Thanks!", "Aaron -- Ravi On Tue, Sep 17, 2013 at 7:01 PM, Aaron McCurry < amccurry@gmail.com wrote: First off let me say welcome!", "Hopefully I can answer your questions inline below.", "On Tue, Sep 17, 2013 at 6:52 AM, Ravikumar Govindarajan < ravikumar.govindarajan@gmail.com wrote: I am quite new to Blur and need some help with the following questions 1. Lets say I have a replication_factor=3 for all HDFS indexes.", "In case one of the server hosting HDFS indexes goes down [temporary or take-down], what will happen to writes?", "Some kind-of HintedHandoff [as in Cassandra] is supported?"], "labels": [0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["Hopefully I can answer your questions inline below.", "On Tue, Sep 17, 2013 at 6:52 AM, Ravikumar Govindarajan < ravikumar.govindarajan@gmail.com wrote: I am quite new to Blur and need some help with the following questions 1. Lets say I have a replication_factor=3 for all HDFS indexes.", "In case one of the server hosting HDFS indexes goes down [temporary or take-down], what will happen to writes?", "Some kind-of HintedHandoff [as in Cassandra] is supported?", "When there is a Blur Shard Server failure state in ZooKeeper will change and the other shard servers will take action to bring the down shard(s) online."], "labels": [0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["On Tue, Sep 17, 2013 at 6:52 AM, Ravikumar Govindarajan < ravikumar.govindarajan@gmail.com wrote: I am quite new to Blur and need some help with the following questions 1. Lets say I have a replication_factor=3 for all HDFS indexes.", "In case one of the server hosting HDFS indexes goes down [temporary or take-down], what will happen to writes?", "Some kind-of HintedHandoff [as in Cassandra] is supported?", "When there is a Blur Shard Server failure state in ZooKeeper will change and the other shard servers will take action to bring the down shard(s) online.", "This is similar to the HBase region model."], "labels": [0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["In case one of the server hosting HDFS indexes goes down [temporary or take-down], what will happen to writes?", "Some kind-of HintedHandoff [as in Cassandra] is supported?", "When there is a Blur Shard Server failure state in ZooKeeper will change and the other shard servers will take action to bring the down shard(s) online.", "This is similar to the HBase region model.", "While the shard(s) are being relocated (which really means being reopened from HDFS) writes to the shard(s) being moved are not available.", "However the bulk load capability is always available as long as HDFS is available, this can be used through Hadoop MapReduce."], "labels": [0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["Some kind-of HintedHandoff [as in Cassandra] is supported?", "When there is a Blur Shard Server failure state in ZooKeeper will change and the other shard servers will take action to bring the down shard(s) online.", "This is similar to the HBase region model.", "While the shard(s) are being relocated (which really means being reopened from HDFS) writes to the shard(s) being moved are not available.", "However the bulk load capability is always available as long as HDFS is available, this can be used through Hadoop MapReduce.", "To re-phrase, what is the Consistency Vs Availability trade-off in Blur, with replication_factor1 for HDFS indexes?"], "labels": [0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["When there is a Blur Shard Server failure state in ZooKeeper will change and the other shard servers will take action to bring the down shard(s) online.", "This is similar to the HBase region model.", "While the shard(s) are being relocated (which really means being reopened from HDFS) writes to the shard(s) being moved are not available.", "However the bulk load capability is always available as long as HDFS is available, this can be used through Hadoop MapReduce.", "To re-phrase, what is the Consistency Vs Availability trade-off in Blur, with replication_factor1 for HDFS indexes?", "Of the two Consistency is favored over Availability, however we are starting development (in 0.3.0) to increase availability during failures."], "labels": [0, 0, 0, 0, 0, 1], "abstract_id": 0}
{"sentences": ["This is similar to the HBase region model.", "While the shard(s) are being relocated (which really means being reopened from HDFS) writes to the shard(s) being moved are not available.", "However the bulk load capability is always available as long as HDFS is available, this can be used through Hadoop MapReduce.", "To re-phrase, what is the Consistency Vs Availability trade-off in Blur, with replication_factor1 for HDFS indexes?", "Of the two Consistency is favored over Availability, however we are starting development (in 0.3.0) to increase availability during failures.", "2. Since HDFSInputStream is used underneath, will this result in too much of data-transfer back-and-forth?"], "labels": [0, 0, 0, 0, 1, 0], "abstract_id": 0}
{"sentences": ["While the shard(s) are being relocated (which really means being reopened from HDFS) writes to the shard(s) being moved are not available.", "However the bulk load capability is always available as long as HDFS is available, this can be used through Hadoop MapReduce.", "To re-phrase, what is the Consistency Vs Availability trade-off in Blur, with replication_factor1 for HDFS indexes?", "Of the two Consistency is favored over Availability, however we are starting development (in 0.3.0) to increase availability during failures.", "2. Since HDFSInputStream is used underneath, will this result in too much of data-transfer back-and-forth?", "A case of multi-segment-merge or even wild-card search could trigger it."], "labels": [0, 0, 0, 1, 0, 0], "abstract_id": 0}
{"sentences": ["However the bulk load capability is always available as long as HDFS is available, this can be used through Hadoop MapReduce.", "To re-phrase, what is the Consistency Vs Availability trade-off in Blur, with replication_factor1 for HDFS indexes?", "Of the two Consistency is favored over Availability, however we are starting development (in 0.3.0) to increase availability during failures.", "2. Since HDFSInputStream is used underneath, will this result in too much of data-transfer back-and-forth?", "A case of multi-segment-merge or even wild-card search could trigger it.", "Blur uses an in process file system cache (Block Cache is the term used in the code) to reduce the IO from HDFS."], "labels": [0, 0, 1, 0, 0, 0], "abstract_id": 0}
{"sentences": ["To re-phrase, what is the Consistency Vs Availability trade-off in Blur, with replication_factor1 for HDFS indexes?", "Of the two Consistency is favored over Availability, however we are starting development (in 0.3.0) to increase availability during failures.", "2. Since HDFSInputStream is used underneath, will this result in too much of data-transfer back-and-forth?", "A case of multi-segment-merge or even wild-card search could trigger it.", "Blur uses an in process file system cache (Block Cache is the term used in the code) to reduce the IO from HDFS.", "During index merges data that is not in the Block Cache is read from HDFS and the output is written back to HDFS."], "labels": [0, 1, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["Of the two Consistency is favored over Availability, however we are starting development (in 0.3.0) to increase availability during failures.", "2. Since HDFSInputStream is used underneath, will this result in too much of data-transfer back-and-forth?", "A case of multi-segment-merge or even wild-card search could trigger it.", "Blur uses an in process file system cache (Block Cache is the term used in the code) to reduce the IO from HDFS.", "During index merges data that is not in the Block Cache is read from HDFS and the output is written back to HDFS.", "Overall once an index is hot (been online for some time) the IO for any given search is fairly small assuming that the cluster has enough memory configured in the Block Cache."], "labels": [1, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["2. Since HDFSInputStream is used underneath, will this result in too much of data-transfer back-and-forth?", "A case of multi-segment-merge or even wild-card search could trigger it.", "Blur uses an in process file system cache (Block Cache is the term used in the code) to reduce the IO from HDFS.", "During index merges data that is not in the Block Cache is read from HDFS and the output is written back to HDFS.", "Overall once an index is hot (been online for some time) the IO for any given search is fairly small assuming that the cluster has enough memory configured in the Block Cache.", "3. Does Blur also support foreign-key like semantics to search across column-families as well as delete using row_id?"], "labels": [0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["A case of multi-segment-merge or even wild-card search could trigger it.", "Blur uses an in process file system cache (Block Cache is the term used in the code) to reduce the IO from HDFS.", "During index merges data that is not in the Block Cache is read from HDFS and the output is written back to HDFS.", "Overall once an index is hot (been online for some time) the IO for any given search is fairly small assuming that the cluster has enough memory configured in the Block Cache.", "3. Does Blur also support foreign-key like semantics to search across column-families as well as delete using row_id?", "Blur supports something called Row Queries that allow for searches across column families within single Rows."], "labels": [0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["Blur uses an in process file system cache (Block Cache is the term used in the code) to reduce the IO from HDFS.", "During index merges data that is not in the Block Cache is read from HDFS and the output is written back to HDFS.", "Overall once an index is hot (been online for some time) the IO for any given search is fairly small assuming that the cluster has enough memory configured in the Block Cache.", "3. Does Blur also support foreign-key like semantics to search across column-families as well as delete using row_id?", "Blur supports something called Row Queries that allow for searches across column families within single Rows.", "Take a look at this page for a better explanation: http://incubator.apache.org/blur/docs/0.2.0/data-model.html#querying"], "labels": [0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["During index merges data that is not in the Block Cache is read from HDFS and the output is written back to HDFS.", "Overall once an index is hot (been online for some time) the IO for any given search is fairly small assuming that the cluster has enough memory configured in the Block Cache.", "3. Does Blur also support foreign-key like semantics to search across column-families as well as delete using row_id?", "Blur supports something called Row Queries that allow for searches across column families within single Rows.", "Take a look at this page for a better explanation: http://incubator.apache.org/blur/docs/0.2.0/data-model.html#querying", "And yes Blur supports deletes by Row check out: http://incubator.apache.org/blur/docs/0.2.0/Blur.html#Fn_Blur_mutate and http://incubator.apache.org/blur/docs/0.2.0/Blur.html#Struct_RowMutation"], "labels": [0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["3. Does Blur also support foreign-key like semantics to search across column-families as well as delete using row_id?", "Blur supports something called Row Queries that allow for searches across column families within single Rows.", "Take a look at this page for a better explanation: http://incubator.apache.org/blur/docs/0.2.0/data-model.html#querying", "And yes Blur supports deletes by Row check out: http://incubator.apache.org/blur/docs/0.2.0/Blur.html#Fn_Blur_mutate and http://incubator.apache.org/blur/docs/0.2.0/Blur.html#Struct_RowMutation", "Hopefully this can answer so of your questions."], "labels": [0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["Blur supports something called Row Queries that allow for searches across column families within single Rows.", "Take a look at this page for a better explanation: http://incubator.apache.org/blur/docs/0.2.0/data-model.html#querying", "And yes Blur supports deletes by Row check out: http://incubator.apache.org/blur/docs/0.2.0/Blur.html#Fn_Blur_mutate and http://incubator.apache.org/blur/docs/0.2.0/Blur.html#Struct_RowMutation", "Hopefully this can answer so of your questions.", "Let us know if you have any more."], "labels": [0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["Take a look at this page for a better explanation: http://incubator.apache.org/blur/docs/0.2.0/data-model.html#querying", "And yes Blur supports deletes by Row check out: http://incubator.apache.org/blur/docs/0.2.0/Blur.html#Fn_Blur_mutate and http://incubator.apache.org/blur/docs/0.2.0/Blur.html#Struct_RowMutation", "Hopefully this can answer so of your questions.", "Let us know if you have any more.", "Thanks, Aaron -- Ravi"], "labels": [0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["Hey Alex Can you provide some info on the scheduler paths thing.", "I don't have/see that issue.", "Do you mean cli paths or by cfg?", "Jira would be nice in any case.", "I don't think the dag processor respects cli parameters.", "Bolke Sent from my iPhone On 31 Jan 2017, at 15:10, Alex Van Boxel <alex@vanboxel.be wrote: It's quite hard to share my complete dags.", "I don't have this locally, but I have it in my production environment where I use Celery.", "I rolled back to beta 4 to make it work again."], "labels": [0, 0, 0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["I don't have/see that issue.", "Do you mean cli paths or by cfg?", "Jira would be nice in any case.", "I don't think the dag processor respects cli parameters.", "Bolke Sent from my iPhone On 31 Jan 2017, at 15:10, Alex Van Boxel <alex@vanboxel.be wrote: It's quite hard to share my complete dags.", "I don't have this locally, but I have it in my production environment where I use Celery.", "I rolled back to beta 4 to make it work again.", "Also @bolke the scheduler logs don't respect the log path."], "labels": [0, 0, 0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["Jira would be nice in any case.", "I don't think the dag processor respects cli parameters.", "Bolke Sent from my iPhone On 31 Jan 2017, at 15:10, Alex Van Boxel <alex@vanboxel.be wrote: It's quite hard to share my complete dags.", "I don't have this locally, but I have it in my production environment where I use Celery.", "I rolled back to beta 4 to make it work again.", "Also @bolke the scheduler logs don't respect the log path.", "On Tue, Jan 31, 2017 at 1:02 AM Dan Davydov <dan.davydov@airbnb.com.invalid wrote: @Alex I'm not able to reproduce locally (assuming the two python files are in the same folder or is on your PYTHONPATH)."], "labels": [0, 0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["Bolke Sent from my iPhone On 31 Jan 2017, at 15:10, Alex Van Boxel <alex@vanboxel.be wrote: It's quite hard to share my complete dags.", "I don't have this locally, but I have it in my production environment where I use Celery.", "I rolled back to beta 4 to make it work again.", "Also @bolke the scheduler logs don't respect the log path.", "On Tue, Jan 31, 2017 at 1:02 AM Dan Davydov <dan.davydov@airbnb.com.invalid wrote: @Alex I'm not able to reproduce locally (assuming the two python files are in the same folder or is on your PYTHONPATH).", "I don't see that import error anyways."], "labels": [0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["I don't have this locally, but I have it in my production environment where I use Celery.", "I rolled back to beta 4 to make it work again.", "Also @bolke the scheduler logs don't respect the log path.", "On Tue, Jan 31, 2017 at 1:02 AM Dan Davydov <dan.davydov@airbnb.com.invalid wrote: @Alex I'm not able to reproduce locally (assuming the two python files are in the same folder or is on your PYTHONPATH).", "I don't see that import error anyways.", "Just in case, what is your complete DAG definition?"], "labels": [0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["I rolled back to beta 4 to make it work again.", "Also @bolke the scheduler logs don't respect the log path.", "On Tue, Jan 31, 2017 at 1:02 AM Dan Davydov <dan.davydov@airbnb.com.invalid wrote: @Alex I'm not able to reproduce locally (assuming the two python files are in the same folder or is on your PYTHONPATH).", "I don't see that import error anyways.", "Just in case, what is your complete DAG definition?", "Is anyone else able to repro?"], "labels": [0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["Also @bolke the scheduler logs don't respect the log path.", "On Tue, Jan 31, 2017 at 1:02 AM Dan Davydov <dan.davydov@airbnb.com.invalid wrote: @Alex I'm not able to reproduce locally (assuming the two python files are in the same folder or is on your PYTHONPATH).", "I don't see that import error anyways.", "Just in case, what is your complete DAG definition?", "Is anyone else able to repro?", "On Mon, Jan 30, 2017 at 3:09 PM, Alex Van Boxel <alex@vanboxel.be wrote: Well this means none of my DAG's work anymore: you just can do this anymore: file bqschema.py with def marketing_segment(): return [ {\"name\": \"user_id\", \"type\": \"integer\", \"mode\": \"nullable\"}, {\"name\": \"bucket_date\", \"type\": \"timestamp\", \"mode\": \"nullable\"}, {\"name\": \"segment_main\", \"type\": \"string\", \"mode\": \"nullable\"}, {\"name\": \"segment_sub\", \"type\": \"integer\", \"mode\": \"nullable\"},"], "labels": [0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["I don't see that import error anyways.", "Just in case, what is your complete DAG definition?", "Is anyone else able to repro?", "On Mon, Jan 30, 2017 at 3:09 PM, Alex Van Boxel <alex@vanboxel.be wrote: Well this means none of my DAG's work anymore: you just can do this anymore: file bqschema.py with def marketing_segment(): return [ {\"name\": \"user_id\", \"type\": \"integer\", \"mode\": \"nullable\"}, {\"name\": \"bucket_date\", \"type\": \"timestamp\", \"mode\": \"nullable\"}, {\"name\": \"segment_main\", \"type\": \"string\", \"mode\": \"nullable\"}, {\"name\": \"segment_sub\", \"type\": \"integer\", \"mode\": \"nullable\"},", "In marketing_segmentation.py: import bqschema Gives an error: Traceback (most recent call last): File \"/usr/local/lib/python2.7/site-packages/airflow-1.8.0b5+ apache.incubating-py2.7.egg/airflow/models.py\", line 264, in process_file m = imp.load_source(mod_name, filepath) File \"/home/airflow/dags/marketing_segmentation.py\", line 17, in <module import bqschema ImportError:"], "labels": [0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["In marketing_segmentation.py: import bqschema Gives an error: Traceback (most recent call last): File \"/usr/local/lib/python2.7/site-packages/airflow-1.8.0b5+ apache.incubating-py2.7.egg/airflow/models.py\", line 264, in process_file m = imp.load_source(mod_name, filepath) File \"/home/airflow/dags/marketing_segmentation.py\", line 17, in <module import bqschema ImportError:", "No module named bqschema *I don't think this is incorrect?!*", "On Mon, Jan 30, 2017 at 11:46 PM"], "labels": [0, 0, 0], "abstract_id": 0}
{"sentences": ["No module named bqschema *I don't think this is incorrect?!*", "On Mon, Jan 30, 2017 at 11:46 PM", "Dan Davydov <dan.davydov@airbnb.com.", "invalid wrote:", "The latest commit fixed a regression since 1.7 that files with parsing errors no longer showed up on the UI.", "On Mon, Jan 30, 2017 at 2:42 PM, Alex Van Boxel <alex@vanboxel.be wrote: Just installed beta 5 on our dev environment it lighted up as a christmas tree.", "I got a a screen full of import errors."], "labels": [0, 0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["On Mon, Jan 30, 2017 at 11:46 PM", "Dan Davydov <dan.davydov@airbnb.com.", "invalid wrote:", "The latest commit fixed a regression since 1.7 that files with parsing errors no longer showed up on the UI.", "On Mon, Jan 30, 2017 at 2:42 PM, Alex Van Boxel <alex@vanboxel.be wrote: Just installed beta 5 on our dev environment it lighted up as a christmas tree.", "I got a a screen full of import errors.", "I see that the latest commit did something with import errors... is it coorect?!"], "labels": [0, 0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["Dan Davydov <dan.davydov@airbnb.com.", "invalid wrote:", "The latest commit fixed a regression since 1.7 that files with parsing errors no longer showed up on the UI.", "On Mon, Jan 30, 2017 at 2:42 PM, Alex Van Boxel <alex@vanboxel.be wrote: Just installed beta 5 on our dev environment it lighted up as a christmas tree.", "I got a a screen full of import errors.", "I see that the latest commit did something with import errors... is it coorect?!", "On Sun, Jan 29, 2017 at 4:37 PM"], "labels": [0, 0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["invalid wrote:", "The latest commit fixed a regression since 1.7 that files with parsing errors no longer showed up on the UI.", "On Mon, Jan 30, 2017 at 2:42 PM, Alex Van Boxel <alex@vanboxel.be wrote: Just installed beta 5 on our dev environment it lighted up as a christmas tree.", "I got a a screen full of import errors.", "I see that the latest commit did something with import errors... is it coorect?!", "On Sun, Jan 29, 2017 at 4:37 PM", "Bolke de Bruin <bdbruin@gmail.com wrote: Hey Boris"], "labels": [0, 0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["On Mon, Jan 30, 2017 at 2:42 PM, Alex Van Boxel <alex@vanboxel.be wrote: Just installed beta 5 on our dev environment it lighted up as a christmas tree.", "I got a a screen full of import errors.", "I see that the latest commit did something with import errors... is it coorect?!", "On Sun, Jan 29, 2017 at 4:37 PM", "Bolke de Bruin <bdbruin@gmail.com wrote: Hey Boris", "The scheduler is a bit more aggressive and can use multiple processors, so higher CPU usage is actually a good thing."], "labels": [0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["I got a a screen full of import errors.", "I see that the latest commit did something with import errors... is it coorect?!", "On Sun, Jan 29, 2017 at 4:37 PM", "Bolke de Bruin <bdbruin@gmail.com wrote: Hey Boris", "The scheduler is a bit more aggressive and can use multiple processors, so higher CPU usage is actually a good thing.", "I case it is really out of hand look at the new scheduler options and heartbeat options (see PR for updating.", "md not in the beta yet)."], "labels": [0, 0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["I see that the latest commit did something with import errors... is it coorect?!", "On Sun, Jan 29, 2017 at 4:37 PM", "Bolke de Bruin <bdbruin@gmail.com wrote: Hey Boris", "The scheduler is a bit more aggressive and can use multiple processors, so higher CPU usage is actually a good thing.", "I case it is really out of hand look at the new scheduler options and heartbeat options (see PR for updating.", "md not in the beta yet).", "Bolke Sent from my iPhone On 29 Jan 2017, at 15:35, Boris Tyukin <boris@boristyukin.com wrote: I am not sure if it is my config or something, but looks like after the upgrade and start of scheduler, airflow would totally hose CPU."], "labels": [0, 0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["On Sun, Jan 29, 2017 at 4:37 PM", "Bolke de Bruin <bdbruin@gmail.com wrote: Hey Boris", "The scheduler is a bit more aggressive and can use multiple processors, so higher CPU usage is actually a good thing.", "I case it is really out of hand look at the new scheduler options and heartbeat options (see PR for updating.", "md not in the beta yet).", "Bolke Sent from my iPhone On 29 Jan 2017, at 15:35, Boris Tyukin <boris@boristyukin.com wrote: I am not sure if it is my config or something, but looks like after the upgrade and start of scheduler, airflow would totally hose CPU.", "The reason is two new examples that start running right away - latest only and latest with trigger."], "labels": [0, 0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["The scheduler is a bit more aggressive and can use multiple processors, so higher CPU usage is actually a good thing.", "I case it is really out of hand look at the new scheduler options and heartbeat options (see PR for updating.", "md not in the beta yet).", "Bolke Sent from my iPhone On 29 Jan 2017, at 15:35, Boris Tyukin <boris@boristyukin.com wrote: I am not sure if it is my config or something, but looks like after the upgrade and start of scheduler, airflow would totally hose CPU.", "The reason is two new examples that start running right away - latest only and latest with trigger.", "Once I pause them, CPU goes back to idle."], "labels": [0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["I case it is really out of hand look at the new scheduler options and heartbeat options (see PR for updating.", "md not in the beta yet).", "Bolke Sent from my iPhone On 29 Jan 2017, at 15:35, Boris Tyukin <boris@boristyukin.com wrote: I am not sure if it is my config or something, but looks like after the upgrade and start of scheduler, airflow would totally hose CPU.", "The reason is two new examples that start running right away - latest only and latest with trigger.", "Once I pause them, CPU goes back to idle.", "Is this because now dags are not paused by default like it was before?"], "labels": [0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["md not in the beta yet).", "Bolke Sent from my iPhone On 29 Jan 2017, at 15:35, Boris Tyukin <boris@boristyukin.com wrote: I am not sure if it is my config or something, but looks like after the upgrade and start of scheduler, airflow would totally hose CPU.", "The reason is two new examples that start running right away - latest only and latest with trigger.", "Once I pause them, CPU goes back to idle.", "Is this because now dags are not paused by default like it was before?", "As I mentioned before, I also had to upgrade mysql to 5.7 - if someone needs a step by step instruction, make sure to follow all steps precisely here for in-place upgrade or you will have heck of the time (like me)."], "labels": [0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["The reason is two new examples that start running right away - latest only and latest with trigger.", "Once I pause them, CPU goes back to idle.", "Is this because now dags are not paused by default like it was before?", "As I mentioned before, I also had to upgrade mysql to 5.7 - if someone needs a step by step instruction, make sure to follow all steps precisely here for in-place upgrade or you will have heck of the time (like me).", "https://dev.mysql.com/doc/refman/5.7/en/upgrading.html# upgrade-procedure-inplace BTW official Oracle repository for Oracle Linux only has MySql 5.6 - for 5.7 you have to use MySql community repo.", "On Sat, Jan 28, 2017 at 10:07 AM, Bolke de Bruin < bdbruin@gmail.com wrote: Hi All, I have made the FIFTH beta of Airflow 1.8.0 available at: https://dist.apache.org/repos/dist/dev/incubator/airflow/ < https://dist.apache.org/repos/dist/dev/incubator/airflow/ , public keys are available at https://dist.apache.org/repos/ dist/release/incubator/ airflow/ <https://dist.apache.org/repos/dist/release/incubator/ airflow/ ."], "labels": [0, 0, 0, 0, 0, 1], "abstract_id": 0}
{"sentences": ["https://dev.mysql.com/doc/refman/5.7/en/upgrading.html# upgrade-procedure-inplace BTW official Oracle repository for Oracle Linux only has MySql 5.6 - for 5.7 you have to use MySql community repo.", "On Sat, Jan 28, 2017 at 10:07 AM, Bolke de Bruin < bdbruin@gmail.com wrote: Hi All, I have made the FIFTH beta of Airflow 1.8.0 available at: https://dist.apache.org/repos/dist/dev/incubator/airflow/ < https://dist.apache.org/repos/dist/dev/incubator/airflow/ , public keys are available at https://dist.apache.org/repos/ dist/release/incubator/ airflow/ <https://dist.apache.org/repos/dist/release/incubator/ airflow/ .", "It is tagged with a local version “apache.incubating” so it allows upgrading from earlier releases."], "labels": [0, 1, 0], "abstract_id": 0}
{"sentences": ["On Sat, Jan 28, 2017 at 10:07 AM, Bolke de Bruin < bdbruin@gmail.com wrote: Hi All, I have made the FIFTH beta of Airflow 1.8.0 available at: https://dist.apache.org/repos/dist/dev/incubator/airflow/ < https://dist.apache.org/repos/dist/dev/incubator/airflow/ , public keys are available at https://dist.apache.org/repos/ dist/release/incubator/ airflow/ <https://dist.apache.org/repos/dist/release/incubator/ airflow/ .", "It is tagged with a local version “apache.incubating” so it allows upgrading from earlier releases.", "Issues fixed: * Parsing errors not showing up in UI fixing a regression** * Scheduler would terminate immediately if no dag files present **"], "labels": [1, 0, 0], "abstract_id": 0}
{"sentences": ["It is tagged with a local version “apache.incubating” so it allows upgrading from earlier releases.", "Issues fixed: * Parsing errors not showing up in UI fixing a regression** * Scheduler would terminate immediately if no dag files present **", "As this touches the scheduler logic I though it warranted another beta.", "This should be the last beta in my opinion and we can prepare changelog, upgrade notes and release notes for the RC (Feb 2).", "Cheers Bolke -- _/ _/ Alex Van Boxel -- _/ _/ Alex Van Boxel -- _/ _/ Alex Van Boxel"], "labels": [0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["Hello, I'm interested in both serialization and deserialization of custom binary data sets.", "My understanding is that daffodil handles deserialization of data into xml - as illustrated in the nice examples at https://daffodil.apache.org/examples/.", "Does anyone know if daffodil handles serialization, as well?", "Thanks, Amy"], "labels": [0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["Raghavendra Singh created LENS-44: -------------------------------------", "Summary: should allow union of cube queries without an outer query Key: LENS-44 URL: https://issues.apache.org/jira/browse/LENS-44", "Project: Apache Lens Issue Type: Improvement Reporter: Raghavendra", "Singh currently {CODE} cube select a1 from cube1 where <condition1 union all cube select a1 from cube1 where <condition2 {CODE} does not work but {CODE} select alias.", "a1 from (cube select a1 from cube1 where <condition1 union all cube select a1 from cube1 where <condition2 ) alias {CODE} works fine --"], "labels": [0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["Summary: should allow union of cube queries without an outer query Key: LENS-44 URL: https://issues.apache.org/jira/browse/LENS-44", "Project: Apache Lens Issue Type: Improvement Reporter: Raghavendra", "Singh currently {CODE} cube select a1 from cube1 where <condition1 union all cube select a1 from cube1 where <condition2 {CODE} does not work but {CODE} select alias.", "a1 from (cube select a1 from cube1 where <condition1 union all cube select a1 from cube1 where <condition2 ) alias {CODE} works fine --", "This message was sent by Atlassian JIRA (v6.3.4#6332)"], "labels": [0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["Hi, the detailed stack trace states that you cannot serialize your Instance class due to a missing no-args constructor.", "I would recomend to follow the provided suggestion for GSON, which is : \"Register an InstanceCreator with Gson for this type to fix this problem\".", "Note that the missing no-arg constructor is also an issue when you serialize with kryo 1, so you'd have to modify the provided serializer to include custom serialization for the instance class.", "Please refer to the kryo documentation for this.", "Regards, Matthieu.", "On 9/4/12 9:19 AM, Raghavendar TS wrote: Hi In S4 0.3.0 I am trying to dispatch object of Instance."], "labels": [0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["I would recomend to follow the provided suggestion for GSON, which is : \"Register an InstanceCreator with Gson for this type to fix this problem\".", "Note that the missing no-arg constructor is also an issue when you serialize with kryo 1, so you'd have to modify the provided serializer to include custom serialization for the instance class.", "Please refer to the kryo documentation for this.", "Regards, Matthieu.", "On 9/4/12 9:19 AM, Raghavendar TS wrote: Hi In S4 0.3.0 I am trying to dispatch object of Instance.", "class from one PE to another."], "labels": [0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["Note that the missing no-arg constructor is also an issue when you serialize with kryo 1, so you'd have to modify the provided serializer to include custom serialization for the instance class.", "Please refer to the kryo documentation for this.", "Regards, Matthieu.", "On 9/4/12 9:19 AM, Raghavendar TS wrote: Hi In S4 0.3.0 I am trying to dispatch object of Instance.", "class from one PE to another.", "But it is not working.ie <http://working.ie PE2 is not receiving events from PE1 if the event consist of object of Instance.class."], "labels": [0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["Please refer to the kryo documentation for this.", "Regards, Matthieu.", "On 9/4/12 9:19 AM, Raghavendar TS wrote: Hi In S4 0.3.0 I am trying to dispatch object of Instance.", "class from one PE to another.", "But it is not working.ie <http://working.ie PE2 is not receiving events from PE1 if the event consist of object of Instance.class.", "What may be the problem?", "Also I tried using GSON to serialize objects of Instance."], "labels": [0, 0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["Regards, Matthieu.", "On 9/4/12 9:19 AM, Raghavendar TS wrote: Hi In S4 0.3.0 I am trying to dispatch object of Instance.", "class from one PE to another.", "But it is not working.ie <http://working.ie PE2 is not receiving events from PE1 if the event consist of object of Instance.class.", "What may be the problem?", "Also I tried using GSON to serialize objects of Instance.", "class to string and vice versa."], "labels": [0, 0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["On 9/4/12 9:19 AM, Raghavendar TS wrote: Hi In S4 0.3.0 I am trying to dispatch object of Instance.", "class from one PE to another.", "But it is not working.ie <http://working.ie PE2 is not receiving events from PE1 if the event consist of object of Instance.class.", "What may be the problem?", "Also I tried using GSON to serialize objects of Instance.", "class to string and vice versa.", "It is throwing the exception during deserialization Exception in thread \"main\" java.lang."], "labels": [0, 0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["class from one PE to another.", "But it is not working.ie <http://working.ie PE2 is not receiving events from PE1 if the event consist of object of Instance.class.", "What may be the problem?", "Also I tried using GSON to serialize objects of Instance.", "class to string and vice versa.", "It is throwing the exception during deserialization Exception in thread \"main\" java.lang.", "RuntimeException: No-args constructor for interface weka.core.", "Instance does not exist."], "labels": [0, 0, 0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["What may be the problem?", "Also I tried using GSON to serialize objects of Instance.", "class to string and vice versa.", "It is throwing the exception during deserialization Exception in thread \"main\" java.lang.", "RuntimeException: No-args constructor for interface weka.core.", "Instance does not exist.", "Register an InstanceCreator with Gson for this type to fix this problem.", "at com.google.gson.MappedObjectConstructor.constructWithNoArgConstructor(MappedObjectConstructor.java:64) at com.google.gson.MappedObjectConstructor.construct(MappedObjectConstructor.java:53) at com.google.gson.JsonObjectDeserializationVisitor.constructTarget(JsonObjectDeserializationVisitor.java:41) at com.google.gson.JsonDeserializationVisitor.getTarget(JsonDeserializationVisitor.java:56) at com.google.gson.ObjectNavigator.accept(ObjectNavigator.java:101) at com.google.gson.JsonDeserializationContextDefault.fromJsonObject(JsonDeserializationContextDefault.java:73) at com.google.gson.JsonDeserializationContextDefault.deserialize(JsonDeserializationContextDefault.java:51) at com.google.gson.Gson.fromJson(Gson.java:495) at com.google.gson.Gson.fromJson(Gson.java:444) at com.google.gson.Gson.fromJson(Gson.java:396) at com.google.gson.Gson.fromJson(Gson.java:372) at gson.main(gson.java:62)"], "labels": [0, 0, 0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["Instance does not exist.", "Register an InstanceCreator with Gson for this type to fix this problem.", "at com.google.gson.MappedObjectConstructor.constructWithNoArgConstructor(MappedObjectConstructor.java:64) at com.google.gson.MappedObjectConstructor.construct(MappedObjectConstructor.java:53) at com.google.gson.JsonObjectDeserializationVisitor.constructTarget(JsonObjectDeserializationVisitor.java:41) at com.google.gson.JsonDeserializationVisitor.getTarget(JsonDeserializationVisitor.java:56) at com.google.gson.ObjectNavigator.accept(ObjectNavigator.java:101) at com.google.gson.JsonDeserializationContextDefault.fromJsonObject(JsonDeserializationContextDefault.java:73) at com.google.gson.JsonDeserializationContextDefault.deserialize(JsonDeserializationContextDefault.java:51) at com.google.gson.Gson.fromJson(Gson.java:495) at com.google.gson.Gson.fromJson(Gson.java:444) at com.google.gson.Gson.fromJson(Gson.java:396) at com.google.gson.Gson.fromJson(Gson.java:372) at gson.main(gson.java:62)", "What is the problem."], "labels": [0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["What is the problem.", "How can I dispatch such objects in S4 0.3.0."], "labels": [0, 0], "abstract_id": 0}
{"sentences": ["On 06/12/10 21:15, Matthew Daniel wrote: Hello, Congratulations on your upcoming move to Apache. :-)", "I have an example source, very similar to the ExTDB[1-3].", "java files which I feel is closer to a \"hello, world\" than the three examples that ship with TDB currently.", "I think this is relevant, especially in light of questions such as these: http://tech.groups.yahoo.com/group/jena-dev/message/46166", "My example creates a new Dataset, grabs a named (but empty, of course) Model, opens the Graph for it, inserts a Statement (showing usage of the IRIFactory) and then persists everything.", "If it is run again, it then uses the ARQ API (QueryFactory et al) to show the contents of that Model."], "labels": [0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["I have an example source, very similar to the ExTDB[1-3].", "java files which I feel is closer to a \"hello, world\" than the three examples that ship with TDB currently.", "I think this is relevant, especially in light of questions such as these: http://tech.groups.yahoo.com/group/jena-dev/message/46166", "My example creates a new Dataset, grabs a named (but empty, of course) Model, opens the Graph for it, inserts a Statement (showing usage of the IRIFactory) and then persists everything.", "If it is run again, it then uses the ARQ API (QueryFactory et al) to show the contents of that Model.", "Simple, but I feel that having this kind of example will lower the cost of entry into TDB (and possibly Jena, seeing as it touches on so many of the parts)."], "labels": [0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["I think this is relevant, especially in light of questions such as these: http://tech.groups.yahoo.com/group/jena-dev/message/46166", "My example creates a new Dataset, grabs a named (but empty, of course) Model, opens the Graph for it, inserts a Statement (showing usage of the IRIFactory) and then persists everything.", "If it is run again, it then uses the ARQ API (QueryFactory et al) to show the contents of that Model.", "Simple, but I feel that having this kind of example will lower the cost of entry into TDB (and possibly Jena, seeing as it touches on so many of the parts).", "I saw the message about the Apache contributor agreement (http://sourceforge.net/mailarchive/forum.php?thread_name=4CEFC4A7.8000104%40epimorphics.com&forum_name=jena-devel) but I didn't want to jump through those hoops until I learn whether my idea would be welcome."], "labels": [0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["My example creates a new Dataset, grabs a named (but empty, of course) Model, opens the Graph for it, inserts a Statement (showing usage of the IRIFactory) and then persists everything.", "If it is run again, it then uses the ARQ API (QueryFactory et al) to show the contents of that Model.", "Simple, but I feel that having this kind of example will lower the cost of entry into TDB (and possibly Jena, seeing as it touches on so many of the parts).", "I saw the message about the Apache contributor agreement (http://sourceforge.net/mailarchive/forum.php?thread_name=4CEFC4A7.8000104%40epimorphics.com&forum_name=jena-devel) but I didn't want to jump through those hoops until I learn whether my idea would be welcome.", "It's welcome."], "labels": [0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["If it is run again, it then uses the ARQ API (QueryFactory et al) to show the contents of that Model.", "Simple, but I feel that having this kind of example will lower the cost of entry into TDB (and possibly Jena, seeing as it touches on so many of the parts).", "I saw the message about the Apache contributor agreement (http://sourceforge.net/mailarchive/forum.php?thread_name=4CEFC4A7.8000104%40epimorphics.com&forum_name=jena-devel) but I didn't want to jump through those hoops until I learn whether my idea would be welcome.", "It's welcome.", "Send it to jena-dev@groups.yahoo.com and see what the reaction is."], "labels": [0, 0, 0, 0, 1], "abstract_id": 0}
{"sentences": ["Simple, but I feel that having this kind of example will lower the cost of entry into TDB (and possibly Jena, seeing as it touches on so many of the parts).", "I saw the message about the Apache contributor agreement (http://sourceforge.net/mailarchive/forum.php?thread_name=4CEFC4A7.8000104%40epimorphics.com&forum_name=jena-devel) but I didn't want to jump through those hoops until I learn whether my idea would be welcome.", "It's welcome.", "Send it to jena-dev@groups.yahoo.com and see what the reaction is.", "For adding something like this, there is a lighter weight way."], "labels": [0, 0, 0, 1, 1], "abstract_id": 0}
{"sentences": ["I saw the message about the Apache contributor agreement (http://sourceforge.net/mailarchive/forum.php?thread_name=4CEFC4A7.8000104%40epimorphics.com&forum_name=jena-devel) but I didn't want to jump through those hoops until I learn whether my idea would be welcome.", "It's welcome.", "Send it to jena-dev@groups.yahoo.com and see what the reaction is.", "For adding something like this, there is a lighter weight way.", "Only committers need to sign an ICLA, and software grants are only needed separately for large blobs of pre-existing code."], "labels": [0, 0, 1, 1, 1], "abstract_id": 0}
{"sentences": ["It's welcome.", "Send it to jena-dev@groups.yahoo.com and see what the reaction is.", "For adding something like this, there is a lighter weight way.", "Only committers need to sign an ICLA, and software grants are only needed separately for large blobs of pre-existing code.", "When we're in Apache, you can contribute by putting it on the Jena JIRA as a patch file.", "This implies the necessary legal permission for ASF to use the patch just by the act of doing it (the Jira installation has a note about this when you create the entry, I think - we're all a bit new to Apache processes).", "Some committer then handles it - I think (we new to this ...) by making sure the project group is OK with it and then applying the patch."], "labels": [0, 1, 1, 1, 1, 1, 1], "abstract_id": 0}
{"sentences": ["For adding something like this, there is a lighter weight way.", "Only committers need to sign an ICLA, and software grants are only needed separately for large blobs of pre-existing code.", "When we're in Apache, you can contribute by putting it on the Jena JIRA as a patch file.", "This implies the necessary legal permission for ASF to use the patch just by the act of doing it (the Jira installation has a note about this when you create the entry, I think - we're all a bit new to Apache processes).", "Some committer then handles it - I think (we new to this ...) by making sure the project group is OK with it and then applying the patch.", "Or the other way round."], "labels": [1, 1, 1, 1, 1, 1], "abstract_id": 0}
{"sentences": ["When we're in Apache, you can contribute by putting it on the Jena JIRA as a patch file.", "This implies the necessary legal permission for ASF to use the patch just by the act of doing it (the Jira installation has a note about this when you create the entry, I think - we're all a bit new to Apache processes).", "Some committer then handles it - I think (we new to this ...) by making sure the project group is OK with it and then applying the patch.", "Or the other way round.", "The point is an email goes to the public development mailing list for everyone, inc committers, to see."], "labels": [1, 1, 1, 1, 1], "abstract_id": 0}
{"sentences": ["This implies the necessary legal permission for ASF to use the patch just by the act of doing it (the Jira installation has a note about this when you create the entry, I think - we're all a bit new to Apache processes).", "Some committer then handles it - I think (we new to this ...) by making sure the project group is OK with it and then applying the patch.", "Or the other way round.", "The point is an email goes to the public development mailing list for everyone, inc committers, to see.", "For added examples, it's a bit of a no-op, but it means it's \"the project\" dciding, not one person in isolation."], "labels": [1, 1, 1, 1, 1], "abstract_id": 0}
{"sentences": ["Some committer then handles it - I think (we new to this ...) by making sure the project group is OK with it and then applying the patch.", "Or the other way round.", "The point is an email goes to the public development mailing list for everyone, inc committers, to see.", "For added examples, it's a bit of a no-op, but it means it's \"the project\" dciding, not one person in isolation.", "It's no work for the contributor - they just upload patch to JIRA.", "We'd be swamped by (electronic) paperwork otherwise."], "labels": [1, 1, 1, 1, 1, 1], "abstract_id": 0}
{"sentences": ["Or the other way round.", "The point is an email goes to the public development mailing list for everyone, inc committers, to see.", "For added examples, it's a bit of a no-op, but it means it's \"the project\" dciding, not one person in isolation.", "It's no work for the contributor - they just upload patch to JIRA.", "We'd be swamped by (electronic) paperwork otherwise.", "The full details are: http://www.apache.org/foundation/getinvolved.html", "Thank you so much for all the hard work on Jena, and I hope I can improve it (even if just a little)."], "labels": [1, 1, 1, 1, 1, 1, 0], "abstract_id": 0}
{"sentences": ["For added examples, it's a bit of a no-op, but it means it's \"the project\" dciding, not one person in isolation.", "It's no work for the contributor - they just upload patch to JIRA.", "We'd be swamped by (electronic) paperwork otherwise.", "The full details are: http://www.apache.org/foundation/getinvolved.html", "Thank you so much for all the hard work on Jena, and I hope I can improve it (even if just a little).", "The more, the merrier."], "labels": [1, 1, 1, 1, 0, 0], "abstract_id": 0}
{"sentences": ["It's no work for the contributor - they just upload patch to JIRA.", "We'd be swamped by (electronic) paperwork otherwise.", "The full details are: http://www.apache.org/foundation/getinvolved.html", "Thank you so much for all the hard work on Jena, and I hope I can improve it (even if just a little).", "The more, the merrier.", "-- /v\\atthew", "Thins may be a bit slow as we get sorted out but JIRA never forgets."], "labels": [1, 1, 1, 0, 0, 0, 1], "abstract_id": 0}
{"sentences": ["We'd be swamped by (electronic) paperwork otherwise.", "The full details are: http://www.apache.org/foundation/getinvolved.html", "Thank you so much for all the hard work on Jena, and I hope I can improve it (even if just a little).", "The more, the merrier.", "-- /v\\atthew", "Thins may be a bit slow as we get sorted out but JIRA never forgets.", "If you could send it for now to jena-dev@groups.yahoo.com then submit it when we are up and running properly at Apache."], "labels": [1, 1, 0, 0, 0, 1, 1], "abstract_id": 0}
{"sentences": ["The full details are: http://www.apache.org/foundation/getinvolved.html", "Thank you so much for all the hard work on Jena, and I hope I can improve it (even if just a little).", "The more, the merrier.", "-- /v\\atthew", "Thins may be a bit slow as we get sorted out but JIRA never forgets.", "If you could send it for now to jena-dev@groups.yahoo.com then submit it when we are up and running properly at Apache.", "Andy"], "labels": [1, 0, 0, 0, 1, 1, 0], "abstract_id": 0}
{"sentences": ["Thank you Sid!", "Best regards, Ruslan On Wed, Mar 22, 2017 at 12:01 AM, siddharth anand <sanand@apache.org wrote: Ruslan,", "Thanks for sharing this list.", "I can pick a few up.", "I agree we should aim to get some of them into 1.8.1.", "-s On Tue, Mar 21, 2017 at 2:29 PM, Ruslan Dautkhanov <dautkhanov@gmail.com wrote: Some of the issues I ran into while testing 1.8rc5 : https://issues.apache.org/jira/browse/AIRFLOW-1015", "https://issues.apache.org/jira/browse/AIRFLOW-1013"], "labels": [0, 0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["Thanks for sharing this list.", "I can pick a few up.", "I agree we should aim to get some of them into 1.8.1.", "-s On Tue, Mar 21, 2017 at 2:29 PM, Ruslan Dautkhanov <dautkhanov@gmail.com wrote: Some of the issues I ran into while testing 1.8rc5 : https://issues.apache.org/jira/browse/AIRFLOW-1015", "https://issues.apache.org/jira/browse/AIRFLOW-1013", "https://issues.apache.org/jira/browse/AIRFLOW-1004", "https://issues.apache.org/jira/browse/AIRFLOW-1003"], "labels": [0, 0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["-s On Tue, Mar 21, 2017 at 2:29 PM, Ruslan Dautkhanov <dautkhanov@gmail.com wrote: Some of the issues I ran into while testing 1.8rc5 : https://issues.apache.org/jira/browse/AIRFLOW-1015", "https://issues.apache.org/jira/browse/AIRFLOW-1013", "https://issues.apache.org/jira/browse/AIRFLOW-1004", "https://issues.apache.org/jira/browse/AIRFLOW-1003", "https://issues.apache.org/jira/browse/AIRFLOW-1001"], "labels": [0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["https://issues.apache.org/jira/browse/AIRFLOW-1013", "https://issues.apache.org/jira/browse/AIRFLOW-1004", "https://issues.apache.org/jira/browse/AIRFLOW-1003", "https://issues.apache.org/jira/browse/AIRFLOW-1001", "https://issues.apache.org/jira/browse/AIRFLOW-1015", "It would be great to have at least some of them fixed in 1.8.1.", "Thank you."], "labels": [0, 0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["https://issues.apache.org/jira/browse/AIRFLOW-1004", "https://issues.apache.org/jira/browse/AIRFLOW-1003", "https://issues.apache.org/jira/browse/AIRFLOW-1001", "https://issues.apache.org/jira/browse/AIRFLOW-1015", "It would be great to have at least some of them fixed in 1.8.1.", "Thank you.", "-- Ruslan Dautkhanov On Tue, Mar 21, 2017 at 3:02 PM, Dan Davydov <dan.davydov@airbnb.com."], "labels": [0, 0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["https://issues.apache.org/jira/browse/AIRFLOW-1003", "https://issues.apache.org/jira/browse/AIRFLOW-1001", "https://issues.apache.org/jira/browse/AIRFLOW-1015", "It would be great to have at least some of them fixed in 1.8.1.", "Thank you.", "-- Ruslan Dautkhanov On Tue, Mar 21, 2017 at 3:02 PM, Dan Davydov <dan.davydov@airbnb.com.", "invalid wrote: Here is my list for targeted 1.8.1 fixes: https://issues.apache.org/jira/browse/AIRFLOW-982"], "labels": [0, 0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["https://issues.apache.org/jira/browse/AIRFLOW-1001", "https://issues.apache.org/jira/browse/AIRFLOW-1015", "It would be great to have at least some of them fixed in 1.8.1.", "Thank you.", "-- Ruslan Dautkhanov On Tue, Mar 21, 2017 at 3:02 PM, Dan Davydov <dan.davydov@airbnb.com.", "invalid wrote: Here is my list for targeted 1.8.1 fixes: https://issues.apache.org/jira/browse/AIRFLOW-982", "https://issues.apache.org/jira/browse/AIRFLOW-983"], "labels": [0, 0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["It would be great to have at least some of them fixed in 1.8.1.", "Thank you.", "-- Ruslan Dautkhanov On Tue, Mar 21, 2017 at 3:02 PM, Dan Davydov <dan.davydov@airbnb.com.", "invalid wrote: Here is my list for targeted 1.8.1 fixes: https://issues.apache.org/jira/browse/AIRFLOW-982", "https://issues.apache.org/jira/browse/AIRFLOW-983", "https://issues.apache.org/jira/browse/AIRFLOW-1019 (and in general the slow startup time from this new logic of orphaned/reset task) https://issues.apache.org/jira/browse/AIRFLOW-1017"], "labels": [0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["Thank you.", "-- Ruslan Dautkhanov On Tue, Mar 21, 2017 at 3:02 PM, Dan Davydov <dan.davydov@airbnb.com.", "invalid wrote: Here is my list for targeted 1.8.1 fixes: https://issues.apache.org/jira/browse/AIRFLOW-982", "https://issues.apache.org/jira/browse/AIRFLOW-983", "https://issues.apache.org/jira/browse/AIRFLOW-1019 (and in general the slow startup time from this new logic of orphaned/reset task) https://issues.apache.org/jira/browse/AIRFLOW-1017", "(which I will hopefully have a fix out for soon just finishing up tests)"], "labels": [0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["invalid wrote: Here is my list for targeted 1.8.1 fixes: https://issues.apache.org/jira/browse/AIRFLOW-982", "https://issues.apache.org/jira/browse/AIRFLOW-983", "https://issues.apache.org/jira/browse/AIRFLOW-1019 (and in general the slow startup time from this new logic of orphaned/reset task) https://issues.apache.org/jira/browse/AIRFLOW-1017", "(which I will hopefully have a fix out for soon just finishing up tests)", "We are also hitting a new issue with subdags with rc5 that we weren't hitting with rc4 where subdags will occasionally just hang (had to roll back from rc5 to rc4), I'll try to spin up a JIRA for it soon which should be on the list too."], "labels": [0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["https://issues.apache.org/jira/browse/AIRFLOW-983", "https://issues.apache.org/jira/browse/AIRFLOW-1019 (and in general the slow startup time from this new logic of orphaned/reset task) https://issues.apache.org/jira/browse/AIRFLOW-1017", "(which I will hopefully have a fix out for soon just finishing up tests)", "We are also hitting a new issue with subdags with rc5 that we weren't hitting with rc4 where subdags will occasionally just hang (had to roll back from rc5 to rc4), I'll try to spin up a JIRA for it soon which should be on the list too.", "On Tue, Mar 21, 2017 at 1:54 PM, Chris Riccomini < criccomini@apache.org wrote: Agreed."], "labels": [0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["https://issues.apache.org/jira/browse/AIRFLOW-1019 (and in general the slow startup time from this new logic of orphaned/reset task) https://issues.apache.org/jira/browse/AIRFLOW-1017", "(which I will hopefully have a fix out for soon just finishing up tests)", "We are also hitting a new issue with subdags with rc5 that we weren't hitting with rc4 where subdags will occasionally just hang (had to roll back from rc5 to rc4), I'll try to spin up a JIRA for it soon which should be on the list too.", "On Tue, Mar 21, 2017 at 1:54 PM, Chris Riccomini < criccomini@apache.org wrote: Agreed.", "I'm looking for a list of checksums/JIRAs that we want in the bugfix release."], "labels": [0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["(which I will hopefully have a fix out for soon just finishing up tests)", "We are also hitting a new issue with subdags with rc5 that we weren't hitting with rc4 where subdags will occasionally just hang (had to roll back from rc5 to rc4), I'll try to spin up a JIRA for it soon which should be on the list too.", "On Tue, Mar 21, 2017 at 1:54 PM, Chris Riccomini < criccomini@apache.org wrote: Agreed.", "I'm looking for a list of checksums/JIRAs that we want in the bugfix release.", "On Tue, Mar 21, 2017 at 12:54 PM, Bolke de Bruin <bdbruin@gmail.com wrote: On 21 Mar 2017, at 12:51, Bolke de Bruin <bdbruin@gmail.com wrote:"], "labels": [0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["On Tue, Mar 21, 2017 at 1:54 PM, Chris Riccomini < criccomini@apache.org wrote: Agreed.", "I'm looking for a list of checksums/JIRAs that we want in the bugfix release.", "On Tue, Mar 21, 2017 at 12:54 PM, Bolke de Bruin <bdbruin@gmail.com wrote: On 21 Mar 2017, at 12:51, Bolke de Bruin <bdbruin@gmail.com wrote:", "My suggestion, as we are using semantic versioning is: 1) no new features in the 1.8 branch 2) only bug fixes in the 1.8 branch 3) new features to land in 1.9", "This allows companies to Have a \"known\" version and can move to the new branch when they want to get new features."], "labels": [0, 0, 0, 1, 0], "abstract_id": 0}
{"sentences": ["I'm looking for a list of checksums/JIRAs that we want in the bugfix release.", "On Tue, Mar 21, 2017 at 12:54 PM, Bolke de Bruin <bdbruin@gmail.com wrote: On 21 Mar 2017, at 12:51, Bolke de Bruin <bdbruin@gmail.com wrote:", "My suggestion, as we are using semantic versioning is: 1) no new features in the 1.8 branch 2) only bug fixes in the 1.8 branch 3) new features to land in 1.9", "This allows companies to Have a \"known\" version and can move to the new branch when they want to get new features.", "Obviously we only support N-1, so when 1.10 comes out we stop supporting 1.8.X."], "labels": [0, 0, 1, 0, 1], "abstract_id": 0}
{"sentences": ["On Tue, Mar 21, 2017 at 12:54 PM, Bolke de Bruin <bdbruin@gmail.com wrote: On 21 Mar 2017, at 12:51, Bolke de Bruin <bdbruin@gmail.com wrote:", "My suggestion, as we are using semantic versioning is: 1) no new features in the 1.8 branch 2) only bug fixes in the 1.8 branch 3) new features to land in 1.9", "This allows companies to Have a \"known\" version and can move to the new branch when they want to get new features.", "Obviously we only support N-1, so when 1.10 comes out we stop supporting 1.8.X.", "Sent from my iPhone On 21 Mar 2017, at 11:22, Chris Riccomini < criccomini@apache.org wrote: Hey all, I suggest that we start a 1.8.1 Airflow release now."], "labels": [0, 1, 0, 1, 0], "abstract_id": 0}
{"sentences": ["My suggestion, as we are using semantic versioning is: 1) no new features in the 1.8 branch 2) only bug fixes in the 1.8 branch 3) new features to land in 1.9", "This allows companies to Have a \"known\" version and can move to the new branch when they want to get new features.", "Obviously we only support N-1, so when 1.10 comes out we stop supporting 1.8.X.", "Sent from my iPhone On 21 Mar 2017, at 11:22, Chris Riccomini < criccomini@apache.org wrote: Hey all, I suggest that we start a 1.8.1 Airflow release now.", "The goal would be: 1) get a second release under our belt 2) patch known issues with the 1.8.0 release I'm happy to run it, but I saw Maxime mentioning that Airbnb might want to."], "labels": [1, 0, 1, 0, 0], "abstract_id": 0}
{"sentences": ["This allows companies to Have a \"known\" version and can move to the new branch when they want to get new features.", "Obviously we only support N-1, so when 1.10 comes out we stop supporting 1.8.X.", "Sent from my iPhone On 21 Mar 2017, at 11:22, Chris Riccomini < criccomini@apache.org wrote: Hey all, I suggest that we start a 1.8.1 Airflow release now.", "The goal would be: 1) get a second release under our belt 2) patch known issues with the 1.8.0 release I'm happy to run it, but I saw Maxime mentioning that Airbnb might want to.", "@Max et al, can you comment?"], "labels": [0, 1, 0, 0, 0], "abstract_id": 0}
{"sentences": ["Obviously we only support N-1, so when 1.10 comes out we stop supporting 1.8.X.", "Sent from my iPhone On 21 Mar 2017, at 11:22, Chris Riccomini < criccomini@apache.org wrote: Hey all, I suggest that we start a 1.8.1 Airflow release now.", "The goal would be: 1) get a second release under our belt 2) patch known issues with the 1.8.0 release I'm happy to run it, but I saw Maxime mentioning that Airbnb might want to.", "@Max et al, can you comment?", "Also, can folks supply JIRAs for stuff that think needs to be in the 1.8.1 bugfix release?"], "labels": [1, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["Sent from my iPhone On 21 Mar 2017, at 11:22, Chris Riccomini < criccomini@apache.org wrote: Hey all, I suggest that we start a 1.8.1 Airflow release now.", "The goal would be: 1) get a second release under our belt 2) patch known issues with the 1.8.0 release I'm happy to run it, but I saw Maxime mentioning that Airbnb might want to.", "@Max et al, can you comment?", "Also, can folks supply JIRAs for stuff that think needs to be in the 1.8.1 bugfix release?", "Cheers, Chris"], "labels": [0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["Yes it does help.", "Thanks Robin!", "I struggled a little on account of having to pass this parameter as a dict but I figured it out and I can copy what you did to create the JIRA ticket and PR.", "Thanks again!", "On Wed, Mar 8, 2017 at 1:15 AM, Miller, Robin < Robin.Miller@affiliate.oliverwyman.com wrote: Hi Desiree,", "It sounds to me like you'll probably need to add an additional configuration option to pass to Celery.", "In the file airflow/executors/celery_executor.py you can see all of the config options that are passed into Airflow in the CeleryConfig class."], "labels": [0, 0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["Thanks Robin!", "I struggled a little on account of having to pass this parameter as a dict but I figured it out and I can copy what you did to create the JIRA ticket and PR.", "Thanks again!", "On Wed, Mar 8, 2017 at 1:15 AM, Miller, Robin < Robin.Miller@affiliate.oliverwyman.com wrote: Hi Desiree,", "It sounds to me like you'll probably need to add an additional configuration option to pass to Celery.", "In the file airflow/executors/celery_executor.py you can see all of the config options that are passed into Airflow in the CeleryConfig class.", "I've currently got a PR open for a change of this nature at the moment: https://github.com/apache/incubator-airflow/pull/1912/files"], "labels": [0, 0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["Thanks again!", "On Wed, Mar 8, 2017 at 1:15 AM, Miller, Robin < Robin.Miller@affiliate.oliverwyman.com wrote: Hi Desiree,", "It sounds to me like you'll probably need to add an additional configuration option to pass to Celery.", "In the file airflow/executors/celery_executor.py you can see all of the config options that are passed into Airflow in the CeleryConfig class.", "I've currently got a PR open for a change of this nature at the moment: https://github.com/apache/incubator-airflow/pull/1912/files", "<https://github.com/apache/incubator-airflow/pull/1912/files."], "labels": [0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["It sounds to me like you'll probably need to add an additional configuration option to pass to Celery.", "In the file airflow/executors/celery_executor.py you can see all of the config options that are passed into Airflow in the CeleryConfig class.", "I've currently got a PR open for a change of this nature at the moment: https://github.com/apache/incubator-airflow/pull/1912/files", "<https://github.com/apache/incubator-airflow/pull/1912/files.", "Hope this helps, Robin Miller OLIVER WYMAN robin.miller@affiliate.oliverwyman.com<mailto:robin."], "labels": [0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["In the file airflow/executors/celery_executor.py you can see all of the config options that are passed into Airflow in the CeleryConfig class.", "I've currently got a PR open for a change of this nature at the moment: https://github.com/apache/incubator-airflow/pull/1912/files", "<https://github.com/apache/incubator-airflow/pull/1912/files.", "Hope this helps, Robin Miller OLIVER WYMAN robin.miller@affiliate.oliverwyman.com<mailto:robin.", "miller@affiliate.oliverwyman.com"], "labels": [0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["I've currently got a PR open for a change of this nature at the moment: https://github.com/apache/incubator-airflow/pull/1912/files", "<https://github.com/apache/incubator-airflow/pull/1912/files.", "Hope this helps, Robin Miller OLIVER WYMAN robin.miller@affiliate.oliverwyman.com<mailto:robin.", "miller@affiliate.oliverwyman.com", "www.oliverwyman.com<http://www.oliverwyman.com/", "<http://www.oliverwyman.com/"], "labels": [0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["<https://github.com/apache/incubator-airflow/pull/1912/files.", "Hope this helps, Robin Miller OLIVER WYMAN robin.miller@affiliate.oliverwyman.com<mailto:robin.", "miller@affiliate.oliverwyman.com", "www.oliverwyman.com<http://www.oliverwyman.com/", "<http://www.oliverwyman.com/", "________________________________", "From: Desiree Cox <dcox@zendesk.com.INVALID Sent: 07 March 2017 18:22:03 To: dev@airflow.incubator.apache.org"], "labels": [0, 0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["Hope this helps, Robin Miller OLIVER WYMAN robin.miller@affiliate.oliverwyman.com<mailto:robin.", "miller@affiliate.oliverwyman.com", "www.oliverwyman.com<http://www.oliverwyman.com/", "<http://www.oliverwyman.com/", "________________________________", "From: Desiree Cox <dcox@zendesk.com.INVALID Sent: 07 March 2017 18:22:03 To: dev@airflow.incubator.apache.org", "Subject:"], "labels": [0, 0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["miller@affiliate.oliverwyman.com", "www.oliverwyman.com<http://www.oliverwyman.com/", "<http://www.oliverwyman.com/", "________________________________", "From: Desiree Cox <dcox@zendesk.com.INVALID Sent: 07 March 2017 18:22:03 To: dev@airflow.incubator.apache.org", "Subject:", "Is anybody using CeleryExecutor + redis-sentinel message broker?"], "labels": [0, 0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["<http://www.oliverwyman.com/", "________________________________", "From: Desiree Cox <dcox@zendesk.com.INVALID Sent: 07 March 2017 18:22:03 To: dev@airflow.incubator.apache.org", "Subject:", "Is anybody using CeleryExecutor + redis-sentinel message broker?", "Hello!", "I am a very new engineer at my company and I have been asked to set up Airflow with Celery."], "labels": [0, 0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["From: Desiree Cox <dcox@zendesk.com.INVALID Sent: 07 March 2017 18:22:03 To: dev@airflow.incubator.apache.org", "Subject:", "Is anybody using CeleryExecutor + redis-sentinel message broker?", "Hello!", "I am a very new engineer at my company and I have been asked to set up Airflow with Celery.", "We have existing Redis resources for the message broker, but I am not allowed to connect to redis directly, I must do it through redis-sentinel.", "Celery 4 can use redis-sentinel but I don't see how to pass the configuration through Airflow—you have to send it a dictionary called 'broker_transport_options' with the name of the Redis service you are looking for."], "labels": [0, 0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["Subject:", "Is anybody using CeleryExecutor + redis-sentinel message broker?", "Hello!", "I am a very new engineer at my company and I have been asked to set up Airflow with Celery.", "We have existing Redis resources for the message broker, but I am not allowed to connect to redis directly, I must do it through redis-sentinel.", "Celery 4 can use redis-sentinel but I don't see how to pass the configuration through Airflow—you have to send it a dictionary called 'broker_transport_options' with the name of the Redis service you are looking for.", "Has anybody gotten the CeleryExecutor working with redis-sentinel?"], "labels": [0, 0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["Is anybody using CeleryExecutor + redis-sentinel message broker?", "Hello!", "I am a very new engineer at my company and I have been asked to set up Airflow with Celery.", "We have existing Redis resources for the message broker, but I am not allowed to connect to redis directly, I must do it through redis-sentinel.", "Celery 4 can use redis-sentinel but I don't see how to pass the configuration through Airflow—you have to send it a dictionary called 'broker_transport_options' with the name of the Redis service you are looking for.", "Has anybody gotten the CeleryExecutor working with redis-sentinel?", "My teammate says I should contribute a PR to Airflow (which I am happy to try) but I want to check in case anybody has suggestions."], "labels": [0, 0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["We have existing Redis resources for the message broker, but I am not allowed to connect to redis directly, I must do it through redis-sentinel.", "Celery 4 can use redis-sentinel but I don't see how to pass the configuration through Airflow—you have to send it a dictionary called 'broker_transport_options' with the name of the Redis service you are looking for.", "Has anybody gotten the CeleryExecutor working with redis-sentinel?", "My teammate says I should contribute a PR to Airflow (which I am happy to try) but I want to check in case anybody has suggestions.", "Thank you!"], "labels": [0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["Celery 4 can use redis-sentinel but I don't see how to pass the configuration through Airflow—you have to send it a dictionary called 'broker_transport_options' with the name of the Redis service you are looking for.", "Has anybody gotten the CeleryExecutor working with redis-sentinel?", "My teammate says I should contribute a PR to Airflow (which I am happy to try) but I want to check in case anybody has suggestions.", "Thank you!", "-- Desiree Cox Associate Software Engineer Zendesk ________________________________"], "labels": [0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["Has anybody gotten the CeleryExecutor working with redis-sentinel?", "My teammate says I should contribute a PR to Airflow (which I am happy to try) but I want to check in case anybody has suggestions.", "Thank you!", "-- Desiree Cox Associate Software Engineer Zendesk ________________________________", "This e-mail and any attachments may be confidential or legally privileged.", "If you received this message in error or are not the intended recipient, you should destroy the e-mail message and any attachments or copies, and you are prohibited from retaining, distributing, disclosing or using any information contained herein."], "labels": [0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["My teammate says I should contribute a PR to Airflow (which I am happy to try) but I want to check in case anybody has suggestions.", "Thank you!", "-- Desiree Cox Associate Software Engineer Zendesk ________________________________", "This e-mail and any attachments may be confidential or legally privileged.", "If you received this message in error or are not the intended recipient, you should destroy the e-mail message and any attachments or copies, and you are prohibited from retaining, distributing, disclosing or using any information contained herein.", "Please inform us of the erroneous delivery by return e-mail."], "labels": [0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["Thank you!", "-- Desiree Cox Associate Software Engineer Zendesk ________________________________", "This e-mail and any attachments may be confidential or legally privileged.", "If you received this message in error or are not the intended recipient, you should destroy the e-mail message and any attachments or copies, and you are prohibited from retaining, distributing, disclosing or using any information contained herein.", "Please inform us of the erroneous delivery by return e-mail.", "Thank you for your cooperation."], "labels": [0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["This e-mail and any attachments may be confidential or legally privileged.", "If you received this message in error or are not the intended recipient, you should destroy the e-mail message and any attachments or copies, and you are prohibited from retaining, distributing, disclosing or using any information contained herein.", "Please inform us of the erroneous delivery by return e-mail.", "Thank you for your cooperation.", "-- Desiree Cox Associate Software Engineer Zendesk"], "labels": [0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["That's all very viable indeed.", "1. TOSCA is an OASIS standard specification for cloud orchestration, consisting of a rich object-oriented modeling grammar as well as a recommended Simple Profile of base types.", "2. ARIA is a straightforward implementation of a TOSCA parser and orchestrator, currently an Apache incubator project.", "3. Cloudify is a mature and feature-rich cloud orchestrator (Apache-licensed, currently at version 4.1) that uses a TOSCA-inspired language, but not real TOSCA.", "Because ARIA is still quite new and missing supporting plugins for various technologies (Docker, Openstack, AWS, Puppet, Chef, Juju, etc.) we have created an adapter layer that help us use Cloudify plugins in ARIA.", "We consider this a temporary measure and intend to re-implement all these plugins natively for ARIA, as extensions in the repository."], "labels": [0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["2. ARIA is a straightforward implementation of a TOSCA parser and orchestrator, currently an Apache incubator project.", "3. Cloudify is a mature and feature-rich cloud orchestrator (Apache-licensed, currently at version 4.1) that uses a TOSCA-inspired language, but not real TOSCA.", "Because ARIA is still quite new and missing supporting plugins for various technologies (Docker, Openstack, AWS, Puppet, Chef, Juju, etc.) we have created an adapter layer that help us use Cloudify plugins in ARIA.", "We consider this a temporary measure and intend to re-implement all these plugins natively for ARIA, as extensions in the repository.", "We're still building up our documentation on the wiki, as well as our list of examples."], "labels": [0, 0, 0, 0, 1], "abstract_id": 0}
{"sentences": ["3. Cloudify is a mature and feature-rich cloud orchestrator (Apache-licensed, currently at version 4.1) that uses a TOSCA-inspired language, but not real TOSCA.", "Because ARIA is still quite new and missing supporting plugins for various technologies (Docker, Openstack, AWS, Puppet, Chef, Juju, etc.) we have created an adapter layer that help us use Cloudify plugins in ARIA.", "We consider this a temporary measure and intend to re-implement all these plugins natively for ARIA, as extensions in the repository.", "We're still building up our documentation on the wiki, as well as our list of examples.", "We currently have a Hello World for Openstack, but not one for Docker yet."], "labels": [0, 0, 0, 1, 0], "abstract_id": 0}
{"sentences": ["Because ARIA is still quite new and missing supporting plugins for various technologies (Docker, Openstack, AWS, Puppet, Chef, Juju, etc.) we have created an adapter layer that help us use Cloudify plugins in ARIA.", "We consider this a temporary measure and intend to re-implement all these plugins natively for ARIA, as extensions in the repository.", "We're still building up our documentation on the wiki, as well as our list of examples.", "We currently have a Hello World for Openstack, but not one for Docker yet.", "Have you tried the Openstack example?"], "labels": [0, 0, 1, 0, 0], "abstract_id": 0}
{"sentences": ["We consider this a temporary measure and intend to re-implement all these plugins natively for ARIA, as extensions in the repository.", "We're still building up our documentation on the wiki, as well as our list of examples.", "We currently have a Hello World for Openstack, but not one for Docker yet.", "Have you tried the Openstack example?", "https://cwiki.apache.org/confluence/display/ARIATOSCA/OpenStack+Hello+World On Fri, Aug 4, 2017 at 4:17 AM, chbndrhnns <code+apache@rueschel.de wrote:", "Hi there, I am just about to start digging into TOSCA, ARIA and Cloudify and stuff and I am still a bit confused about it all works together (or not)."], "labels": [0, 1, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["We're still building up our documentation on the wiki, as well as our list of examples.", "We currently have a Hello World for Openstack, but not one for Docker yet.", "Have you tried the Openstack example?", "https://cwiki.apache.org/confluence/display/ARIATOSCA/OpenStack+Hello+World On Fri, Aug 4, 2017 at 4:17 AM, chbndrhnns <code+apache@rueschel.de wrote:", "Hi there, I am just about to start digging into TOSCA, ARIA and Cloudify and stuff and I am still a bit confused about it all works together (or not).", "I can get the `hello-world` example to run locally and now I would like to connect to a Docker instance, pull an image and run workflows either via ssh on that container or via the Docker plugin."], "labels": [1, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["We currently have a Hello World for Openstack, but not one for Docker yet.", "Have you tried the Openstack example?", "https://cwiki.apache.org/confluence/display/ARIATOSCA/OpenStack+Hello+World On Fri, Aug 4, 2017 at 4:17 AM, chbndrhnns <code+apache@rueschel.de wrote:", "Hi there, I am just about to start digging into TOSCA, ARIA and Cloudify and stuff and I am still a bit confused about it all works together (or not).", "I can get the `hello-world` example to run locally and now I would like to connect to a Docker instance, pull an image and run workflows either via ssh on that container or via the Docker plugin.", "Is that a viable use case and can someone provide me with a hello world, as well?"], "labels": [0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["Hi there, I am just about to start digging into TOSCA, ARIA and Cloudify and stuff and I am still a bit confused about it all works together (or not).", "I can get the `hello-world` example to run locally and now I would like to connect to a Docker instance, pull an image and run workflows either via ssh on that container or via the Docker plugin.", "Is that a viable use case and can someone provide me with a hello world, as well?", "Bye, Jo"], "labels": [0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["Right.. I'm \"sanand\" in JIRA.", "Assigned to self.", "-s On Sat, May 28, 2016 at 8:28 PM, Cyril Scetbon <cyril.scetbon@free.fr wrote: Hey, I've created the JIRA https://issues.apache.org/jira/browse/AIRFLOW-188, but Jira can't find your user id when I try to assign it to you.", "Did you make a mistake ?", "On May 27, 2016, at 23:24, siddharth anand <sanand@apache.org wrote: Cyril, Can you create a Jira for this?", "We need a way to reproduce this."], "labels": [0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["Assigned to self.", "-s On Sat, May 28, 2016 at 8:28 PM, Cyril Scetbon <cyril.scetbon@free.fr wrote: Hey, I've created the JIRA https://issues.apache.org/jira/browse/AIRFLOW-188, but Jira can't find your user id when I try to assign it to you.", "Did you make a mistake ?", "On May 27, 2016, at 23:24, siddharth anand <sanand@apache.org wrote: Cyril, Can you create a Jira for this?", "We need a way to reproduce this.", "Please add your backend db (e.g. sqlite or something else) and an example of your code -- the one you are trying to clear."], "labels": [0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["Did you make a mistake ?", "On May 27, 2016, at 23:24, siddharth anand <sanand@apache.org wrote: Cyril, Can you create a Jira for this?", "We need a way to reproduce this.", "Please add your backend db (e.g. sqlite or something else) and an example of your code -- the one you are trying to clear.", "Then assign the bug to me (r39132).", "This may be related to the recursive clear of subdags, which was merged in https://github.com/apache/incubator-airflow/pull/1478", "I mention in that PR the need to implement the CLI as well and this might be a result of a half-implemented feature (i.e. works for UI, but not for CLI)."], "labels": [0, 0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["We need a way to reproduce this.", "Please add your backend db (e.g. sqlite or something else) and an example of your code -- the one you are trying to clear.", "Then assign the bug to me (r39132).", "This may be related to the recursive clear of subdags, which was merged in https://github.com/apache/incubator-airflow/pull/1478", "I mention in that PR the need to implement the CLI as well and this might be a result of a half-implemented feature (i.e. works for UI, but not for CLI).", "If you provide your code example, I can verify if this is the case."], "labels": [0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["Please add your backend db (e.g. sqlite or something else) and an example of your code -- the one you are trying to clear.", "Then assign the bug to me (r39132).", "This may be related to the recursive clear of subdags, which was merged in https://github.com/apache/incubator-airflow/pull/1478", "I mention in that PR the need to implement the CLI as well and this might be a result of a half-implemented feature (i.e. works for UI, but not for CLI).", "If you provide your code example, I can verify if this is the case.", "-s On Fri, May 27, 2016 at 3:23 PM, Cyril Scetbon <cyril.scetbon@free.fr wrote: Hi,"], "labels": [0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["Then assign the bug to me (r39132).", "This may be related to the recursive clear of subdags, which was merged in https://github.com/apache/incubator-airflow/pull/1478", "I mention in that PR the need to implement the CLI as well and this might be a result of a half-implemented feature (i.e. works for UI, but not for CLI).", "If you provide your code example, I can verify if this is the case.", "-s On Fri, May 27, 2016 at 3:23 PM, Cyril Scetbon <cyril.scetbon@free.fr wrote: Hi,", "When I try to clear the past of a task I get a Oops."], "labels": [0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["I mention in that PR the need to implement the CLI as well and this might be a result of a half-implemented feature (i.e. works for UI, but not for CLI).", "If you provide your code example, I can verify if this is the case.", "-s On Fri, May 27, 2016 at 3:23 PM, Cyril Scetbon <cyril.scetbon@free.fr wrote: Hi,", "When I try to clear the past of a task I get a Oops.", "Here is the output I get : http://pastebin.com/yTYsekyB", "I'm using Airflow 1.7.0 and my dag contains a SubDagOperator with a subdag containing a BashOperator"], "labels": [0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["If you provide your code example, I can verify if this is the case.", "-s On Fri, May 27, 2016 at 3:23 PM, Cyril Scetbon <cyril.scetbon@free.fr wrote: Hi,", "When I try to clear the past of a task I get a Oops.", "Here is the output I get : http://pastebin.com/yTYsekyB", "I'm using Airflow 1.7.0 and my dag contains a SubDagOperator with a subdag containing a BashOperator", "Is it a known issue ?"], "labels": [0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["-s On Fri, May 27, 2016 at 3:23 PM, Cyril Scetbon <cyril.scetbon@free.fr wrote: Hi,", "When I try to clear the past of a task I get a Oops.", "Here is the output I get : http://pastebin.com/yTYsekyB", "I'm using Airflow 1.7.0 and my dag contains a SubDagOperator with a subdag containing a BashOperator", "Is it a known issue ?", "Thanks"], "labels": [0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["Sure thing.", "Current Behavior: - User creates DAG with default_args start date to 2015 - dagrun gets kicked off for 2015 - User changes default_args start date to 2016 - dagruns continue running for 2015 New Behavior: - User creates DAG with default_args start date to 2015 - dagrun gets kicked off for 2015 - User changes default_args start date to 2016 - *dagruns start running for the 2016 start date instead of 2015*", "On Tue, Mar 7, 2017 at 11:49 AM, Bolke de Bruin <bdbruin@gmail.com wrote: Hey Dan,", "Im not sure if I am seeing a difference for #1 vs now, except you are excluding backfills now from the calculation?", "Can you provide an example?"], "labels": [0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["On Tue, Mar 7, 2017 at 11:49 AM, Bolke de Bruin <bdbruin@gmail.com wrote: Hey Dan,", "Im not sure if I am seeing a difference for #1 vs now, except you are excluding backfills now from the calculation?", "Can you provide an example?", "Bolke On 7 Mar 2017, at 20:38, Dan Davydov <dan.davydov@airbnb.com.INVALID wrote: A very common source of confusion for our users is when they specify start_date in default_args but not in their DAG arguments and then try to change this start_date to move the execution of their DAG forward (e.g. from 2015 to 2016).", "This doesn't work because the logic that is used to calculate the \"initial\" start date of a dag differs from the logic to calculate subsequent dagrun start dates."], "labels": [0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["Im not sure if I am seeing a difference for #1 vs now, except you are excluding backfills now from the calculation?", "Can you provide an example?", "Bolke On 7 Mar 2017, at 20:38, Dan Davydov <dan.davydov@airbnb.com.INVALID wrote: A very common source of confusion for our users is when they specify start_date in default_args but not in their DAG arguments and then try to change this start_date to move the execution of their DAG forward (e.g. from 2015 to 2016).", "This doesn't work because the logic that is used to calculate the \"initial\" start date of a dag differs from the logic to calculate subsequent dagrun start dates.", "Current Airflow Logic: DS to schedule initial dagrun: dag.start_date if it exists, else min(start date of tasks_of_dag) DS to schedule subsequent dagruns: last_dagrun + scheduled_interval"], "labels": [0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["Can you provide an example?", "Bolke On 7 Mar 2017, at 20:38, Dan Davydov <dan.davydov@airbnb.com.INVALID wrote: A very common source of confusion for our users is when they specify start_date in default_args but not in their DAG arguments and then try to change this start_date to move the execution of their DAG forward (e.g. from 2015 to 2016).", "This doesn't work because the logic that is used to calculate the \"initial\" start date of a dag differs from the logic to calculate subsequent dagrun start dates.", "Current Airflow Logic: DS to schedule initial dagrun: dag.start_date if it exists, else min(start date of tasks_of_dag) DS to schedule subsequent dagruns: last_dagrun + scheduled_interval", "There are a couple ways of addressing this: 1. Change the definition of start date for subsequent dagruns to match the \"initial\" dagrun start date (calculated from the minimum of task start dates)"], "labels": [0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["This doesn't work because the logic that is used to calculate the \"initial\" start date of a dag differs from the logic to calculate subsequent dagrun start dates.", "Current Airflow Logic: DS to schedule initial dagrun: dag.start_date if it exists, else min(start date of tasks_of_dag) DS to schedule subsequent dagruns: last_dagrun + scheduled_interval", "There are a couple ways of addressing this: 1. Change the definition of start date for subsequent dagruns to match the \"initial\" dagrun start date (calculated from the minimum of task start dates)", "2. Force explicit dag start dates I personally like 1.", "I also propose that we throw errors for DAGs that have tasks that depend on other tasks with start dates that occur after theirs (otherwise there could be deadlocks)."], "labels": [0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["Current Airflow Logic: DS to schedule initial dagrun: dag.start_date if it exists, else min(start date of tasks_of_dag) DS to schedule subsequent dagruns: last_dagrun + scheduled_interval", "There are a couple ways of addressing this: 1. Change the definition of start date for subsequent dagruns to match the \"initial\" dagrun start date (calculated from the minimum of task start dates)", "2. Force explicit dag start dates I personally like 1.", "I also propose that we throw errors for DAGs that have tasks that depend on other tasks with start dates that occur after theirs (otherwise there could be deadlocks).", "What do people think?"], "labels": [0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["Hi Bolke, Here is the JIRA issue, https://issues.apache.org/jira/browse/AIRFLOW-747.", "Harvey Xia | Software Engineer harveyxia@spotify.com +1 (339) 225 1875 On Wed, Jan 11, 2017 at 11:32 AM, Bolke de Bruin <bdbruin@gmail.com wrote: Hi Harvey,", "Thanks for reporting!", "Can you create a lira for this?", "I’ll have a look if I can reproduce it.", "- Bolke On 11 Jan 2017, at 16:06, Harvey Xia <harveyxia@spotify.com.INVALID wrote: Hi all, In Airflow 1.8 alpha 2, using LocalExecutor, DAGs do not seem to honor the retry_delay parameter, i.e. the retries happen immediately one after the other without waiting the specific retry_delay time."], "labels": [0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["Harvey Xia | Software Engineer harveyxia@spotify.com +1 (339) 225 1875 On Wed, Jan 11, 2017 at 11:32 AM, Bolke de Bruin <bdbruin@gmail.com wrote: Hi Harvey,", "Thanks for reporting!", "Can you create a lira for this?", "I’ll have a look if I can reproduce it.", "- Bolke On 11 Jan 2017, at 16:06, Harvey Xia <harveyxia@spotify.com.INVALID wrote: Hi all, In Airflow 1.8 alpha 2, using LocalExecutor, DAGs do not seem to honor the retry_delay parameter, i.e. the retries happen immediately one after the other without waiting the specific retry_delay time.", "However, the *number* of retries is honored."], "labels": [0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["Thanks for reporting!", "Can you create a lira for this?", "I’ll have a look if I can reproduce it.", "- Bolke On 11 Jan 2017, at 16:06, Harvey Xia <harveyxia@spotify.com.INVALID wrote: Hi all, In Airflow 1.8 alpha 2, using LocalExecutor, DAGs do not seem to honor the retry_delay parameter, i.e. the retries happen immediately one after the other without waiting the specific retry_delay time.", "However, the *number* of retries is honored.", "I am testing with the following code: from airflow import DAG from airflow.operators.bash_operator import BashOperator from datetime import datetime, timedelta default_args = { 'owner': 'airflow', 'depends_on_past': False, 'start_date': datetime(2016, 10, 5, 19), 'end_date': datetime(2016, 10, 6, 19), 'email': ['airflow@airflow.com'], 'email_on_failure': False, 'email_on_retry': False, 'retries': 10, 'retry_delay': timedelta(0, 500) } dag = DAG('test_retry_handling_job', default_args=default_args, schedule_interval='@once') task1 = BashOperator( task_id='test_retry_handling_op1', bash_command='exit 1', dag=dag) task2 = BashOperator( task_id='test_retry_handling_op2', bash_command='exit 1', dag=dag) task2.set_upstream(task1)"], "labels": [0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["However, the *number* of retries is honored.", "I am testing with the following code: from airflow import DAG from airflow.operators.bash_operator import BashOperator from datetime import datetime, timedelta default_args = { 'owner': 'airflow', 'depends_on_past': False, 'start_date': datetime(2016, 10, 5, 19), 'end_date': datetime(2016, 10, 6, 19), 'email': ['airflow@airflow.com'], 'email_on_failure': False, 'email_on_retry': False, 'retries': 10, 'retry_delay': timedelta(0, 500) } dag = DAG('test_retry_handling_job', default_args=default_args, schedule_interval='@once') task1 = BashOperator( task_id='test_retry_handling_op1', bash_command='exit 1', dag=dag) task2 = BashOperator( task_id='test_retry_handling_op2', bash_command='exit 1', dag=dag) task2.set_upstream(task1)", "Let me know if anyone has any ideas about this issue, thanks!"], "labels": [0, 0, 0], "abstract_id": 0}
{"sentences": ["Let me know if anyone has any ideas about this issue, thanks!", "Harvey Xia | Software Engineer harveyxia@spotify.com +1 (339) 225 1875"], "labels": [0, 0], "abstract_id": 0}
{"sentences": ["About structuring memory use: we have some major chunks of code set up as web services.", "We have a separate machine that runs one service (a Java-based app) and is limited to running 20 at once so that we can't run out of ram.", "Our installation uses a separate Docker container for each Airflow app.", "Docker includes quotas for containers but we have not used them yet (cgroups).", "This feature allows us to allocate X amount of space for each app, so one unruly app cannot crash the whole Airflow service.", "On Fri, Jun 3, 2016 at 9:41 AM, Dennis O'Brien <dennis@dennisobrien.net wrote:"], "labels": [0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["We have a separate machine that runs one service (a Java-based app) and is limited to running 20 at once so that we can't run out of ram.", "Our installation uses a separate Docker container for each Airflow app.", "Docker includes quotas for containers but we have not used them yet (cgroups).", "This feature allows us to allocate X amount of space for each app, so one unruly app cannot crash the whole Airflow service.", "On Fri, Jun 3, 2016 at 9:41 AM, Dennis O'Brien <dennis@dennisobrien.net wrote:", "Thanks very much for the help."], "labels": [0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["Our installation uses a separate Docker container for each Airflow app.", "Docker includes quotas for containers but we have not used them yet (cgroups).", "This feature allows us to allocate X amount of space for each app, so one unruly app cannot crash the whole Airflow service.", "On Fri, Jun 3, 2016 at 9:41 AM, Dennis O'Brien <dennis@dennisobrien.net wrote:", "Thanks very much for the help.", "It seems I had two errors happening here.", "First, as Mattias pointed out, I was doing it wrong with the jinja2."], "labels": [0, 0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["Docker includes quotas for containers but we have not used them yet (cgroups).", "This feature allows us to allocate X amount of space for each app, so one unruly app cannot crash the whole Airflow service.", "On Fri, Jun 3, 2016 at 9:41 AM, Dennis O'Brien <dennis@dennisobrien.net wrote:", "Thanks very much for the help.", "It seems I had two errors happening here.", "First, as Mattias pointed out, I was doing it wrong with the jinja2.", "PackageLoader."], "labels": [0, 0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["This feature allows us to allocate X amount of space for each app, so one unruly app cannot crash the whole Airflow service.", "On Fri, Jun 3, 2016 at 9:41 AM, Dennis O'Brien <dennis@dennisobrien.net wrote:", "Thanks very much for the help.", "It seems I had two errors happening here.", "First, as Mattias pointed out, I was doing it wrong with the jinja2.", "PackageLoader.", "(It's always embarrassing to email a dev list when the error is somewhere entirely different.)"], "labels": [0, 0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["On Fri, Jun 3, 2016 at 9:41 AM, Dennis O'Brien <dennis@dennisobrien.net wrote:", "Thanks very much for the help.", "It seems I had two errors happening here.", "First, as Mattias pointed out, I was doing it wrong with the jinja2.", "PackageLoader.", "(It's always embarrassing to email a dev list when the error is somewhere entirely different.)", "I switched to jinja2.", "FileLoader and it worked."], "labels": [0, 0, 0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["Thanks very much for the help.", "It seems I had two errors happening here.", "First, as Mattias pointed out, I was doing it wrong with the jinja2.", "PackageLoader.", "(It's always embarrassing to email a dev list when the error is somewhere entirely different.)", "I switched to jinja2.", "FileLoader and it worked.", "My other issue was from an out-of-memory problem.", "This wasn't obvious from the task instance log, but when I found it when running the job command line."], "labels": [0, 0, 0, 0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["It seems I had two errors happening here.", "First, as Mattias pointed out, I was doing it wrong with the jinja2.", "PackageLoader.", "(It's always embarrassing to email a dev list when the error is somewhere entirely different.)", "I switched to jinja2.", "FileLoader and it worked.", "My other issue was from an out-of-memory problem.", "This wasn't obvious from the task instance log, but when I found it when running the job command line.", "I dialed down the concurrency in airflow.cfg and this fixed the problem."], "labels": [0, 0, 0, 0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["PackageLoader.", "(It's always embarrassing to email a dev list when the error is somewhere entirely different.)", "I switched to jinja2.", "FileLoader and it worked.", "My other issue was from an out-of-memory problem.", "This wasn't obvious from the task instance log, but when I found it when running the job command line.", "I dialed down the concurrency in airflow.cfg and this fixed the problem.", "I also deferred some imports so that the DAG itself was not importing so much (the entire pydata stack) but the workers themselves did the imports when run.", "And thanks for the pointers about template_searchpath and the pitfalls of sys.path hacks."], "labels": [0, 0, 0, 0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["I switched to jinja2.", "FileLoader and it worked.", "My other issue was from an out-of-memory problem.", "This wasn't obvious from the task instance log, but when I found it when running the job command line.", "I dialed down the concurrency in airflow.cfg and this fixed the problem.", "I also deferred some imports so that the DAG itself was not importing so much (the entire pydata stack) but the workers themselves did the imports when run.", "And thanks for the pointers about template_searchpath and the pitfalls of sys.path hacks.", "I'd still be interested to learn more about how others structure more complex roll outs of Airflow."], "labels": [0, 0, 0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["My other issue was from an out-of-memory problem.", "This wasn't obvious from the task instance log, but when I found it when running the job command line.", "I dialed down the concurrency in airflow.cfg and this fixed the problem.", "I also deferred some imports so that the DAG itself was not importing so much (the entire pydata stack) but the workers themselves did the imports when run.", "And thanks for the pointers about template_searchpath and the pitfalls of sys.path hacks.", "I'd still be interested to learn more about how others structure more complex roll outs of Airflow.", "We're moving from the \"proof of concept\" phase to the \"we're doing this\" phase so learning how others are configuring and deploying would be really helpful."], "labels": [0, 0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["I dialed down the concurrency in airflow.cfg and this fixed the problem.", "I also deferred some imports so that the DAG itself was not importing so much (the entire pydata stack) but the workers themselves did the imports when run.", "And thanks for the pointers about template_searchpath and the pitfalls of sys.path hacks.", "I'd still be interested to learn more about how others structure more complex roll outs of Airflow.", "We're moving from the \"proof of concept\" phase to the \"we're doing this\" phase so learning how others are configuring and deploying would be really helpful.", "Maybe at the next meetup. :-) cheers, Dennis On Thu, Jun 2, 2016 at 2:24 PM"], "labels": [0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["I also deferred some imports so that the DAG itself was not importing so much (the entire pydata stack) but the workers themselves did the imports when run.", "And thanks for the pointers about template_searchpath and the pitfalls of sys.path hacks.", "I'd still be interested to learn more about how others structure more complex roll outs of Airflow.", "We're moving from the \"proof of concept\" phase to the \"we're doing this\" phase so learning how others are configuring and deploying would be really helpful.", "Maybe at the next meetup. :-) cheers, Dennis On Thu, Jun 2, 2016 at 2:24 PM", "Maxime Beauchemin < maximebeauchemin@gmail.com wrote: A few related things: *"], "labels": [0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["And thanks for the pointers about template_searchpath and the pitfalls of sys.path hacks.", "I'd still be interested to learn more about how others structure more complex roll outs of Airflow.", "We're moving from the \"proof of concept\" phase to the \"we're doing this\" phase so learning how others are configuring and deploying would be really helpful.", "Maybe at the next meetup. :-) cheers, Dennis On Thu, Jun 2, 2016 at 2:24 PM", "Maxime Beauchemin < maximebeauchemin@gmail.com wrote: A few related things: *", "You can use the `template_searchpath` param of the DAG constructor to add folders to the jinja searchpath for your DAG."], "labels": [0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["I'd still be interested to learn more about how others structure more complex roll outs of Airflow.", "We're moving from the \"proof of concept\" phase to the \"we're doing this\" phase so learning how others are configuring and deploying would be really helpful.", "Maybe at the next meetup. :-) cheers, Dennis On Thu, Jun 2, 2016 at 2:24 PM", "Maxime Beauchemin < maximebeauchemin@gmail.com wrote: A few related things: *", "You can use the `template_searchpath` param of the DAG constructor to add folders to the jinja searchpath for your DAG.", "Documented here: http://pythonhosted.org/airflow/code.html?highlight=template_searchpath#airflow.models.DAG"], "labels": [0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["Maybe at the next meetup. :-) cheers, Dennis On Thu, Jun 2, 2016 at 2:24 PM", "Maxime Beauchemin < maximebeauchemin@gmail.com wrote: A few related things: *", "You can use the `template_searchpath` param of the DAG constructor to add folders to the jinja searchpath for your DAG.", "Documented here: http://pythonhosted.org/airflow/code.html?highlight=template_searchpath#airflow.models.DAG", "* Airflow only adds DAGS_FOLDER to your `sys.", "path` beyond that you have to manage your PYTHONPATH on your own."], "labels": [0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["Maxime Beauchemin < maximebeauchemin@gmail.com wrote: A few related things: *", "You can use the `template_searchpath` param of the DAG constructor to add folders to the jinja searchpath for your DAG.", "Documented here: http://pythonhosted.org/airflow/code.html?highlight=template_searchpath#airflow.models.DAG", "* Airflow only adds DAGS_FOLDER to your `sys.", "path` beyond that you have to manage your PYTHONPATH on your own.", "Note that in the current version messing with `sys."], "labels": [0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["You can use the `template_searchpath` param of the DAG constructor to add folders to the jinja searchpath for your DAG.", "Documented here: http://pythonhosted.org/airflow/code.html?highlight=template_searchpath#airflow.models.DAG", "* Airflow only adds DAGS_FOLDER to your `sys.", "path` beyond that you have to manage your PYTHONPATH on your own.", "Note that in the current version messing with `sys.", "path` affects the main thread, meaning that DAGs parsed after this alteration have a different `sys."], "labels": [0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["Documented here: http://pythonhosted.org/airflow/code.html?highlight=template_searchpath#airflow.models.DAG", "* Airflow only adds DAGS_FOLDER to your `sys.", "path` beyond that you have to manage your PYTHONPATH on your own.", "Note that in the current version messing with `sys.", "path` affects the main thread, meaning that DAGs parsed after this alteration have a different `sys.", "path` than the ones before, which can create some serious, hard to debug problem.", "We're addressing this issue in the next version where DAG parsing will be done in subprocesses Max On Thu, Jun 2, 2016 at 1:43 AM, Matthias Huschle < matthias.huschle@paymill.de wrote: Hi Dennis, the first error is thrown by jinja2."], "labels": [0, 0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["* Airflow only adds DAGS_FOLDER to your `sys.", "path` beyond that you have to manage your PYTHONPATH on your own.", "Note that in the current version messing with `sys.", "path` affects the main thread, meaning that DAGs parsed after this alteration have a different `sys.", "path` than the ones before, which can create some serious, hard to debug problem.", "We're addressing this issue in the next version where DAG parsing will be done in subprocesses Max On Thu, Jun 2, 2016 at 1:43 AM, Matthias Huschle < matthias.huschle@paymill.de wrote: Hi Dennis, the first error is thrown by jinja2.", "PackageLoader."], "labels": [0, 0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["path` beyond that you have to manage your PYTHONPATH on your own.", "Note that in the current version messing with `sys.", "path` affects the main thread, meaning that DAGs parsed after this alteration have a different `sys.", "path` than the ones before, which can create some serious, hard to debug problem.", "We're addressing this issue in the next version where DAG parsing will be done in subprocesses Max On Thu, Jun 2, 2016 at 1:43 AM, Matthias Huschle < matthias.huschle@paymill.de wrote: Hi Dennis, the first error is thrown by jinja2.", "PackageLoader.", "I think you still have to use dot notation in the first argument, as the module itself is under the reports path: In: \"/home/airflow/workspace/verticadw/airflow/dags/reports/gsn_kpi_daily_email. py\", line 212, in get_email_html Change: env = jinja2.Environment(loader=jinja2.PackageLoader('gsn_kpi_daily_email', 'templates'))"], "labels": [0, 0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["path` than the ones before, which can create some serious, hard to debug problem.", "We're addressing this issue in the next version where DAG parsing will be done in subprocesses Max On Thu, Jun 2, 2016 at 1:43 AM, Matthias Huschle < matthias.huschle@paymill.de wrote: Hi Dennis, the first error is thrown by jinja2.", "PackageLoader.", "I think you still have to use dot notation in the first argument, as the module itself is under the reports path: In: \"/home/airflow/workspace/verticadw/airflow/dags/reports/gsn_kpi_daily_email. py\", line 212, in get_email_html Change: env = jinja2.Environment(loader=jinja2.PackageLoader('gsn_kpi_daily_email', 'templates'))", "To: env = jinja2.Environment(loader=jinja2.PackageLoader('reports.gsn_kpi_ daily_email', 'templates'))"], "labels": [0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["PackageLoader.", "I think you still have to use dot notation in the first argument, as the module itself is under the reports path: In: \"/home/airflow/workspace/verticadw/airflow/dags/reports/gsn_kpi_daily_email. py\", line 212, in get_email_html Change: env = jinja2.Environment(loader=jinja2.PackageLoader('gsn_kpi_daily_email', 'templates'))", "To: env = jinja2.Environment(loader=jinja2.PackageLoader('reports.gsn_kpi_ daily_email', 'templates'))", "For the second error I don't see a cause."], "labels": [0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["I think you still have to use dot notation in the first argument, as the module itself is under the reports path: In: \"/home/airflow/workspace/verticadw/airflow/dags/reports/gsn_kpi_daily_email. py\", line 212, in get_email_html Change: env = jinja2.Environment(loader=jinja2.PackageLoader('gsn_kpi_daily_email', 'templates'))", "To: env = jinja2.Environment(loader=jinja2.PackageLoader('reports.gsn_kpi_ daily_email', 'templates'))", "For the second error I don't see a cause.", "You should first check sys.path from within the script to see if etl/lib/ is properly added."], "labels": [0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["To: env = jinja2.Environment(loader=jinja2.PackageLoader('reports.gsn_kpi_ daily_email', 'templates'))", "For the second error I don't see a cause.", "You should first check sys.path from within the script to see if etl/lib/ is properly added.", "It's strange that the first error is thrown during runtime of the same module that fails to import in the second error.", "Do you modify sys.path from within your scripts?", "If I understand your setup correctly, an __init__.py is only necessary in reports."], "labels": [0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["For the second error I don't see a cause.", "You should first check sys.path from within the script to see if etl/lib/ is properly added.", "It's strange that the first error is thrown during runtime of the same module that fails to import in the second error.", "Do you modify sys.path from within your scripts?", "If I understand your setup correctly, an __init__.py is only necessary in reports.", "I don't think it has any purpose in folders, that are directly in sys.", "path ."], "labels": [0, 0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["You should first check sys.path from within the script to see if etl/lib/ is properly added.", "It's strange that the first error is thrown during runtime of the same module that fails to import in the second error.", "Do you modify sys.path from within your scripts?", "If I understand your setup correctly, an __init__.py is only necessary in reports.", "I don't think it has any purpose in folders, that are directly in sys.", "path .", "However, the names \"lib\" and \"db_connect\" are quite generic."], "labels": [0, 0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["It's strange that the first error is thrown during runtime of the same module that fails to import in the second error.", "Do you modify sys.path from within your scripts?", "If I understand your setup correctly, an __init__.py is only necessary in reports.", "I don't think it has any purpose in folders, that are directly in sys.", "path .", "However, the names \"lib\" and \"db_connect\" are quite generic.", "I'd consider renaming lib (sth. like etl_lib) and adding just etl/ to sys.path , and an __init__.py to the lib folder to avoid namespace pollution."], "labels": [0, 0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["Do you modify sys.path from within your scripts?", "If I understand your setup correctly, an __init__.py is only necessary in reports.", "I don't think it has any purpose in folders, that are directly in sys.", "path .", "However, the names \"lib\" and \"db_connect\" are quite generic.", "I'd consider renaming lib (sth. like etl_lib) and adding just etl/ to sys.path , and an __init__.py to the lib folder to avoid namespace pollution.", "You'd have to use \"from etl_lib import db_connect\" then, of course."], "labels": [0, 0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["If I understand your setup correctly, an __init__.py is only necessary in reports.", "I don't think it has any purpose in folders, that are directly in sys.", "path .", "However, the names \"lib\" and \"db_connect\" are quite generic.", "I'd consider renaming lib (sth. like etl_lib) and adding just etl/ to sys.path , and an __init__.py to the lib folder to avoid namespace pollution.", "You'd have to use \"from etl_lib import db_connect\" then, of course.", "Hope that helps, Matthias 2016-06-01 20:10 GMT+02:00 Dennis O'Brien <dennis@dennisobrien.net:"], "labels": [0, 0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["I don't think it has any purpose in folders, that are directly in sys.", "path .", "However, the names \"lib\" and \"db_connect\" are quite generic.", "I'd consider renaming lib (sth. like etl_lib) and adding just etl/ to sys.path , and an __init__.py to the lib folder to avoid namespace pollution.", "You'd have to use \"from etl_lib import db_connect\" then, of course.", "Hope that helps, Matthias 2016-06-01 20:10 GMT+02:00 Dennis O'Brien <dennis@dennisobrien.net:", "Hi folks I'm looking for some advice here on how others separate their DAGs and the code those DAGs call and any PYTHONPATH fixups that may be necessary."], "labels": [0, 0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["I'd consider renaming lib (sth. like etl_lib) and adding just etl/ to sys.path , and an __init__.py to the lib folder to avoid namespace pollution.", "You'd have to use \"from etl_lib import db_connect\" then, of course.", "Hope that helps, Matthias 2016-06-01 20:10 GMT+02:00 Dennis O'Brien <dennis@dennisobrien.net:", "Hi folks I'm looking for some advice here on how others separate their DAGs and the code those DAGs call and any PYTHONPATH fixups that may be necessary.", "I have a project that looks like this ."], "labels": [0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["You'd have to use \"from etl_lib import db_connect\" then, of course.", "Hope that helps, Matthias 2016-06-01 20:10 GMT+02:00 Dennis O'Brien <dennis@dennisobrien.net:", "Hi folks I'm looking for some advice here on how others separate their DAGs and the code those DAGs call and any PYTHONPATH fixups that may be necessary.", "I have a project that looks like this .", "├── airflow │ ├── dags │ │ ├── reports │ │ └── sql │ └── deploy │ └── templates ├── etl │ ├── lib All the DAGs are in airflow/dags", "The sql used by SqlSensor tasks are in airflow/dags/sql"], "labels": [0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["Hope that helps, Matthias 2016-06-01 20:10 GMT+02:00 Dennis O'Brien <dennis@dennisobrien.net:", "Hi folks I'm looking for some advice here on how others separate their DAGs and the code those DAGs call and any PYTHONPATH fixups that may be necessary.", "I have a project that looks like this .", "├── airflow │ ├── dags │ │ ├── reports │ │ └── sql │ └── deploy │ └── templates ├── etl │ ├── lib All the DAGs are in airflow/dags", "The sql used by SqlSensor tasks are in airflow/dags/sql", "The python code used by PythonOperator is in airflow/dags/reports and etl/lib Existing etl code is all in etl In ./airflow/dags/etl_gsn_daily_kpi_email.py ``` from reports.gsn_kpi_daily_email import send_daily_kpi_email ``` I thought I could just import code in airflow/dags/reports from airflow/dags since DAGS_FOLDER is added to sys.path but after deploying the code I saw an error in the web UI about failing to import the module `reports.gsn_kpi_daily_email`."], "labels": [0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["I have a project that looks like this .", "├── airflow │ ├── dags │ │ ├── reports │ │ └── sql │ └── deploy │ └── templates ├── etl │ ├── lib All the DAGs are in airflow/dags", "The sql used by SqlSensor tasks are in airflow/dags/sql", "The python code used by PythonOperator is in airflow/dags/reports and etl/lib Existing etl code is all in etl In ./airflow/dags/etl_gsn_daily_kpi_email.py ``` from reports.gsn_kpi_daily_email import send_daily_kpi_email ``` I thought I could just import code in airflow/dags/reports from airflow/dags since DAGS_FOLDER is added to sys.path but after deploying the code I saw an error in the web UI about failing to import the module `reports.gsn_kpi_daily_email`.", "So I added __init__.py files in dags and dags/reports with no success."], "labels": [0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["The sql used by SqlSensor tasks are in airflow/dags/sql", "The python code used by PythonOperator is in airflow/dags/reports and etl/lib Existing etl code is all in etl In ./airflow/dags/etl_gsn_daily_kpi_email.py ``` from reports.gsn_kpi_daily_email import send_daily_kpi_email ``` I thought I could just import code in airflow/dags/reports from airflow/dags since DAGS_FOLDER is added to sys.path but after deploying the code I saw an error in the web UI about failing to import the module `reports.gsn_kpi_daily_email`.", "So I added __init__.py files in dags and dags/reports with no success.", "Then I modified my upstart scripts to fix up the PYTHONPATH."], "labels": [0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["So I added __init__.py files in dags and dags/reports with no success.", "Then I modified my upstart scripts to fix up the PYTHONPATH.", "``` env PYTHONPATH=$PYTHONPATH:{{ destination_dir }}/airflow/dags/:{{ destination_dir }}/etl/lib/ export PYTHONPATH ```", "This fixed the error in the web UI but on the next run of the job, I got these tracebacks: ``` [2016-06-01 12:14:38,352]", "{models.py:1286} ERROR - No module named gsn_kpi_daily_email Traceback (most recent call last): File \"/home/airflow/venv/local/lib/python2.7/site-packages/airflow/models.py\", line 1245, in run result = task_copy.execute(context=context) File \"/home/airflow/venv/lib/python2.7/site-packages/airflow/operators/python_operator.py\", line 66, in execute return_value = self.python_callable(*self.op_args, **self.op_kwargs) File \"/home/airflow/workspace/verticadw/airflow/dags/reports/gsn_kpi_daily_email.py\", line 223, in send_daily_kpi_email html = get_email_html(kpi_df) File \"/home/airflow/workspace/verticadw/airflow/dags/reports/gsn_kpi_daily_email.py\", line 212, in get_email_html env = jinja2.Environment(loader=jinja2.PackageLoader('gsn_kpi_daily_email', 'templates'))"], "labels": [0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["This fixed the error in the web UI but on the next run of the job, I got these tracebacks: ``` [2016-06-01 12:14:38,352]", "{models.py:1286} ERROR - No module named gsn_kpi_daily_email Traceback (most recent call last): File \"/home/airflow/venv/local/lib/python2.7/site-packages/airflow/models.py\", line 1245, in run result = task_copy.execute(context=context) File \"/home/airflow/venv/lib/python2.7/site-packages/airflow/operators/python_operator.py\", line 66, in execute return_value = self.python_callable(*self.op_args, **self.op_kwargs) File \"/home/airflow/workspace/verticadw/airflow/dags/reports/gsn_kpi_daily_email.py\", line 223, in send_daily_kpi_email html = get_email_html(kpi_df) File \"/home/airflow/workspace/verticadw/airflow/dags/reports/gsn_kpi_daily_email.py\", line 212, in get_email_html env = jinja2.Environment(loader=jinja2.PackageLoader('gsn_kpi_daily_email', 'templates'))", "File \"/home/airflow/venv/local/lib/python2.7/site-packages/jinja2/loaders.py\", line 224, in __init__ provider = get_provider(package_name) File \"/home/airflow/venv/local/lib/python2.7/site-packages/pkg_resources/__init__.py\", line 419, in get_provider __import__(moduleOrReq) ImportError:"], "labels": [0, 0, 0], "abstract_id": 0}
{"sentences": ["File \"/home/airflow/venv/local/lib/python2.7/site-packages/jinja2/loaders.py\", line 224, in __init__ provider = get_provider(package_name) File \"/home/airflow/venv/local/lib/python2.7/site-packages/pkg_resources/__init__.py\", line 419, in get_provider __import__(moduleOrReq) ImportError:", "No module named gsn_kpi_daily_email ... [2016-06-01 12:19:42,556]", "{models.py:250} ERROR - Failed to import: /home/airflow/workspace/verticadw/airflow/dags/etl_gsn_daily_kpi_email.py Traceback (most recent call last): File \"/home/airflow/venv/local/lib/python2.7/site-packages/airflow/models.py\", line 247, in process_file m = imp.load_source(mod_name, filepath) File \"/home/airflow/workspace/verticadw/airflow/dags/etl_gsn_daily_kpi_email.py\", line 4, in <module from reports.gsn_kpi_daily_email import send_daily_kpi_email File \"/home/airflow/workspace/verticadw/airflow/dags/reports/gsn_kpi_daily_email.py\", line 8, in <module from db_connect import get_db_connection_native as get_db_connection ImportError:"], "labels": [0, 0, 0], "abstract_id": 0}
{"sentences": ["No module named gsn_kpi_daily_email ... [2016-06-01 12:19:42,556]", "{models.py:250} ERROR - Failed to import: /home/airflow/workspace/verticadw/airflow/dags/etl_gsn_daily_kpi_email.py Traceback (most recent call last): File \"/home/airflow/venv/local/lib/python2.7/site-packages/airflow/models.py\", line 247, in process_file m = imp.load_source(mod_name, filepath) File \"/home/airflow/workspace/verticadw/airflow/dags/etl_gsn_daily_kpi_email.py\", line 4, in <module from reports.gsn_kpi_daily_email import send_daily_kpi_email File \"/home/airflow/workspace/verticadw/airflow/dags/reports/gsn_kpi_daily_email.py\", line 8, in <module from db_connect import get_db_connection_native as get_db_connection ImportError:", "No module named db_connect ```"], "labels": [0, 0, 0], "abstract_id": 0}
{"sentences": ["No module named db_connect ```", "The first error is strange because the module it can't find, gsn_kpi_daily_email, is in the stack trace.", "With that second error, db_connect is in etl/lib which I added to the PYTHONPATH.", "If anyone has advice on how to separate DAG code and other Python code, I'd appreciate any pointers.", "And some configuration info: airflow[celery,crypto,hive,jdbc,postgres,s3,redis,vertica]==1.7.1.2 celery[redis]==3.1.23 AWS EC2 m4.large with Ubuntu 14.04 AMI Using CeleryExecutor thanks, Dennis -- Lance Norskog lance.norskog@gmail.com Redwood City, CA"], "labels": [0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["Hey Harish,", "One thing that I'm not clear on is whether backfill even honors pools at all.", "I believe backfill currently starts its own scheduler outside of the main scheduler process.", "As a result, I think the pools are completely disregarded.", "Bolke/Jeremiah/Paul can correct me if I'm wrong.", "Cheers, Chris On Mon, Jun 20, 2016 at 7:46 PM, Lance Norskog <lance.norskog@gmail.com wrote:", "One reason to use Pools is because you have tasks in different DAGs that all use the same resource, like a database.", "A Pool lets you say, \"I will send no more than 3 requests to this database at once\"."], "labels": [0, 0, 0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["I believe backfill currently starts its own scheduler outside of the main scheduler process.", "As a result, I think the pools are completely disregarded.", "Bolke/Jeremiah/Paul can correct me if I'm wrong.", "Cheers, Chris On Mon, Jun 20, 2016 at 7:46 PM, Lance Norskog <lance.norskog@gmail.com wrote:", "One reason to use Pools is because you have tasks in different DAGs that all use the same resource, like a database.", "A Pool lets you say, \"I will send no more than 3 requests to this database at once\".", "However, there are bugs in the scheduler and it is possible to have many active tasks overscheduled against a pool."], "labels": [0, 0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["As a result, I think the pools are completely disregarded.", "Bolke/Jeremiah/Paul can correct me if I'm wrong.", "Cheers, Chris On Mon, Jun 20, 2016 at 7:46 PM, Lance Norskog <lance.norskog@gmail.com wrote:", "One reason to use Pools is because you have tasks in different DAGs that all use the same resource, like a database.", "A Pool lets you say, \"I will send no more than 3 requests to this database at once\".", "However, there are bugs in the scheduler and it is possible to have many active tasks overscheduled against a pool.", "You can create a pool in the Admin-Pools drop-down."], "labels": [0, 0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["Cheers, Chris On Mon, Jun 20, 2016 at 7:46 PM, Lance Norskog <lance.norskog@gmail.com wrote:", "One reason to use Pools is because you have tasks in different DAGs that all use the same resource, like a database.", "A Pool lets you say, \"I will send no more than 3 requests to this database at once\".", "However, there are bugs in the scheduler and it is possible to have many active tasks overscheduled against a pool.", "You can create a pool in the Admin-Pools drop-down.", "You don't need a script."], "labels": [0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["One reason to use Pools is because you have tasks in different DAGs that all use the same resource, like a database.", "A Pool lets you say, \"I will send no more than 3 requests to this database at once\".", "However, there are bugs in the scheduler and it is possible to have many active tasks overscheduled against a pool.", "You can create a pool in the Admin-Pools drop-down.", "You don't need a script.", "On Mon, Jun 20, 2016 at 2:46 PM, harish singh <harish.singh22@gmail.com wrote: Hi,"], "labels": [0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["A Pool lets you say, \"I will send no more than 3 requests to this database at once\".", "However, there are bugs in the scheduler and it is possible to have many active tasks overscheduled against a pool.", "You can create a pool in the Admin-Pools drop-down.", "You don't need a script.", "On Mon, Jun 20, 2016 at 2:46 PM, harish singh <harish.singh22@gmail.com wrote: Hi,", "We have been using airflow for few 3 months now.", "One pain I felt was, during backfill if I have 2 tasks t1 and t2 - with t1 having depends_on_past=true, t0 - t1 t0 - t2 I find that the task t2 with no past dependency keeps getting scheduled."], "labels": [0, 0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["However, there are bugs in the scheduler and it is possible to have many active tasks overscheduled against a pool.", "You can create a pool in the Admin-Pools drop-down.", "You don't need a script.", "On Mon, Jun 20, 2016 at 2:46 PM, harish singh <harish.singh22@gmail.com wrote: Hi,", "We have been using airflow for few 3 months now.", "One pain I felt was, during backfill if I have 2 tasks t1 and t2 - with t1 having depends_on_past=true, t0 - t1 t0 - t2 I find that the task t2 with no past dependency keeps getting scheduled.", "This causes the task t1 to wait for a long time before it gets scheduled."], "labels": [0, 0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["You can create a pool in the Admin-Pools drop-down.", "You don't need a script.", "On Mon, Jun 20, 2016 at 2:46 PM, harish singh <harish.singh22@gmail.com wrote: Hi,", "We have been using airflow for few 3 months now.", "One pain I felt was, during backfill if I have 2 tasks t1 and t2 - with t1 having depends_on_past=true, t0 - t1 t0 - t2 I find that the task t2 with no past dependency keeps getting scheduled.", "This causes the task t1 to wait for a long time before it gets scheduled.", "I think this is a good use case for creating \"pools\" and allocate slots for each pool."], "labels": [0, 0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["On Mon, Jun 20, 2016 at 2:46 PM, harish singh <harish.singh22@gmail.com wrote: Hi,", "We have been using airflow for few 3 months now.", "One pain I felt was, during backfill if I have 2 tasks t1 and t2 - with t1 having depends_on_past=true, t0 - t1 t0 - t2 I find that the task t2 with no past dependency keeps getting scheduled.", "This causes the task t1 to wait for a long time before it gets scheduled.", "I think this is a good use case for creating \"pools\" and allocate slots for each pool.", "Also, I will have to use priority_weights."], "labels": [0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["We have been using airflow for few 3 months now.", "One pain I felt was, during backfill if I have 2 tasks t1 and t2 - with t1 having depends_on_past=true, t0 - t1 t0 - t2 I find that the task t2 with no past dependency keeps getting scheduled.", "This causes the task t1 to wait for a long time before it gets scheduled.", "I think this is a good use case for creating \"pools\" and allocate slots for each pool.", "Also, I will have to use priority_weights.", "And adjust parallelism!!!"], "labels": [0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["This causes the task t1 to wait for a long time before it gets scheduled.", "I think this is a good use case for creating \"pools\" and allocate slots for each pool.", "Also, I will have to use priority_weights.", "And adjust parallelism!!!", "Is there a better way to handle this?", "Also, in general, are there any examples on how to use pools?", "I peeked into*", "airflow/tests/operators/subdag_operator.py *and found the below snippet: session = airflow.settings.Session() pool_1 = airflow.models.Pool(pool='test_pool_1', slots=1) session.add(pool_1) session.commit()"], "labels": [0, 0, 0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["I think this is a good use case for creating \"pools\" and allocate slots for each pool.", "Also, I will have to use priority_weights.", "And adjust parallelism!!!", "Is there a better way to handle this?", "Also, in general, are there any examples on how to use pools?", "I peeked into*", "airflow/tests/operators/subdag_operator.py *and found the below snippet: session = airflow.settings.Session() pool_1 = airflow.models.Pool(pool='test_pool_1', slots=1) session.add(pool_1) session.commit()", "Why do we need Session instance?"], "labels": [0, 0, 0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["Also, I will have to use priority_weights.", "And adjust parallelism!!!", "Is there a better way to handle this?", "Also, in general, are there any examples on how to use pools?", "I peeked into*", "airflow/tests/operators/subdag_operator.py *and found the below snippet: session = airflow.settings.Session() pool_1 = airflow.models.Pool(pool='test_pool_1', slots=1) session.add(pool_1) session.commit()", "Why do we need Session instance?", "Do we need to run the below code before creating a pool in code (inside my pipeline."], "labels": [0, 0, 0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["And adjust parallelism!!!", "Is there a better way to handle this?", "Also, in general, are there any examples on how to use pools?", "I peeked into*", "airflow/tests/operators/subdag_operator.py *and found the below snippet: session = airflow.settings.Session() pool_1 = airflow.models.Pool(pool='test_pool_1', slots=1) session.add(pool_1) session.commit()", "Why do we need Session instance?", "Do we need to run the below code before creating a pool in code (inside my pipeline.", "py under dags/ directory): *pool = ( session.query(Pool) .filter(Pool.pool == 'AIRFLOW-205') .first()) if not pool: session.add(Pool(pool='AIRFLOW-205', slots=8)) session.commit()*"], "labels": [0, 0, 0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["I peeked into*", "airflow/tests/operators/subdag_operator.py *and found the below snippet: session = airflow.settings.Session() pool_1 = airflow.models.Pool(pool='test_pool_1', slots=1) session.add(pool_1) session.commit()", "Why do we need Session instance?", "Do we need to run the below code before creating a pool in code (inside my pipeline.", "py under dags/ directory): *pool = ( session.query(Pool) .filter(Pool.pool == 'AIRFLOW-205') .first()) if not pool: session.add(Pool(pool='AIRFLOW-205', slots=8)) session.commit()*", "Also, I saw few places where pool: 'backfill' is used?"], "labels": [0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["Why do we need Session instance?", "Do we need to run the below code before creating a pool in code (inside my pipeline.", "py under dags/ directory): *pool = ( session.query(Pool) .filter(Pool.pool == 'AIRFLOW-205') .first()) if not pool: session.add(Pool(pool='AIRFLOW-205', slots=8)) session.commit()*", "Also, I saw few places where pool: 'backfill' is used?", "Is 'backfill' a special pre-defined pool?", "If not, how do we create different types of pools based on whether it is backfill or not?"], "labels": [0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["py under dags/ directory): *pool = ( session.query(Pool) .filter(Pool.pool == 'AIRFLOW-205') .first()) if not pool: session.add(Pool(pool='AIRFLOW-205', slots=8)) session.commit()*", "Also, I saw few places where pool: 'backfill' is used?", "Is 'backfill' a special pre-defined pool?", "If not, how do we create different types of pools based on whether it is backfill or not?", "All this is being done in pipeline."], "labels": [0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["Also, I saw few places where pool: 'backfill' is used?", "Is 'backfill' a special pre-defined pool?", "If not, how do we create different types of pools based on whether it is backfill or not?", "All this is being done in pipeline.", "py script under 'dags/' directory.", "Thanks, Harish -- Lance Norskog lance.norskog@gmail.com Redwood City, CA"], "labels": [0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["Binglin", "Chang has posted comments on this change.", "Change subject: KUDU-1317 (part 2): decay the replica creation load on TS lazily ...................................................................... Patch Set 2: Code-Review+1 -- To view, visit http://gerrit.cloudera.org:8080/1979", "To unsubscribe, visit http://gerrit.cloudera.org:8080/settings Gerrit-MessageType: comment Gerrit-Change-Id: I15899b8bf221f334fdec5983e1b5d93cc57fab3b Gerrit-PatchSet: 2 Gerrit-Project: kudu Gerrit-Branch: master Gerrit-Owner: Todd Lipcon <todd@apache.org Gerrit-Reviewer: Adar Dembo <adar@cloudera.com Gerrit-Reviewer: Binglin Chang <decstery@gmail.com Gerrit-Reviewer: Jean-Daniel Cryans Gerrit-Reviewer: Todd Lipcon <todd@apache.org Gerrit-HasComments: No"], "labels": [0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["Hi Guys,", "Im not sure if it will fit the agenda and we don’t have something like break out rooms ;-).", "So this is for your consideration if we can add it: 1. MySQL 5.6 compatibility issues: Fractional seconds vs Round off MySQL does not store fractional seconds which is against the SQL standard (http://dev.mysql.com/doc/refman/5.6/en/fractional-seconds.html", "<http://dev.mysql.com/doc/refman/5.6/en/fractional-seconds.html).", "Therefore there is a difference on how MySQL stores seconds and SQLite and Postgres do.", "It also means that for some edge cases we are incompatible with MySQL 5.6."], "labels": [0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["<http://dev.mysql.com/doc/refman/5.6/en/fractional-seconds.html).", "Therefore there is a difference on how MySQL stores seconds and SQLite and Postgres do.", "It also means that for some edge cases we are incompatible with MySQL 5.6.", "This has been caught by the unit tests when trying to move to Travis’ ubuntu trusty which relies on MySQL 5.6.", "It has been proposed to change MySQL’s schema to store fractional seconds, but a counter proposal was made to do a round off in code.", "Both options have their pro’s and con’s, but it is blocking the upgrade of the CI environment."], "labels": [0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["Therefore there is a difference on how MySQL stores seconds and SQLite and Postgres do.", "It also means that for some edge cases we are incompatible with MySQL 5.6.", "This has been caught by the unit tests when trying to move to Travis’ ubuntu trusty which relies on MySQL 5.6.", "It has been proposed to change MySQL’s schema to store fractional seconds, but a counter proposal was made to do a round off in code.", "Both options have their pro’s and con’s, but it is blocking the upgrade of the CI environment.", "2. Perceived scheduler stability & roadmap Several issues affect the perception of the robustness of the scheduler."], "labels": [0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["It also means that for some edge cases we are incompatible with MySQL 5.6.", "This has been caught by the unit tests when trying to move to Travis’ ubuntu trusty which relies on MySQL 5.6.", "It has been proposed to change MySQL’s schema to store fractional seconds, but a counter proposal was made to do a round off in code.", "Both options have their pro’s and con’s, but it is blocking the upgrade of the CI environment.", "2. Perceived scheduler stability & roadmap Several issues affect the perception of the robustness of the scheduler.", "Reports have been coming in of schedulers being stuck that have been impossible to replicate."], "labels": [0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["This has been caught by the unit tests when trying to move to Travis’ ubuntu trusty which relies on MySQL 5.6.", "It has been proposed to change MySQL’s schema to store fractional seconds, but a counter proposal was made to do a round off in code.", "Both options have their pro’s and con’s, but it is blocking the upgrade of the CI environment.", "2. Perceived scheduler stability & roadmap Several issues affect the perception of the robustness of the scheduler.", "Reports have been coming in of schedulers being stuck that have been impossible to replicate.", "The reports itself often lack detail (executor, broker, airflow config, python version, os etc) and quite often are incorrect due to the difference between the in process executors (Local/Sequential) and out-of-band executors (Celery/Mesos): long running tasks will affect loop the scheduler in case of in process executors."], "labels": [0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["Both options have their pro’s and con’s, but it is blocking the upgrade of the CI environment.", "2. Perceived scheduler stability & roadmap Several issues affect the perception of the robustness of the scheduler.", "Reports have been coming in of schedulers being stuck that have been impossible to replicate.", "The reports itself often lack detail (executor, broker, airflow config, python version, os etc) and quite often are incorrect due to the difference between the in process executors (Local/Sequential) and out-of-band executors (Celery/Mesos): long running tasks will affect loop the scheduler in case of in process executors.", "However, there are some other issues that need to be addressed.", "a) Airflow’s heritage contains a “num_runs” feature that made the scheduler stop after num_runs loops."], "labels": [0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["Reports have been coming in of schedulers being stuck that have been impossible to replicate.", "The reports itself often lack detail (executor, broker, airflow config, python version, os etc) and quite often are incorrect due to the difference between the in process executors (Local/Sequential) and out-of-band executors (Celery/Mesos): long running tasks will affect loop the scheduler in case of in process executors.", "However, there are some other issues that need to be addressed.", "a) Airflow’s heritage contains a “num_runs” feature that made the scheduler stop after num_runs loops.", "Although never a full explanation has been provided, the most likely explanation is that this was related the the scheduler in certain circumstances not being able to queue new tasks when using the CeleryExecutor."], "labels": [0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["However, there are some other issues that need to be addressed.", "a) Airflow’s heritage contains a “num_runs” feature that made the scheduler stop after num_runs loops.", "Although never a full explanation has been provided, the most likely explanation is that this was related the the scheduler in certain circumstances not being able to queue new tasks when using the CeleryExecutor.", "The scheduler then seems “stuck”.", "In a recent refactor of the scheduler code also “run_duration” has been introduced which more or less seems to address the same issue by stopping the scheduler after a certain amount of time.", "This run_duration cannot be disabled at the moment, nevertheless several shops are running on Celery without num_runs (our scheduler uptime is 76 days at the moment)."], "labels": [0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["Although never a full explanation has been provided, the most likely explanation is that this was related the the scheduler in certain circumstances not being able to queue new tasks when using the CeleryExecutor.", "The scheduler then seems “stuck”.", "In a recent refactor of the scheduler code also “run_duration” has been introduced which more or less seems to address the same issue by stopping the scheduler after a certain amount of time.", "This run_duration cannot be disabled at the moment, nevertheless several shops are running on Celery without num_runs (our scheduler uptime is 76 days at the moment).", "This begs the question what is the root cause for having the functionality and was the root issue maybe fixed upstream?"], "labels": [0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["The scheduler then seems “stuck”.", "In a recent refactor of the scheduler code also “run_duration” has been introduced which more or less seems to address the same issue by stopping the scheduler after a certain amount of time.", "This run_duration cannot be disabled at the moment, nevertheless several shops are running on Celery without num_runs (our scheduler uptime is 76 days at the moment).", "This begs the question what is the root cause for having the functionality and was the root issue maybe fixed upstream?", "I guess reliability and predictability of the scheduler are important to everyone. b)", "In some circusstances the scheduler seems to get stuck (not logging anymore) when tasks are being scheduled through scheduler childs (1.7.1.3 - multiprocessing)."], "labels": [0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["This run_duration cannot be disabled at the moment, nevertheless several shops are running on Celery without num_runs (our scheduler uptime is 76 days at the moment).", "This begs the question what is the root cause for having the functionality and was the root issue maybe fixed upstream?", "I guess reliability and predictability of the scheduler are important to everyone. b)", "In some circusstances the scheduler seems to get stuck (not logging anymore) when tasks are being scheduled through scheduler childs (1.7.1.3 - multiprocessing).", "See also Jira-366.", "It is impossible to replicate this locally for me with both the LocalExecutor and CeleryExecutor."], "labels": [0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["This begs the question what is the root cause for having the functionality and was the root issue maybe fixed upstream?", "I guess reliability and predictability of the scheduler are important to everyone. b)", "In some circusstances the scheduler seems to get stuck (not logging anymore) when tasks are being scheduled through scheduler childs (1.7.1.3 - multiprocessing).", "See also Jira-366.", "It is impossible to replicate this locally for me with both the LocalExecutor and CeleryExecutor.", "c) Event driven scheduler?"], "labels": [0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["I guess reliability and predictability of the scheduler are important to everyone. b)", "In some circusstances the scheduler seems to get stuck (not logging anymore) when tasks are being scheduled through scheduler childs (1.7.1.3 - multiprocessing).", "See also Jira-366.", "It is impossible to replicate this locally for me with both the LocalExecutor and CeleryExecutor.", "c) Event driven scheduler?", "3. Logging etiquette Logging (Configuration (SysLog, Files) in Airflow is not standardized."], "labels": [0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["In some circusstances the scheduler seems to get stuck (not logging anymore) when tasks are being scheduled through scheduler childs (1.7.1.3 - multiprocessing).", "See also Jira-366.", "It is impossible to replicate this locally for me with both the LocalExecutor and CeleryExecutor.", "c) Event driven scheduler?", "3. Logging etiquette Logging (Configuration (SysLog, Files) in Airflow is not standardized.", "So we have arbitrary files being written and making it difficult to debug certain issues."], "labels": [0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["See also Jira-366.", "It is impossible to replicate this locally for me with both the LocalExecutor and CeleryExecutor.", "c) Event driven scheduler?", "3. Logging etiquette Logging (Configuration (SysLog, Files) in Airflow is not standardized.", "So we have arbitrary files being written and making it difficult to debug certain issues.", "4. API - Protocols (AVRO/Protobuf, JSON) - Security (OAUTH, Kerberos); integration with web-ui authentication - Own process?", "- Interprocess API (Tasks asking for connection details from a central API, instead of going to the DB directly) Bolke Op 17 sep. 2016, om 00:53 heeft gurer.kiratli@airbnb.com.INVALID het volgende geschreven: Never miss an appointment."], "labels": [0, 0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["c) Event driven scheduler?", "3. Logging etiquette Logging (Configuration (SysLog, Files) in Airflow is not standardized.", "So we have arbitrary files being written and making it difficult to debug certain issues.", "4. API - Protocols (AVRO/Protobuf, JSON) - Security (OAUTH, Kerberos); integration with web-ui authentication - Own process?", "- Interprocess API (Tasks asking for connection details from a central API, instead of going to the DB directly) Bolke Op 17 sep. 2016, om 00:53 heeft gurer.kiratli@airbnb.com.INVALID het volgende geschreven: Never miss an appointment.", "Download the Google Calendar app."], "labels": [0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["3. Logging etiquette Logging (Configuration (SysLog, Files) in Airflow is not standardized.", "So we have arbitrary files being written and making it difficult to debug certain issues.", "4. API - Protocols (AVRO/Protobuf, JSON) - Security (OAUTH, Kerberos); integration with web-ui authentication - Own process?", "- Interprocess API (Tasks asking for connection details from a central API, instead of going to the DB directly) Bolke Op 17 sep. 2016, om 00:53 heeft gurer.kiratli@airbnb.com.INVALID het volgende geschreven: Never miss an appointment.", "Download the Google Calendar app.", "<https://goo.gl/czFEqm"], "labels": [0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["4. API - Protocols (AVRO/Protobuf, JSON) - Security (OAUTH, Kerberos); integration with web-ui authentication - Own process?", "- Interprocess API (Tasks asking for connection details from a central API, instead of going to the DB directly) Bolke Op 17 sep. 2016, om 00:53 heeft gurer.kiratli@airbnb.com.INVALID het volgende geschreven: Never miss an appointment.", "Download the Google Calendar app.", "<https://goo.gl/czFEqm", "<https://goo.gl/hxLBzR more details » <https://www.google.com/calendar/event?action=VIEW&eid=b2YxYjB2a3M2cDc0ZDVnMHYwMGZmMmFzN2sgZGV2QGFpcmZsb3cuaW5jdWJhdG9yLmFwYWNoZS5vcmc&tok=MjQjZ3VyZXIua2lyYXRsaUBhaXJibmIuY29tMDQ5ZGNhMzI3OWI5NTJjNThjYTc3YTkzYzgwODc0Yjk0ZmI2NWUwOQ&ctz=America/Los_Angeles&hl=en Airflow Contributors & Roadmapping Meeting"], "labels": [0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["Download the Google Calendar app.", "<https://goo.gl/czFEqm", "<https://goo.gl/hxLBzR more details » <https://www.google.com/calendar/event?action=VIEW&eid=b2YxYjB2a3M2cDc0ZDVnMHYwMGZmMmFzN2sgZGV2QGFpcmZsb3cuaW5jdWJhdG9yLmFwYWNoZS5vcmc&tok=MjQjZ3VyZXIua2lyYXRsaUBhaXJibmIuY29tMDQ5ZGNhMzI3OWI5NTJjNThjYTc3YTkzYzgwODc0Yjk0ZmI2NWUwOQ&ctz=America/Los_Angeles&hl=en Airflow Contributors & Roadmapping Meeting", "Hi all, Again it has been a while after our last meeting."], "labels": [0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["<https://goo.gl/czFEqm", "<https://goo.gl/hxLBzR more details » <https://www.google.com/calendar/event?action=VIEW&eid=b2YxYjB2a3M2cDc0ZDVnMHYwMGZmMmFzN2sgZGV2QGFpcmZsb3cuaW5jdWJhdG9yLmFwYWNoZS5vcmc&tok=MjQjZ3VyZXIua2lyYXRsaUBhaXJibmIuY29tMDQ5ZGNhMzI3OWI5NTJjNThjYTc3YTkzYzgwODc0Yjk0ZmI2NWUwOQ&ctz=America/Los_Angeles&hl=en Airflow Contributors & Roadmapping Meeting", "Hi all, Again it has been a while after our last meeting.", "Let's have another meeting to sync up!"], "labels": [0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["Hi all, Again it has been a while after our last meeting.", "Let's have another meeting to sync up!", "We are super happy to host all you folks at Airbnb(888 Brannan St 94103) on October 7th at 10:00am.", "Also we will have a webex session at https://airbnb.webex.com/meet/gurer.kiratli", "<https://www.google.com/url?q=https%3A%2F%2Fairbnb.webex.com%2Fmeet%2Fgurer.kiratli&sa=D&usd=2&usg=AFQjCNFC3kEwm1Mu8gSE2gl7SlNkV5NMCg.", "I will send this out as a Google Calendar but due to the fact that it goes thru the mail group I don't see your responses."], "labels": [0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["We are super happy to host all you folks at Airbnb(888 Brannan St 94103) on October 7th at 10:00am.", "Also we will have a webex session at https://airbnb.webex.com/meet/gurer.kiratli", "<https://www.google.com/url?q=https%3A%2F%2Fairbnb.webex.com%2Fmeet%2Fgurer.kiratli&sa=D&usd=2&usg=AFQjCNFC3kEwm1Mu8gSE2gl7SlNkV5NMCg.", "I will send this out as a Google Calendar but due to the fact that it goes thru the mail group I don't see your responses.", "If you are planning to come on please respond back to me with your first name, last name."], "labels": [0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["Also we will have a webex session at https://airbnb.webex.com/meet/gurer.kiratli", "<https://www.google.com/url?q=https%3A%2F%2Fairbnb.webex.com%2Fmeet%2Fgurer.kiratli&sa=D&usd=2&usg=AFQjCNFC3kEwm1Mu8gSE2gl7SlNkV5NMCg.", "I will send this out as a Google Calendar but due to the fact that it goes thru the mail group I don't see your responses.", "If you are planning to come on please respond back to me with your first name, last name.", "And please try to arrive by 9:30 so we can check you and head to the meeting room."], "labels": [0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["I will send this out as a Google Calendar but due to the fact that it goes thru the mail group I don't see your responses.", "If you are planning to come on please respond back to me with your first name, last name.", "And please try to arrive by 9:30 so we can check you and head to the meeting room.", ": )", "Here is the proposed agenda: 10:00am -10:45am PDT", "Contributors sync-up: progress and plan Release Schedule, Management 10:45am - 11:00am PDT Coffee Break 11:00am - 12:00pm PDT Roadmap discussion 12:00pm - 1:00pm PDT Lunch @ Airbnb Cheers, Gurer === * * * === https://airbnb.webex.com/meet/gurer.kiratli"], "labels": [0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["If you are planning to come on please respond back to me with your first name, last name.", "And please try to arrive by 9:30 so we can check you and head to the meeting room.", ": )", "Here is the proposed agenda: 10:00am -10:45am PDT", "Contributors sync-up: progress and plan Release Schedule, Management 10:45am - 11:00am PDT Coffee Break 11:00am - 12:00pm PDT Roadmap discussion 12:00pm - 1:00pm PDT Lunch @ Airbnb Cheers, Gurer === * * * === https://airbnb.webex.com/meet/gurer.kiratli", "<https://www.google.com/url?q=https%3A%2F%2Fairbnb.webex.com%2Fmeet%2Fgurer.kiratli&sa=D&usd=2&usg=AFQjCNFC3kEwm1Mu8gSE2gl7SlNkV5NMCg [WebEx: 000000000]"], "labels": [0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["And please try to arrive by 9:30 so we can check you and head to the meeting room.", ": )", "Here is the proposed agenda: 10:00am -10:45am PDT", "Contributors sync-up: progress and plan Release Schedule, Management 10:45am - 11:00am PDT Coffee Break 11:00am - 12:00pm PDT Roadmap discussion 12:00pm - 1:00pm PDT Lunch @ Airbnb Cheers, Gurer === * * * === https://airbnb.webex.com/meet/gurer.kiratli", "<https://www.google.com/url?q=https%3A%2F%2Fairbnb.webex.com%2Fmeet%2Fgurer.kiratli&sa=D&usd=2&usg=AFQjCNFC3kEwm1Mu8gSE2gl7SlNkV5NMCg [WebEx: 000000000]", "When Thu Oct 6, 2016 10am – 12pm Pacific Time Where Airbnb HQ, 888 Brannan St, San Francisco, CA 94103, USA (map <https://maps.google.com/maps?q=Airbnb+HQ,+888+Brannan+St,+San+Francisco,+CA+94103,+USA&hl=en) Calendar gurer.kiratli@airbnb.com"], "labels": [0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["<https://www.google.com/url?q=https%3A%2F%2Fairbnb.webex.com%2Fmeet%2Fgurer.kiratli&sa=D&usd=2&usg=AFQjCNFC3kEwm1Mu8gSE2gl7SlNkV5NMCg [WebEx: 000000000]", "When Thu Oct 6, 2016 10am – 12pm Pacific Time Where Airbnb HQ, 888 Brannan St, San Francisco, CA 94103, USA (map <https://maps.google.com/maps?q=Airbnb+HQ,+888+Brannan+St,+San+Francisco,+CA+94103,+USA&hl=en) Calendar gurer.kiratli@airbnb.com", "Who • gurer.kiratli@airbnb.com - organizer • dev@airflow.incubator.apache.org Going?"], "labels": [0, 0, 0], "abstract_id": 0}
{"sentences": ["When Thu Oct 6, 2016 10am – 12pm Pacific Time Where Airbnb HQ, 888 Brannan St, San Francisco, CA 94103, USA (map <https://maps.google.com/maps?q=Airbnb+HQ,+888+Brannan+St,+San+Francisco,+CA+94103,+USA&hl=en) Calendar gurer.kiratli@airbnb.com", "Who • gurer.kiratli@airbnb.com - organizer • dev@airflow.incubator.apache.org Going?", "Yes <https://www.google.com/calendar/event?action=RESPOND&eid=b2YxYjB2a3M2cDc0ZDVnMHYwMGZmMmFzN2sgZGV2QGFpcmZsb3cuaW5jdWJhdG9yLmFwYWNoZS5vcmc&rst=1&tok=MjQjZ3VyZXIua2lyYXRsaUBhaXJibmIuY29tMDQ5ZGNhMzI3OWI5NTJjNThjYTc3YTkzYzgwODc0Yjk0ZmI2NWUwOQ&ctz=America/Los_Angeles&hl=en - Maybe <https://www.google.com/calendar/event?action=RESPOND&eid=b2YxYjB2a3M2cDc0ZDVnMHYwMGZmMmFzN2sgZGV2QGFpcmZsb3cuaW5jdWJhdG9yLmFwYWNoZS5vcmc&rst=3&tok=MjQjZ3VyZXIua2lyYXRsaUBhaXJibmIuY29tMDQ5ZGNhMzI3OWI5NTJjNThjYTc3YTkzYzgwODc0Yjk0ZmI2NWUwOQ&ctz=America/Los_Angeles&hl=en - No <https://www.google.com/calendar/event?action=RESPOND&eid=b2YxYjB2a3M2cDc0ZDVnMHYwMGZmMmFzN2sgZGV2QGFpcmZsb3cuaW5jdWJhdG9yLmFwYWNoZS5vcmc&rst=2&tok=MjQjZ3VyZXIua2lyYXRsaUBhaXJibmIuY29tMDQ5ZGNhMzI3OWI5NTJjNThjYTc3YTkzYzgwODc0Yjk0ZmI2NWUwOQ&ctz=America/Los_Angeles&hl=en more options » <https://www.google.com/calendar/event?action=VIEW&eid=b2YxYjB2a3M2cDc0ZDVnMHYwMGZmMmFzN2sgZGV2QGFpcmZsb3cuaW5jdWJhdG9yLmFwYWNoZS5vcmc&tok=MjQjZ3VyZXIua2lyYXRsaUBhaXJibmIuY29tMDQ5ZGNhMzI3OWI5NTJjNThjYTc3YTkzYzgwODc0Yjk0ZmI2NWUwOQ&ctz=America/Los_Angeles&hl=en Invitation from Google Calendar <https://www.google.com/calendar/"], "labels": [0, 0, 0], "abstract_id": 0}
{"sentences": ["You are receiving this courtesy email at the account dev@airflow.incubator.apache.org because you are an attendee of this event.", "To stop receiving future updates for this event, decline this event.", "Alternatively you can sign up for a Google account at https://www.google.com/calendar/ and control your notification settings for your entire calendar.", "Forwarding this invitation could allow any recipient to modify your RSVP response.", "Learn More <https://support.google.com/calendar/answer/37135#forwarding.", "<Mail-bijlage.ics<invite.ics"], "labels": [0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["Hi Tison, In Ozone the proto files are compiled using the maven plugin.", "Please find usage in the following file https://github.com/apache/hadoop-ozone/blob/master/hadoop-hdds/common/pom.xml#L178.", "Thanks, Mukul On 30/11/19 4:13 pm, tison wrote: Hello here again, I'm not sure how \"Ozone uses the shaded ByteString version\".", "Could you please show me the way for doing so?", "Best, tison.", "tison <wander4096@gmail.com <mailto:wander4096@gmail.com 于2019年11月14日周四 上午11:20写道："], "labels": [0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["Thanks, Mukul On 30/11/19 4:13 pm, tison wrote: Hello here again, I'm not sure how \"Ozone uses the shaded ByteString version\".", "Could you please show me the way for doing so?", "Best, tison.", "tison <wander4096@gmail.com <mailto:wander4096@gmail.com 于2019年11月14日周四 上午11:20写道：", "Thanks for your information Mukul!", "I have one more question."], "labels": [0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["Could you please show me the way for doing so?", "Best, tison.", "tison <wander4096@gmail.com <mailto:wander4096@gmail.com 于2019年11月14日周四 上午11:20写道：", "Thanks for your information Mukul!", "I have one more question.", "Even if I want to use the shaded ByteString version when compile with protoc it requires protobuf-java deps.", "How can I configure protoc use the shaded version to generate codes?", "Best, tison."], "labels": [0, 0, 0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["tison <wander4096@gmail.com <mailto:wander4096@gmail.com 于2019年11月14日周四 上午11:20写道：", "Thanks for your information Mukul!", "I have one more question.", "Even if I want to use the shaded ByteString version when compile with protoc it requires protobuf-java deps.", "How can I configure protoc use the shaded version to generate codes?", "Best, tison.", "Mukul Kumar Singh <mksingh.apache@gmail.com <mailto:mksingh.apache@gmail.com 于2019年11月14日周四 上午11:15写道："], "labels": [0, 0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["Thanks for your information Mukul!", "I have one more question.", "Even if I want to use the shaded ByteString version when compile with protoc it requires protobuf-java deps.", "How can I configure protoc use the shaded version to generate codes?", "Best, tison.", "Mukul Kumar Singh <mksingh.apache@gmail.com <mailto:mksingh.apache@gmail.com 于2019年11月14日周四 上午11:15写道：", "Hi Tison,", "Thanks for the interest in Ratis."], "labels": [0, 0, 0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["Even if I want to use the shaded ByteString version when compile with protoc it requires protobuf-java deps.", "How can I configure protoc use the shaded version to generate codes?", "Best, tison.", "Mukul Kumar Singh <mksingh.apache@gmail.com <mailto:mksingh.apache@gmail.com 于2019年11月14日周四 上午11:15写道：", "Hi Tison,", "Thanks for the interest in Ratis.", "There are 2 options as you have already noticed."], "labels": [0, 0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["How can I configure protoc use the shaded version to generate codes?", "Best, tison.", "Mukul Kumar Singh <mksingh.apache@gmail.com <mailto:mksingh.apache@gmail.com 于2019年11月14日周四 上午11:15写道：", "Hi Tison,", "Thanks for the interest in Ratis.", "There are 2 options as you have already noticed.", "a) Ozone which is a consumer of Ratis, we have used the shaded ByteString version in the Ozone codebase. b)"], "labels": [0, 0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["Best, tison.", "Mukul Kumar Singh <mksingh.apache@gmail.com <mailto:mksingh.apache@gmail.com 于2019年11月14日周四 上午11:15写道：", "Hi Tison,", "Thanks for the interest in Ratis.", "There are 2 options as you have already noticed.", "a) Ozone which is a consumer of Ratis, we have used the shaded ByteString version in the Ozone codebase. b)", "We can have a utility for conversion as you have already pointed out."], "labels": [0, 0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["Mukul Kumar Singh <mksingh.apache@gmail.com <mailto:mksingh.apache@gmail.com 于2019年11月14日周四 上午11:15写道：", "Hi Tison,", "Thanks for the interest in Ratis.", "There are 2 options as you have already noticed.", "a) Ozone which is a consumer of Ratis, we have used the shaded ByteString version in the Ozone codebase. b)", "We can have a utility for conversion as you have already pointed out.", "Thanks, Mukul On 13/11/19 8:28 pm, tison wrote: Well I find a way to write a utility for convertion."], "labels": [0, 0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["Hi Tison,", "Thanks for the interest in Ratis.", "There are 2 options as you have already noticed.", "a) Ozone which is a consumer of Ratis, we have used the shaded ByteString version in the Ozone codebase. b)", "We can have a utility for conversion as you have already pointed out.", "Thanks, Mukul On 13/11/19 8:28 pm, tison wrote: Well I find a way to write a utility for convertion.", "Best, tison.", "tison <wander4096@gmail.com <mailto:wander4096@gmail.com 于2019年11月13日周三 下午10:46写道："], "labels": [0, 0, 0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["There are 2 options as you have already noticed.", "a) Ozone which is a consumer of Ratis, we have used the shaded ByteString version in the Ozone codebase. b)", "We can have a utility for conversion as you have already pointed out.", "Thanks, Mukul On 13/11/19 8:28 pm, tison wrote: Well I find a way to write a utility for convertion.", "Best, tison.", "tison <wander4096@gmail.com <mailto:wander4096@gmail.com 于2019年11月13日周三 下午10:46写道：", "Hi devs, I am trying to develop a filesystem-view storage on ratis, and here is the problem I meet:"], "labels": [0, 0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["We can have a utility for conversion as you have already pointed out.", "Thanks, Mukul On 13/11/19 8:28 pm, tison wrote: Well I find a way to write a utility for convertion.", "Best, tison.", "tison <wander4096@gmail.com <mailto:wander4096@gmail.com 于2019年11月13日周三 下午10:46写道：", "Hi devs, I am trying to develop a filesystem-view storage on ratis, and here is the problem I meet:", "When I trying to reply within `StateMachine#query` while generating Message, compiler fails on ByteString is not compatible with ByteString."], "labels": [0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["Thanks, Mukul On 13/11/19 8:28 pm, tison wrote: Well I find a way to write a utility for convertion.", "Best, tison.", "tison <wander4096@gmail.com <mailto:wander4096@gmail.com 于2019年11月13日周三 下午10:46写道：", "Hi devs, I am trying to develop a filesystem-view storage on ratis, and here is the problem I meet:", "When I trying to reply within `StateMachine#query` while generating Message, compiler fails on ByteString is not compatible with ByteString.", "I think it is because ratis use shaded protobuf deps."], "labels": [0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["Best, tison.", "tison <wander4096@gmail.com <mailto:wander4096@gmail.com 于2019年11月13日周三 下午10:46写道：", "Hi devs, I am trying to develop a filesystem-view storage on ratis, and here is the problem I meet:", "When I trying to reply within `StateMachine#query` while generating Message, compiler fails on ByteString is not compatible with ByteString.", "I think it is because ratis use shaded protobuf deps.", "However, how can I instance Message outside ratis project?"], "labels": [0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["Hi devs, I am trying to develop a filesystem-view storage on ratis, and here is the problem I meet:", "When I trying to reply within `StateMachine#query` while generating Message, compiler fails on ByteString is not compatible with ByteString.", "I think it is because ratis use shaded protobuf deps.", "However, how can I instance Message outside ratis project?", "Shall I also depends on ratis-thirdparty-misc?", "Is there a workaround?"], "labels": [0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["When I trying to reply within `StateMachine#query` while generating Message, compiler fails on ByteString is not compatible with ByteString.", "I think it is because ratis use shaded protobuf deps.", "However, how can I instance Message outside ratis project?", "Shall I also depends on ratis-thirdparty-misc?", "Is there a workaround?", "Or will ratis provides its own abstraction for resolving dep issues?", "Best, tison."], "labels": [0, 0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["I was curious what the thoughts are regarding shifting Airflow to a publish model from the poll model currently used by many of the sensors inheriting from BaseSensorOperator.", "It would prevent much of the polling that may take up quite a bit of resources.", "Thanks.", "Regards, David"], "labels": [0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["Hi Steve,", "In the case of decimal numbers, Daffodil creates an infoset output with the minimum number of digits necessary to display it with the same precision.", "So 5000.00 will be output as 5000", "If I want to retain the digits to the right of the decimal point, then I should declare the price element with the type xs:string, is that correct?", "/Roger -----Original Message-----", "From: Steve Lawrence <slawrence@apache.org Sent: Monday, December 3, 2018 9:36 AM To: users@daffodil.apache.org; Costello, Roger L. <costello@mitre.org Subject: Re: How to retain the digits to the right of the decimal point?", "The pattern defines the format of the data."], "labels": [0, 0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["So 5000.00 will be output as 5000", "If I want to retain the digits to the right of the decimal point, then I should declare the price element with the type xs:string, is that correct?", "/Roger -----Original Message-----", "From: Steve Lawrence <slawrence@apache.org Sent: Monday, December 3, 2018 9:36 AM To: users@daffodil.apache.org; Costello, Roger L. <costello@mitre.org Subject: Re: How to retain the digits to the right of the decimal point?", "The pattern defines the format of the data.", "It does not define the format of the infoset."], "labels": [0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["/Roger -----Original Message-----", "From: Steve Lawrence <slawrence@apache.org Sent: Monday, December 3, 2018 9:36 AM To: users@daffodil.apache.org; Costello, Roger L. <costello@mitre.org Subject: Re: How to retain the digits to the right of the decimal point?", "The pattern defines the format of the data.", "It does not define the format of the infoset.", "I believe the spec is ambiguous or silent about how various data fields should be output to the infoset.", "I know we've had this issue with date/time fields recently."], "labels": [0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["The pattern defines the format of the data.", "It does not define the format of the infoset.", "I believe the spec is ambiguous or silent about how various data fields should be output to the infoset.", "I know we've had this issue with date/time fields recently.", "In the case of decimal numbers, Daffodil creates an infoset output with the minimum number of digits necessary to display it with the same precision.", "So 5000.00 will be output as 5000, but 5000.99 will be output with the extra decimal precision.", "- Steve On 12/3/18 9:30 AM, Costello, Roger L. wrote: Hi Mike, * Use 0 instead of # for the rightmost two."], "labels": [0, 0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["It does not define the format of the infoset.", "I believe the spec is ambiguous or silent about how various data fields should be output to the infoset.", "I know we've had this issue with date/time fields recently.", "In the case of decimal numbers, Daffodil creates an infoset output with the minimum number of digits necessary to display it with the same precision.", "So 5000.00 will be output as 5000, but 5000.99 will be output with the extra decimal precision.", "- Steve On 12/3/18 9:30 AM, Costello, Roger L. wrote: Hi Mike, * Use 0 instead of # for the rightmost two.", "I tried that: <xs:elementname=\"price\"type=\"xs:decimal\" dfdl:textStandardDecimalSeparator=\".\" dfdl:textNumberPattern=\"####.00\"/"], "labels": [0, 0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["I know we've had this issue with date/time fields recently.", "In the case of decimal numbers, Daffodil creates an infoset output with the minimum number of digits necessary to display it with the same precision.", "So 5000.00 will be output as 5000, but 5000.99 will be output with the extra decimal precision.", "- Steve On 12/3/18 9:30 AM, Costello, Roger L. wrote: Hi Mike, * Use 0 instead of # for the rightmost two.", "I tried that: <xs:elementname=\"price\"type=\"xs:decimal\" dfdl:textStandardDecimalSeparator=\".\" dfdl:textNumberPattern=\"####.00\"/", "It gave the same result (the .00 is removed): 5000.00 -- parse -- 5000"], "labels": [0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["So 5000.00 will be output as 5000, but 5000.99 will be output with the extra decimal precision.", "- Steve On 12/3/18 9:30 AM, Costello, Roger L. wrote: Hi Mike, * Use 0 instead of # for the rightmost two.", "I tried that: <xs:elementname=\"price\"type=\"xs:decimal\" dfdl:textStandardDecimalSeparator=\".\" dfdl:textNumberPattern=\"####.00\"/", "It gave the same result (the .00 is removed): 5000.00 -- parse -- 5000", "Thoughts?"], "labels": [0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["- Steve On 12/3/18 9:30 AM, Costello, Roger L. wrote: Hi Mike, * Use 0 instead of # for the rightmost two.", "I tried that: <xs:elementname=\"price\"type=\"xs:decimal\" dfdl:textStandardDecimalSeparator=\".\" dfdl:textNumberPattern=\"####.00\"/", "It gave the same result (the .00 is removed): 5000.00 -- parse -- 5000", "Thoughts?", "/Roger *From:*"], "labels": [0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["I tried that: <xs:elementname=\"price\"type=\"xs:decimal\" dfdl:textStandardDecimalSeparator=\".\" dfdl:textNumberPattern=\"####.00\"/", "It gave the same result (the .00 is removed): 5000.00 -- parse -- 5000", "Thoughts?", "/Roger *From:*", "Mike Beckerle <mbeckerle@tresys.com *Sent:* Monday, December 3, 2018 9:21 AM", "*To:* users@daffodil.apache.org *Subject:*"], "labels": [0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["It gave the same result (the .00 is removed): 5000.00 -- parse -- 5000", "Thoughts?", "/Roger *From:*", "Mike Beckerle <mbeckerle@tresys.com *Sent:* Monday, December 3, 2018 9:21 AM", "*To:* users@daffodil.apache.org *Subject:*", "Re: How to retain the digits to the right of the decimal point?", "Use 0 instead of # for the rightmost two.", "In a pattern, a zero denotes any digit."], "labels": [0, 0, 0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["Thoughts?", "/Roger *From:*", "Mike Beckerle <mbeckerle@tresys.com *Sent:* Monday, December 3, 2018 9:21 AM", "*To:* users@daffodil.apache.org *Subject:*", "Re: How to retain the digits to the right of the decimal point?", "Use 0 instead of # for the rightmost two.", "In a pattern, a zero denotes any digit.", "A # denotes an optional digit.", "--------"], "labels": [0, 0, 0, 0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["*To:* users@daffodil.apache.org *Subject:*", "Re: How to retain the digits to the right of the decimal point?", "Use 0 instead of # for the rightmost two.", "In a pattern, a zero denotes any digit.", "A # denotes an optional digit.", "--------", "Original message --------", "From: \"Costello, Roger L.\" <costello@mitre.org <mailto:costello@mitre.org Date: 12/3/18 8:46 AM (GMT-05:00) To: users@daffodil.apache.org <mailto:users@daffodil.apache.org"], "labels": [0, 0, 0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["Re: How to retain the digits to the right of the decimal point?", "Use 0 instead of # for the rightmost two.", "In a pattern, a zero denotes any digit.", "A # denotes an optional digit.", "--------", "Original message --------", "From: \"Costello, Roger L.\" <costello@mitre.org <mailto:costello@mitre.org Date: 12/3/18 8:46 AM (GMT-05:00) To: users@daffodil.apache.org <mailto:users@daffodil.apache.org", "Subject:"], "labels": [0, 0, 0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["Use 0 instead of # for the rightmost two.", "In a pattern, a zero denotes any digit.", "A # denotes an optional digit.", "--------", "Original message --------", "From: \"Costello, Roger L.\" <costello@mitre.org <mailto:costello@mitre.org Date: 12/3/18 8:46 AM (GMT-05:00) To: users@daffodil.apache.org <mailto:users@daffodil.apache.org", "Subject:", "How to retain the digits to the right of the decimal point?"], "labels": [0, 0, 0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["In a pattern, a zero denotes any digit.", "A # denotes an optional digit.", "--------", "Original message --------", "From: \"Costello, Roger L.\" <costello@mitre.org <mailto:costello@mitre.org Date: 12/3/18 8:46 AM (GMT-05:00) To: users@daffodil.apache.org <mailto:users@daffodil.apache.org", "Subject:", "How to retain the digits to the right of the decimal point?", "Hello DFDL community,"], "labels": [0, 0, 0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["--------", "Original message --------", "From: \"Costello, Roger L.\" <costello@mitre.org <mailto:costello@mitre.org Date: 12/3/18 8:46 AM (GMT-05:00) To: users@daffodil.apache.org <mailto:users@daffodil.apache.org", "Subject:", "How to retain the digits to the right of the decimal point?", "Hello DFDL community,", "My input contains decimal values such as: 2999.99 and 5000.00"], "labels": [0, 0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["From: \"Costello, Roger L.\" <costello@mitre.org <mailto:costello@mitre.org Date: 12/3/18 8:46 AM (GMT-05:00) To: users@daffodil.apache.org <mailto:users@daffodil.apache.org", "Subject:", "How to retain the digits to the right of the decimal point?", "Hello DFDL community,", "My input contains decimal values such as: 2999.99 and 5000.00", "When I parse my input, the .00 gets removed, e.g., 5000.00 -- parse -- 5000"], "labels": [0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["Subject:", "How to retain the digits to the right of the decimal point?", "Hello DFDL community,", "My input contains decimal values such as: 2999.99 and 5000.00", "When I parse my input, the .00 gets removed, e.g., 5000.00 -- parse -- 5000", "But the .99 is not removed, e.g., 2999.99 -- parse -- 2999.99", "I want to retain the two digits to the right of the decimal point, even if they are 00 How to retain the digits?", "I thought this would do the job: dfdl:textNumberPattern=\"####.##\"/"], "labels": [0, 0, 0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["Hello DFDL community,", "My input contains decimal values such as: 2999.99 and 5000.00", "When I parse my input, the .00 gets removed, e.g., 5000.00 -- parse -- 5000", "But the .99 is not removed, e.g., 2999.99 -- parse -- 2999.99", "I want to retain the two digits to the right of the decimal point, even if they are 00 How to retain the digits?", "I thought this would do the job: dfdl:textNumberPattern=\"####.##\"/", "However, that has no effect."], "labels": [0, 0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["When I parse my input, the .00 gets removed, e.g., 5000.00 -- parse -- 5000", "But the .99 is not removed, e.g., 2999.99 -- parse -- 2999.99", "I want to retain the two digits to the right of the decimal point, even if they are 00 How to retain the digits?", "I thought this would do the job: dfdl:textNumberPattern=\"####.##\"/", "However, that has no effect.", "What's the right way to do it?"], "labels": [0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["But the .99 is not removed, e.g., 2999.99 -- parse -- 2999.99", "I want to retain the two digits to the right of the decimal point, even if they are 00 How to retain the digits?", "I thought this would do the job: dfdl:textNumberPattern=\"####.##\"/", "However, that has no effect.", "What's the right way to do it?", "/Roger"], "labels": [0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["In Airflow 1.6.2, all of the concurrency controls are sometimes ignored and many tasks are scheduled simultaneously.", "I don't know if this has been completely fixed.", "You can rely on them to separate your task runs *most* of the time, but not *all* of the time- so don't write code that depends on exclusive operation.", "Lance On Thu, Aug 11, 2016 at 1:15 PM, Kurt Muehlner <kmuehlner@connexity.com wrote: I’m not aware of a concurrency limit at task granularity, however, one available option is the ‘max_active_runs’ parameter in the DAG class.", "max_active_runs (int) – maximum number of active DAG runs, beyond this number of DAG runs in a running state, the scheduler won’t create new active DAG runs I’ve used the ‘pool size of 1’ option you mention as a very simple way to ensure two DAGs run in serial."], "labels": [0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["I don't know if this has been completely fixed.", "You can rely on them to separate your task runs *most* of the time, but not *all* of the time- so don't write code that depends on exclusive operation.", "Lance On Thu, Aug 11, 2016 at 1:15 PM, Kurt Muehlner <kmuehlner@connexity.com wrote: I’m not aware of a concurrency limit at task granularity, however, one available option is the ‘max_active_runs’ parameter in the DAG class.", "max_active_runs (int) – maximum number of active DAG runs, beyond this number of DAG runs in a running state, the scheduler won’t create new active DAG runs I’ve used the ‘pool size of 1’ option you mention as a very simple way to ensure two DAGs run in serial.", "Kurt On 8/11/16, 6:57 AM, \"הילה ויזן\" <hilaviz@gmail.com wrote: should I use pool of size 1?"], "labels": [0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["Lance On Thu, Aug 11, 2016 at 1:15 PM, Kurt Muehlner <kmuehlner@connexity.com wrote: I’m not aware of a concurrency limit at task granularity, however, one available option is the ‘max_active_runs’ parameter in the DAG class.", "max_active_runs (int) – maximum number of active DAG runs, beyond this number of DAG runs in a running state, the scheduler won’t create new active DAG runs I’ve used the ‘pool size of 1’ option you mention as a very simple way to ensure two DAGs run in serial.", "Kurt On 8/11/16, 6:57 AM, \"הילה ויזן\" <hilaviz@gmail.com wrote: should I use pool of size 1?", "On Thu, Aug 11, 2016 at 4:46 PM, הילה ויזן <hilaviz@gmail.com wrote:"], "labels": [0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["max_active_runs (int) – maximum number of active DAG runs, beyond this number of DAG runs in a running state, the scheduler won’t create new active DAG runs I’ve used the ‘pool size of 1’ option you mention as a very simple way to ensure two DAGs run in serial.", "Kurt On 8/11/16, 6:57 AM, \"הילה ויזן\" <hilaviz@gmail.com wrote: should I use pool of size 1?", "On Thu, Aug 11, 2016 at 4:46 PM, הילה ויזן <hilaviz@gmail.com wrote:", "Hi, I searched in the documentation for a way to limit a specific task concurrency to 1, but didn't find a way."], "labels": [0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["Kurt On 8/11/16, 6:57 AM, \"הילה ויזן\" <hilaviz@gmail.com wrote: should I use pool of size 1?", "On Thu, Aug 11, 2016 at 4:46 PM, הילה ויזן <hilaviz@gmail.com wrote:", "Hi, I searched in the documentation for a way to limit a specific task concurrency to 1, but didn't find a way.", "I thought that 'depends_on_past' should achieve this goal, but I want the task to run even if the previous task failed - just to be sure the they don't run in parallel.", "The task doesn't have a downstream task, so I can't use 'wait_for_downstream'."], "labels": [0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["On Thu, Aug 11, 2016 at 4:46 PM, הילה ויזן <hilaviz@gmail.com wrote:", "Hi, I searched in the documentation for a way to limit a specific task concurrency to 1, but didn't find a way.", "I thought that 'depends_on_past' should achieve this goal, but I want the task to run even if the previous task failed - just to be sure the they don't run in parallel.", "The task doesn't have a downstream task, so I can't use 'wait_for_downstream'.", "Am I Missing something?"], "labels": [0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["Hi, I searched in the documentation for a way to limit a specific task concurrency to 1, but didn't find a way.", "I thought that 'depends_on_past' should achieve this goal, but I want the task to run even if the previous task failed - just to be sure the they don't run in parallel.", "The task doesn't have a downstream task, so I can't use 'wait_for_downstream'.", "Am I Missing something?", "Thanks, Hila -- Lance Norskog lance.norskog@gmail.com Redwood City, CA"], "labels": [0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["Just created https://issues.apache.org/jira/browse/AIRFLOW-1273, https://issues.apache.org/jira/browse/AIRFLOW-1272, and https://issues.apache.org/jira/browse/AIRFLOW-1271.", "We'll follow up with pull requests in the coming weeks.", "On Thu, Jun 1, 2017 at 10:44 AM Peter Dolan <peterdolan@google.com wrote: Hi Bolke, Great!", "And yes, we will be able to maintain these operators after the contributions.", "We further would always insist on strong test coverage as well."], "labels": [0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["We'll follow up with pull requests in the coming weeks.", "On Thu, Jun 1, 2017 at 10:44 AM Peter Dolan <peterdolan@google.com wrote: Hi Bolke, Great!", "And yes, we will be able to maintain these operators after the contributions.", "We further would always insist on strong test coverage as well.", "I'll open some JIRA tickets to track their implementation.", "Thanks, Peter On Thu, Jun 1, 2017 at 6:05 AM", "Bolke de Bruin <bdbruin@gmail.com wrote: Hi Peter,"], "labels": [0, 0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["On Thu, Jun 1, 2017 at 10:44 AM Peter Dolan <peterdolan@google.com wrote: Hi Bolke, Great!", "And yes, we will be able to maintain these operators after the contributions.", "We further would always insist on strong test coverage as well.", "I'll open some JIRA tickets to track their implementation.", "Thanks, Peter On Thu, Jun 1, 2017 at 6:05 AM", "Bolke de Bruin <bdbruin@gmail.com wrote: Hi Peter,", "That sounds great!"], "labels": [0, 0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["And yes, we will be able to maintain these operators after the contributions.", "We further would always insist on strong test coverage as well.", "I'll open some JIRA tickets to track their implementation.", "Thanks, Peter On Thu, Jun 1, 2017 at 6:05 AM", "Bolke de Bruin <bdbruin@gmail.com wrote: Hi Peter,", "That sounds great!", "I think the main criteria for this is will you maintain the code afterwards?", "The contrib section is slowly but steadily growing and with operators/hooks we are particularly dependent on the community as not all (or even none in some case) of the committers use these themselves."], "labels": [0, 0, 0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["We further would always insist on strong test coverage as well.", "I'll open some JIRA tickets to track their implementation.", "Thanks, Peter On Thu, Jun 1, 2017 at 6:05 AM", "Bolke de Bruin <bdbruin@gmail.com wrote: Hi Peter,", "That sounds great!", "I think the main criteria for this is will you maintain the code afterwards?", "The contrib section is slowly but steadily growing and with operators/hooks we are particularly dependent on the community as not all (or even none in some case) of the committers use these themselves.", "In any case test coverage is required, but that is a given I think."], "labels": [0, 0, 0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["Thanks, Peter On Thu, Jun 1, 2017 at 6:05 AM", "Bolke de Bruin <bdbruin@gmail.com wrote: Hi Peter,", "That sounds great!", "I think the main criteria for this is will you maintain the code afterwards?", "The contrib section is slowly but steadily growing and with operators/hooks we are particularly dependent on the community as not all (or even none in some case) of the committers use these themselves.", "In any case test coverage is required, but that is a given I think.", "Kind regards, Bolke On 31 May 2017, at 21:10, Peter Dolan <peterdolan@google.com.INVALID wrote: Hello developers, I work with Google Cloud ML, and my team and I are interested in contributing a set of Operators to support working with the Cloud ML platform."], "labels": [0, 0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["Bolke de Bruin <bdbruin@gmail.com wrote: Hi Peter,", "That sounds great!", "I think the main criteria for this is will you maintain the code afterwards?", "The contrib section is slowly but steadily growing and with operators/hooks we are particularly dependent on the community as not all (or even none in some case) of the committers use these themselves.", "In any case test coverage is required, but that is a given I think.", "Kind regards, Bolke On 31 May 2017, at 21:10, Peter Dolan <peterdolan@google.com.INVALID wrote: Hello developers, I work with Google Cloud ML, and my team and I are interested in contributing a set of Operators to support working with the Cloud ML platform.", "The platform supports using the TensorFlow deep neural network framework as a managed system."], "labels": [0, 0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["I think the main criteria for this is will you maintain the code afterwards?", "The contrib section is slowly but steadily growing and with operators/hooks we are particularly dependent on the community as not all (or even none in some case) of the committers use these themselves.", "In any case test coverage is required, but that is a given I think.", "Kind regards, Bolke On 31 May 2017, at 21:10, Peter Dolan <peterdolan@google.com.INVALID wrote: Hello developers, I work with Google Cloud ML, and my team and I are interested in contributing a set of Operators to support working with the Cloud ML platform.", "The platform supports using the TensorFlow deep neural network framework as a managed system.", "In particular, we would like to contribute * CloudMLTrainingOperator, which would launch and monitor a Cloud ML Training Job ( https://cloud.google.com/ml-engine/docs/how-tos/training-jobs < https://cloud.google.com/ml-engine/docs/how-tos/training-jobs), * CloudMLBatchPredictionOperator, which would launch and monitor a Cloud ML Batch Prediction Job ( https://cloud.google.com/ml-engine/docs/how-tos/batch-predict < https://cloud.google.com/ml-engine/docs/how-tos/batch-predict), and * CloudMLVersionOperator, which can create, update, and delete TensorFlow model versions ( https://cloud.google.com/ml-engine/docs/how-tos/managing-models-jobs < https://cloud.google.com/ml-engine/docs/how-tos/managing-models-jobs)"], "labels": [0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["Kind regards, Bolke On 31 May 2017, at 21:10, Peter Dolan <peterdolan@google.com.INVALID wrote: Hello developers, I work with Google Cloud ML, and my team and I are interested in contributing a set of Operators to support working with the Cloud ML platform.", "The platform supports using the TensorFlow deep neural network framework as a managed system.", "In particular, we would like to contribute * CloudMLTrainingOperator, which would launch and monitor a Cloud ML Training Job ( https://cloud.google.com/ml-engine/docs/how-tos/training-jobs < https://cloud.google.com/ml-engine/docs/how-tos/training-jobs), * CloudMLBatchPredictionOperator, which would launch and monitor a Cloud ML Batch Prediction Job ( https://cloud.google.com/ml-engine/docs/how-tos/batch-predict < https://cloud.google.com/ml-engine/docs/how-tos/batch-predict), and * CloudMLVersionOperator, which can create, update, and delete TensorFlow model versions ( https://cloud.google.com/ml-engine/docs/how-tos/managing-models-jobs < https://cloud.google.com/ml-engine/docs/how-tos/managing-models-jobs)", "I'm eager to hear if the Airflow project is open to these contributions, and if any changes are suggested."], "labels": [0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["I'm eager to hear if the Airflow project is open to these contributions, and if any changes are suggested.", "We have working prototype versions of all of them.", "Thanks in advance, Peter"], "labels": [0, 0, 0], "abstract_id": 0}
{"sentences": ["Github user rodsimpson commented on the issue: https://github.com/apache/usergrid/pull/576", "Looks good to me - merging now.", "---"], "labels": [0, 0, 0], "abstract_id": 0}
{"sentences": ["Hello,", "We are using gobblin to ingest data from a remote hdfc cluster to a local one.", "Both clusters are in same geolocation.", "How ever when we start I hating data we observe two behaviour.", "1 The JVM heap usage is erratic.", "Near the beginning of the job start we see frequent GC on the driver jvm.", "The memory usage is also really high.", "We have around 56000 files and the size is 1TB 2 The initial time spent by the job on the driver box is nearly 6times of the map job duration.", "This mean we are spending almost 6times rounding up the files compare to actual copy."], "labels": [0, 0, 0, 0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["Both clusters are in same geolocation.", "How ever when we start I hating data we observe two behaviour.", "1 The JVM heap usage is erratic.", "Near the beginning of the job start we see frequent GC on the driver jvm.", "The memory usage is also really high.", "We have around 56000 files and the size is 1TB 2 The initial time spent by the job on the driver box is nearly 6times of the map job duration.", "This mean we are spending almost 6times rounding up the files compare to actual copy.", "We would like to know if there is a way we could avoid these two pitfalls while using distcp-NG."], "labels": [0, 0, 0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["1 The JVM heap usage is erratic.", "Near the beginning of the job start we see frequent GC on the driver jvm.", "The memory usage is also really high.", "We have around 56000 files and the size is 1TB 2 The initial time spent by the job on the driver box is nearly 6times of the map job duration.", "This mean we are spending almost 6times rounding up the files compare to actual copy.", "We would like to know if there is a way we could avoid these two pitfalls while using distcp-NG.", "We are ok if the data is inconsistent at the dataset level as long as individual files are copied correctly."], "labels": [0, 0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["Near the beginning of the job start we see frequent GC on the driver jvm.", "The memory usage is also really high.", "We have around 56000 files and the size is 1TB 2 The initial time spent by the job on the driver box is nearly 6times of the map job duration.", "This mean we are spending almost 6times rounding up the files compare to actual copy.", "We would like to know if there is a way we could avoid these two pitfalls while using distcp-NG.", "We are ok if the data is inconsistent at the dataset level as long as individual files are copied correctly.", "Another thing, we see there are a few parameters which are used in the code but I could not find their reference in the docs."], "labels": [0, 0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["We have around 56000 files and the size is 1TB 2 The initial time spent by the job on the driver box is nearly 6times of the map job duration.", "This mean we are spending almost 6times rounding up the files compare to actual copy.", "We would like to know if there is a way we could avoid these two pitfalls while using distcp-NG.", "We are ok if the data is inconsistent at the dataset level as long as individual files are copied correctly.", "Another thing, we see there are a few parameters which are used in the code but I could not find their reference in the docs.", "E.g. gobblin.prioritization.maxCopy.copyEntities Gobblin.copy.max.concurrent.listing.services Gobblin.copy.binpacking.Maxworkunitperbin Gobblin.copy.binpacking.MaxsizePerBin Gobblin.copy.abortonsinglefailure"], "labels": [0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["This mean we are spending almost 6times rounding up the files compare to actual copy.", "We would like to know if there is a way we could avoid these two pitfalls while using distcp-NG.", "We are ok if the data is inconsistent at the dataset level as long as individual files are copied correctly.", "Another thing, we see there are a few parameters which are used in the code but I could not find their reference in the docs.", "E.g. gobblin.prioritization.maxCopy.copyEntities Gobblin.copy.max.concurrent.listing.services Gobblin.copy.binpacking.Maxworkunitperbin Gobblin.copy.binpacking.MaxsizePerBin Gobblin.copy.abortonsinglefailure", "Is there a better way to understand these other than looking into the code ?"], "labels": [0, 0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["We are ok if the data is inconsistent at the dataset level as long as individual files are copied correctly.", "Another thing, we see there are a few parameters which are used in the code but I could not find their reference in the docs.", "E.g. gobblin.prioritization.maxCopy.copyEntities Gobblin.copy.max.concurrent.listing.services Gobblin.copy.binpacking.Maxworkunitperbin Gobblin.copy.binpacking.MaxsizePerBin Gobblin.copy.abortonsinglefailure", "Is there a better way to understand these other than looking into the code ?", "-- Cheerio!"], "labels": [0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["Another thing, we see there are a few parameters which are used in the code but I could not find their reference in the docs.", "E.g. gobblin.prioritization.maxCopy.copyEntities Gobblin.copy.max.concurrent.listing.services Gobblin.copy.binpacking.Maxworkunitperbin Gobblin.copy.binpacking.MaxsizePerBin Gobblin.copy.abortonsinglefailure", "Is there a better way to understand these other than looking into the code ?", "-- Cheerio!", "*Rohit*"], "labels": [0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["[ https://issues.apache.org/jira/browse/USERGRID-1344?page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel&focusedCommentId=16033038#comment-16033038 ] ASF GitHub Bot commented on USERGRID-1344: ------------------------------------------", "Github user vineetvermait commented on the issue: https://github.com/apache/usergrid/pull/571", "Issue filed in JIRA: [USERGRID-1344](https://issues.apache.org/jira/browse/USERGRID-1344)"], "labels": [0, 0, 0], "abstract_id": 0}
{"sentences": ["Github user vineetvermait commented on the issue: https://github.com/apache/usergrid/pull/571", "Issue filed in JIRA: [USERGRID-1344](https://issues.apache.org/jira/browse/USERGRID-1344)", "Upgrade of Elastic Search Client to 5.4.0", "----------------------------------------- Key: USERGRID-1344 URL: https://issues.apache.org/jira/browse/USERGRID-1344", "Project: Usergrid Issue Type: Improvement Components: Chop, Stack Affects Versions: 2.2.0, 2.1.0 Reporter: Vineet Verma Labels: client, elasticsearch, java, patch, upgrade Fix For: 2.1.0 Upgrade from: ElasticSearch 1.4.x - 1.7.x"], "labels": [0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["Issue filed in JIRA: [USERGRID-1344](https://issues.apache.org/jira/browse/USERGRID-1344)", "Upgrade of Elastic Search Client to 5.4.0", "----------------------------------------- Key: USERGRID-1344 URL: https://issues.apache.org/jira/browse/USERGRID-1344", "Project: Usergrid Issue Type: Improvement Components: Chop, Stack Affects Versions: 2.2.0, 2.1.0 Reporter: Vineet Verma Labels: client, elasticsearch, java, patch, upgrade Fix For: 2.1.0 Upgrade from: ElasticSearch 1.4.x - 1.7.x", "To ElasticSearch 5.4.x --"], "labels": [0, 0, 0, 0, 0], "abstract_id": 0}
{"sentences": ["Upgrade of Elastic Search Client to 5.4.0", "----------------------------------------- Key: USERGRID-1344 URL: https://issues.apache.org/jira/browse/USERGRID-1344", "Project: Usergrid Issue Type: Improvement Components: Chop, Stack Affects Versions: 2.2.0, 2.1.0 Reporter: Vineet Verma Labels: client, elasticsearch, java, patch, upgrade Fix For: 2.1.0 Upgrade from: ElasticSearch 1.4.x - 1.7.x", "To ElasticSearch 5.4.x --", "This message was sent by Atlassian JIRA (v6.3.15#6346)"], "labels": [0, 0, 0, 0, 0], "abstract_id": 0}
